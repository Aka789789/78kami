# é‡‘é±¼æ™ºç›’å¡å¯†æˆæƒç³»ç»Ÿ - å®Œæ•´å¼€å‘æ–‡æ¡£

## ç›®å½•

- [1. é¡¹ç›®æ¦‚è¿°](#1-é¡¹ç›®æ¦‚è¿°)
- [2. å‰ç«¯å¼€å‘éƒ¨åˆ†](#2-å‰ç«¯å¼€å‘éƒ¨åˆ†)
- [3. åç«¯å¼€å‘éƒ¨åˆ†](#3-åç«¯å¼€å‘éƒ¨åˆ†)
- [4. æ•°æ®éƒ¨åˆ†](#4-æ•°æ®éƒ¨åˆ†)
- [5. UI/UXè®¾è®¡éƒ¨åˆ†](#5-uiuxè®¾è®¡éƒ¨åˆ†)
- [6. å…¶ä»–ä¿¡æ¯](#6-å…¶ä»–ä¿¡æ¯)

---

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 ç³»ç»Ÿç®€ä»‹

é‡‘é±¼æ™ºç›’å¡å¯†æˆæƒç³»ç»Ÿæ˜¯ä¸€ä¸ªä¼ä¸šçº§çš„è½¯ä»¶æˆæƒç®¡ç†å¹³å°ï¼Œé‡‡ç”¨å‰åç«¯åˆ†ç¦»æ¶æ„ï¼Œæ”¯æŒè´¦å·å¯†ç +å¡å¯†åŒé‡éªŒè¯æœºåˆ¶ã€‚ç³»ç»Ÿä¸»è¦ç”¨äºPythonæ¡Œé¢åº”ç”¨çš„æˆæƒæ§åˆ¶ï¼Œæä¾›å®Œæ•´çš„å¡å¯†ç”Ÿæˆã€åˆ†å‘ã€æ¿€æ´»å’Œç®¡ç†åŠŸèƒ½ã€‚

### 1.2 æ ¸å¿ƒåŠŸèƒ½

- **åº”ç”¨ç®¡ç†**ï¼šæ”¯æŒå¤šåº”ç”¨ç®¡ç†ï¼Œæ¯ä¸ªåº”ç”¨ç‹¬ç«‹çš„æˆæƒç­–ç•¥
- **å¡å¯†ç®¡ç†**ï¼šæ‰¹é‡ç”Ÿæˆã€æ¿€æ´»æ§åˆ¶ã€åˆ°æœŸç®¡ç†
- **ç”¨æˆ·ç®¡ç†**ï¼šå¤šè§’è‰²æƒé™ä½“ç³»ï¼Œç²¾ç»†åŒ–æƒé™æ§åˆ¶
- **è®¾å¤‡ç»‘å®š**ï¼šç¡¬ä»¶æŒ‡çº¹è¯†åˆ«ï¼Œé˜²æ­¢æˆæƒæ»¥ç”¨
- **å®‰å…¨æ§åˆ¶**ï¼šAES-256åŠ å¯†ã€JWTè®¤è¯ã€IPç™½åå•
- **ç›‘æ§å®¡è®¡**ï¼šå®Œæ•´çš„æ“ä½œæ—¥å¿—å’Œå®‰å…¨å®¡è®¡

### 1.3 æŠ€æœ¯æ¶æ„

```mermaid
graph TB
    A[å‰ç«¯ React + Next.js] --> B[APIç½‘å…³]
    B --> C[åç«¯ FastAPI]
    C --> D[PostgreSQL æ•°æ®åº“]
    C --> E[Redis ç¼“å­˜]
    C --> F[æ–‡ä»¶å­˜å‚¨]
    G[Pythonå®¢æˆ·ç«¯] --> B
```

---

## 2. å‰ç«¯å¼€å‘éƒ¨åˆ†

### 2.1 æŠ€æœ¯æ ˆè¯´æ˜

#### æ ¸å¿ƒæ¡†æ¶
- **React 18.2.0**ï¼šä¸»è¦UIæ¡†æ¶
- **Next.js 13.4.19**ï¼šå…¨æ ˆReactæ¡†æ¶ï¼Œæ”¯æŒSSR/SSG
- **TypeScript 5.1.6**ï¼šç±»å‹å®‰å…¨çš„JavaScriptè¶…é›†

#### UIç»„ä»¶åº“
- **Ant Design 5.8.6**ï¼šä¼ä¸šçº§UIè®¾è®¡è¯­è¨€
- **Heroicons**ï¼šé«˜è´¨é‡SVGå›¾æ ‡åº“
- **Headless UI**ï¼šæ— æ ·å¼å¯è®¿é—®ç»„ä»¶

#### çŠ¶æ€ç®¡ç†ä¸æ•°æ®è·å–
- **Axios 1.5.0**ï¼šHTTPå®¢æˆ·ç«¯
- **SWR**ï¼šæ•°æ®è·å–å’Œç¼“å­˜
- **React Hook Form**ï¼šè¡¨å•çŠ¶æ€ç®¡ç†

#### æ ·å¼ä¸åŠ¨ç”»
- **Tailwind CSS 3.3.3**ï¼šåŸå­åŒ–CSSæ¡†æ¶
- **Framer Motion**ï¼šåŠ¨ç”»åº“
- **Class Variance Authority**ï¼šæ ·å¼å˜ä½“ç®¡ç†

#### å·¥å…·åº“
- **Day.js**ï¼šæ—¥æœŸå¤„ç†
- **React Hot Toast**ï¼šé€šçŸ¥ç»„ä»¶
- **js-cookie**ï¼šCookieç®¡ç†

### 2.2 ç»„ä»¶ç»“æ„å›¾

```mermaid
graph TD
    A[App] --> B[Layout]
    B --> C[Header]
    B --> D[Sidebar]
    B --> E[Main Content]
    
    C --> C1[UserMenu]
    C --> C2[ThemeToggle]
    C --> C3[NotificationBell]
    
    D --> D1[Navigation]
    D --> D2[UserInfo]
    
    E --> E1[Dashboard]
    E --> E2[Applications]
    E --> E3[Licenses]
    E --> E4[Users]
    E --> E5[Security]
    
    E1 --> E1A[StatsCards]
    E1 --> E1B[Charts]
    E1 --> E1C[RecentActivities]
    
    E2 --> E2A[ApplicationList]
    E2 --> E2B[ApplicationForm]
    E2 --> E2C[ApplicationStats]
    
    E3 --> E3A[LicenseList]
    E3 --> E3B[LicenseGenerate]
    E3 --> E3C[LicenseActivations]
    
    F[Common Components] --> F1[Button]
    F[Common Components] --> F2[Input]
    F[Common Components] --> F3[Modal]
    F[Common Components] --> F4[Table]
    F[Common Components] --> F5[Form]
```

### 2.3 è·¯ç”±é…ç½®

#### ä¸»è¦è·¯ç”±ç»“æ„

```typescript
// pages/è·¯ç”±æ˜ å°„
const routes = {
  // è®¤è¯ç›¸å…³
  '/login': 'pages/login.tsx',
  '/change-password': 'pages/change-password/index.tsx',
  
  // ä¸»è¦åŠŸèƒ½æ¨¡å—
  '/dashboard': 'pages/dashboard.tsx',
  '/applications': 'pages/applications/index.tsx',
  '/applications/[id]': 'pages/applications/[id].tsx',
  '/applications/stats': 'pages/applications/stats.tsx',
  '/applications/monitoring': 'pages/applications/monitoring.tsx',
  
  '/licenses': 'pages/licenses/index.tsx',
  '/licenses/generate': 'pages/licenses/generate.tsx',
  '/licenses/expiring': 'pages/licenses/expiring.tsx',
  '/licenses/activations': 'pages/licenses/activations.tsx',
  
  '/users': 'pages/users/index.tsx',
  '/users/roles': 'pages/users/roles.tsx',
  '/users/logs': 'pages/users/logs.tsx',
  
  '/security': 'pages/security/index.tsx',
  '/security/logs': 'pages/security/logs.tsx',
  '/security/alerts': 'pages/security/alerts.tsx',
  '/security/enhanced': 'pages/security/enhanced.tsx',
  
  // ç³»ç»ŸåŠŸèƒ½
  '/settings': 'pages/settings/index.tsx',
  '/extensions': 'pages/extensions/index.tsx',
  '/monitoring': 'pages/monitoring/index.tsx',
  '/audit': 'pages/audit/index.tsx',
  '/backup': 'pages/backup/index.tsx'
};
```

#### è·¯ç”±å®ˆå«

```typescript
// lib/auth-guard.ts
const authGuard = {
  // å…¬å¼€è·¯ç”±ï¼ˆæ— éœ€è®¤è¯ï¼‰
  publicRoutes: ['/login', '/404'],
  
  // éœ€è¦è®¤è¯çš„è·¯ç”±
  protectedRoutes: ['*'],
  
  // è§’è‰²æƒé™æ˜ å°„
  roleBasedRoutes: {
    super_admin: ['*'],
    admin: ['/dashboard', '/applications', '/licenses', '/users', '/extensions'],
    user: ['/dashboard', '/profile']
  }
};
```

### 2.4 çŠ¶æ€ç®¡ç†æ–¹æ¡ˆ

#### å…¨å±€çŠ¶æ€ç®¡ç†

```typescript
// lib/store.ts - ä½¿ç”¨Context + useReducer
interface GlobalState {
  user: UserInfo | null;
  theme: 'light' | 'dark' | 'system';
  notifications: Notification[];
  loading: boolean;
}

const initialState: GlobalState = {
  user: null,
  theme: 'system',
  notifications: [],
  loading: false
};

// Actions
type Action = 
  | { type: 'SET_USER'; payload: UserInfo }
  | { type: 'SET_THEME'; payload: 'light' | 'dark' | 'system' }
  | { type: 'ADD_NOTIFICATION'; payload: Notification }
  | { type: 'SET_LOADING'; payload: boolean };
```

#### æ•°æ®è·å–ç­–ç•¥

```typescript
// hooks/useApiWithRetry.ts
const useApiWithRetry = <T>(url: string, options?: RequestOptions) => {
  const { data, error, mutate } = useSWR<T>(
    url,
    (url) => api.get(url).then(res => res.data),
    {
      revalidateOnFocus: false,
      revalidateOnReconnect: true,
      errorRetryCount: 3,
      errorRetryInterval: 1000,
      ...options
    }
  );
  
  return {
    data,
    loading: !error && !data,
    error,
    mutate
  };
};
```

### 2.6 åº”ç”¨å…¬å‘Šæ¨¡å—å®ç°

#### 2.6.1 å‰ç«¯ç»„ä»¶è®¾è®¡

##### å…¬å‘ŠçŠ¶æ€ç®¡ç†

```typescript
// stores/announcementStore.ts
import { create } from 'zustand';
import { persist } from 'zustand/middleware';

interface Announcement {
  id: string;
  title: string;
  content: string;
  type: 'info' | 'warning' | 'error' | 'success';
  priority: 'low' | 'medium' | 'high' | 'urgent';
  targetType: 'all' | 'application' | 'license_rule' | 'user_role';
  targetIds: string[];
  displayType: 'popup' | 'banner' | 'notification';
  isForceRead: boolean;
  startTime: string;
  endTime: string;
  attachments?: {
    name: string;
    url: string;
    size: number;
  }[];
  createdBy: string;
  createdAt: string;
  updatedAt: string;
  status: 'draft' | 'published' | 'expired' | 'deleted';
  readCount: number;
  totalTargets: number;
}

interface AnnouncementState {
  announcements: Announcement[];
  unreadCount: number;
  currentAnnouncement: Announcement | null;
  loading: boolean;
  
  // Actions
  fetchAnnouncements: () => Promise<void>;
  markAsRead: (id: string) => Promise<void>;
  createAnnouncement: (data: Partial<Announcement>) => Promise<void>;
  updateAnnouncement: (id: string, data: Partial<Announcement>) => Promise<void>;
  deleteAnnouncement: (id: string) => Promise<void>;
  setCurrentAnnouncement: (announcement: Announcement | null) => void;
}

export const useAnnouncementStore = create<AnnouncementState>()(
  persist(
    (set, get) => ({
      announcements: [],
      unreadCount: 0,
      currentAnnouncement: null,
      loading: false,
      
      fetchAnnouncements: async () => {
        set({ loading: true });
        try {
          const response = await api.get('/announcements');
          const announcements = response.data.data;
          const unreadCount = announcements.filter(
            (a: Announcement) => !localStorage.getItem(`announcement_read_${a.id}`)
          ).length;
          
          set({ announcements, unreadCount, loading: false });
        } catch (error) {
          console.error('Failed to fetch announcements:', error);
          set({ loading: false });
        }
      },
      
      markAsRead: async (id: string) => {
        try {
          await api.post(`/announcements/${id}/read`);
          localStorage.setItem(`announcement_read_${id}`, 'true');
          
          const { announcements, unreadCount } = get();
          set({ unreadCount: Math.max(0, unreadCount - 1) });
        } catch (error) {
          console.error('Failed to mark announcement as read:', error);
        }
      },
      
      createAnnouncement: async (data) => {
        set({ loading: true });
        try {
          await api.post('/announcements', data);
          await get().fetchAnnouncements();
        } catch (error) {
          console.error('Failed to create announcement:', error);
          set({ loading: false });
        }
      },
      
      updateAnnouncement: async (id, data) => {
        set({ loading: true });
        try {
          await api.put(`/announcements/${id}`, data);
          await get().fetchAnnouncements();
        } catch (error) {
          console.error('Failed to update announcement:', error);
          set({ loading: false });
        }
      },
      
      deleteAnnouncement: async (id) => {
        try {
          await api.delete(`/announcements/${id}`);
          const { announcements } = get();
          set({ 
            announcements: announcements.filter(a => a.id !== id)
          });
        } catch (error) {
          console.error('Failed to delete announcement:', error);
        }
      },
      
      setCurrentAnnouncement: (announcement) => {
        set({ currentAnnouncement: announcement });
      }
    }),
    {
      name: 'announcement-store',
      partialize: (state) => ({ unreadCount: state.unreadCount })
    }
  )
);
```

##### å…¬å‘Šåˆ—è¡¨ç»„ä»¶

```typescript
// components/announcements/AnnouncementList.tsx
import React, { useEffect, useState } from 'react';
import { useAnnouncementStore } from '@/stores/announcementStore';
import { Card, Badge, Button, Modal, Typography, Space, Tag, Tooltip } from 'antd';
import { BellOutlined, EyeOutlined, EditOutlined, DeleteOutlined } from '@ant-design/icons';
import { formatDistanceToNow } from 'date-fns';
import { zhCN } from 'date-fns/locale';

const { Title, Paragraph } = Typography;

interface AnnouncementListProps {
  showActions?: boolean;
  limit?: number;
}

export const AnnouncementList: React.FC<AnnouncementListProps> = ({ 
  showActions = false, 
  limit 
}) => {
  const { 
    announcements, 
    loading, 
    fetchAnnouncements, 
    markAsRead, 
    deleteAnnouncement,
    setCurrentAnnouncement 
  } = useAnnouncementStore();
  
  const [selectedAnnouncement, setSelectedAnnouncement] = useState<Announcement | null>(null);
  const [detailModalVisible, setDetailModalVisible] = useState(false);
  
  useEffect(() => {
    fetchAnnouncements();
  }, []);
  
  const displayAnnouncements = limit ? announcements.slice(0, limit) : announcements;
  
  const handleViewDetail = (announcement: Announcement) => {
    setSelectedAnnouncement(announcement);
    setDetailModalVisible(true);
    markAsRead(announcement.id);
  };
  
  const handleDelete = async (id: string) => {
    Modal.confirm({
      title: 'ç¡®è®¤åˆ é™¤',
      content: 'ç¡®å®šè¦åˆ é™¤è¿™æ¡å…¬å‘Šå—ï¼Ÿæ­¤æ“ä½œä¸å¯æ’¤é”€ã€‚',
      onOk: () => deleteAnnouncement(id)
    });
  };
  
  const getPriorityColor = (priority: string) => {
    const colors = {
      low: 'default',
      medium: 'blue',
      high: 'orange',
      urgent: 'red'
    };
    return colors[priority as keyof typeof colors] || 'default';
  };
  
  const getTypeIcon = (type: string) => {
    const icons = {
      info: 'ğŸ“¢',
      warning: 'âš ï¸',
      error: 'âŒ',
      success: 'âœ…'
    };
    return icons[type as keyof typeof icons] || 'ğŸ“¢';
  };
  
  return (
    <div className="announcement-list">
      <Space direction="vertical" size="middle" style={{ width: '100%' }}>
        {displayAnnouncements.map((announcement) => {
          const isRead = localStorage.getItem(`announcement_read_${announcement.id}`);
          
          return (
            <Card
              key={announcement.id}
              className={`announcement-card ${!isRead ? 'unread' : ''}`}
              size="small"
              hoverable
              actions={showActions ? [
                <Tooltip title="æŸ¥çœ‹è¯¦æƒ…">
                  <EyeOutlined onClick={() => handleViewDetail(announcement)} />
                </Tooltip>,
                <Tooltip title="ç¼–è¾‘">
                  <EditOutlined onClick={() => setCurrentAnnouncement(announcement)} />
                </Tooltip>,
                <Tooltip title="åˆ é™¤">
                  <DeleteOutlined onClick={() => handleDelete(announcement.id)} />
                </Tooltip>
              ] : [
                <Button 
                  type="link" 
                  size="small" 
                  onClick={() => handleViewDetail(announcement)}
                >
                  æŸ¥çœ‹è¯¦æƒ…
                </Button>
              ]}
            >
              <div className="announcement-header">
                <Space>
                  <span className="type-icon">{getTypeIcon(announcement.type)}</span>
                  <Title level={5} style={{ margin: 0 }}>
                    {announcement.title}
                  </Title>
                  {!isRead && <Badge status="processing" />}
                </Space>
                <Space>
                  <Tag color={getPriorityColor(announcement.priority)}>
                    {announcement.priority.toUpperCase()}
                  </Tag>
                  <span className="time">
                    {formatDistanceToNow(new Date(announcement.createdAt), {
                      addSuffix: true,
                      locale: zhCN
                    })}
                  </span>
                </Space>
              </div>
              
              <Paragraph 
                ellipsis={{ rows: 2, expandable: false }}
                style={{ margin: '8px 0 0 0', color: '#666' }}
              >
                {announcement.content.replace(/<[^>]*>/g, '')}
              </Paragraph>
              
              {announcement.attachments && announcement.attachments.length > 0 && (
                <div className="attachments">
                  <Space size="small">
                    ğŸ“
                    {announcement.attachments.map((file, index) => (
                      <Tag key={index} size="small">{file.name}</Tag>
                    ))}
                  </Space>
                </div>
              )}
            </Card>
          );
        })}
      </Space>
      
      {/* å…¬å‘Šè¯¦æƒ…å¼¹çª— */}
      <Modal
        title={selectedAnnouncement?.title}
        open={detailModalVisible}
        onCancel={() => setDetailModalVisible(false)}
        footer={[
          <Button key="close" onClick={() => setDetailModalVisible(false)}>
            å…³é—­
          </Button>
        ]}
        width={800}
      >
        {selectedAnnouncement && (
          <AnnouncementDetail announcement={selectedAnnouncement} />
        )}
      </Modal>
    </div>
  );
};
```

##### å…¬å‘Šåˆ›å»º/ç¼–è¾‘ç»„ä»¶

```typescript
// components/announcements/AnnouncementForm.tsx
import React, { useState, useEffect } from 'react';
import { 
  Form, 
  Input, 
  Select, 
  DatePicker, 
  Switch, 
  Upload, 
  Button, 
  Card,
  Space,
  message,
  Row,
  Col
} from 'antd';
import { UploadOutlined, PlusOutlined } from '@ant-design/icons';
import { useAnnouncementStore } from '@/stores/announcementStore';
import ReactQuill from 'react-quill';
import 'react-quill/dist/quill.snow.css';
import dayjs from 'dayjs';

const { Option } = Select;
const { RangePicker } = DatePicker;

interface AnnouncementFormProps {
  announcement?: Announcement;
  onSuccess?: () => void;
  onCancel?: () => void;
}

export const AnnouncementForm: React.FC<AnnouncementFormProps> = ({
  announcement,
  onSuccess,
  onCancel
}) => {
  const [form] = Form.useForm();
  const { createAnnouncement, updateAnnouncement, loading } = useAnnouncementStore();
  const [content, setContent] = useState('');
  const [fileList, setFileList] = useState<any[]>([]);
  
  useEffect(() => {
    if (announcement) {
      form.setFieldsValue({
        ...announcement,
        timeRange: [dayjs(announcement.startTime), dayjs(announcement.endTime)],
        targetIds: announcement.targetIds
      });
      setContent(announcement.content);
      setFileList(announcement.attachments?.map((file, index) => ({
        uid: index,
        name: file.name,
        status: 'done',
        url: file.url
      })) || []);
    }
  }, [announcement, form]);
  
  const handleSubmit = async (values: any) => {
    try {
      const formData = {
        ...values,
        content,
        startTime: values.timeRange[0].toISOString(),
        endTime: values.timeRange[1].toISOString(),
        attachments: fileList.map(file => ({
          name: file.name,
          url: file.url || file.response?.url,
          size: file.size
        }))
      };
      
      if (announcement) {
        await updateAnnouncement(announcement.id, formData);
        message.success('å…¬å‘Šæ›´æ–°æˆåŠŸ');
      } else {
        await createAnnouncement(formData);
        message.success('å…¬å‘Šåˆ›å»ºæˆåŠŸ');
      }
      
      onSuccess?.();
    } catch (error) {
      message.error('æ“ä½œå¤±è´¥ï¼Œè¯·é‡è¯•');
    }
  };
  
  const uploadProps = {
    name: 'file',
    action: '/api/upload',
    headers: {
      authorization: `Bearer ${localStorage.getItem('token')}`
    },
    fileList,
    onChange: ({ fileList }: any) => setFileList(fileList),
    beforeUpload: (file: File) => {
      const isValidType = ['application/pdf', 'application/msword', 
        'application/vnd.openxmlformats-officedocument.wordprocessingml.document'
      ].includes(file.type);
      
      if (!isValidType) {
        message.error('åªæ”¯æŒ PDF å’Œ Word æ–‡æ¡£ï¼');
        return false;
      }
      
      const isLt10M = file.size / 1024 / 1024 < 10;
      if (!isLt10M) {
        message.error('æ–‡ä»¶å¤§å°ä¸èƒ½è¶…è¿‡ 10MBï¼');
        return false;
      }
      
      return true;
    }
  };
  
  return (
    <Card title={announcement ? 'ç¼–è¾‘å…¬å‘Š' : 'åˆ›å»ºå…¬å‘Š'}>
      <Form
        form={form}
        layout="vertical"
        onFinish={handleSubmit}
        initialValues={{
          type: 'info',
          priority: 'medium',
          targetType: 'all',
          displayType: 'banner',
          isForceRead: false
        }}
      >
        <Row gutter={16}>
          <Col span={12}>
            <Form.Item
              name="title"
              label="å…¬å‘Šæ ‡é¢˜"
              rules={[
                { required: true, message: 'è¯·è¾“å…¥å…¬å‘Šæ ‡é¢˜' },
                { max: 50, message: 'æ ‡é¢˜ä¸èƒ½è¶…è¿‡50ä¸ªå­—ç¬¦' }
              ]}
            >
              <Input placeholder="è¯·è¾“å…¥å…¬å‘Šæ ‡é¢˜" />
            </Form.Item>
          </Col>
          
          <Col span={6}>
            <Form.Item name="type" label="å…¬å‘Šç±»å‹">
              <Select>
                <Option value="info">ä¿¡æ¯</Option>
                <Option value="warning">è­¦å‘Š</Option>
                <Option value="error">é”™è¯¯</Option>
                <Option value="success">æˆåŠŸ</Option>
              </Select>
            </Form.Item>
          </Col>
          
          <Col span={6}>
            <Form.Item name="priority" label="ä¼˜å…ˆçº§">
              <Select>
                <Option value="low">ä½</Option>
                <Option value="medium">ä¸­</Option>
                <Option value="high">é«˜</Option>
                <Option value="urgent">ç´§æ€¥</Option>
              </Select>
            </Form.Item>
          </Col>
        </Row>
        
        <Form.Item label="å…¬å‘Šå†…å®¹">
          <ReactQuill
            value={content}
            onChange={setContent}
            modules={{
              toolbar: [
                [{ 'header': [1, 2, 3, false] }],
                ['bold', 'italic', 'underline', 'strike'],
                [{ 'list': 'ordered'}, { 'list': 'bullet' }],
                ['link', 'image'],
                ['clean']
              ]
            }}
            style={{ height: '200px', marginBottom: '50px' }}
          />
        </Form.Item>
        
        <Row gutter={16}>
          <Col span={8}>
            <Form.Item name="targetType" label="å‘å¸ƒèŒƒå›´">
              <Select>
                <Option value="all">å…¨éƒ¨ç”¨æˆ·</Option>
                <Option value="application">æŒ‡å®šåº”ç”¨</Option>
                <Option value="license_rule">æŒ‡å®šå¡å¯†è§„åˆ™</Option>
                <Option value="user_role">æŒ‡å®šç”¨æˆ·è§’è‰²</Option>
              </Select>
            </Form.Item>
          </Col>
          
          <Col span={8}>
            <Form.Item name="displayType" label="å±•ç¤ºæ–¹å¼">
              <Select>
                <Option value="popup">å¼¹çª—</Option>
                <Option value="banner">æ¨ªå¹…</Option>
                <Option value="notification">é€šçŸ¥</Option>
              </Select>
            </Form.Item>
          </Col>
          
          <Col span={8}>
            <Form.Item name="isForceRead" label="å¼ºåˆ¶é˜…è¯»" valuePropName="checked">
              <Switch />
            </Form.Item>
          </Col>
        </Row>
        
        <Form.Item
          name="timeRange"
          label="ç”Ÿæ•ˆæ—¶é—´"
          rules={[{ required: true, message: 'è¯·é€‰æ‹©ç”Ÿæ•ˆæ—¶é—´èŒƒå›´' }]}
        >
          <RangePicker 
            showTime 
            format="YYYY-MM-DD HH:mm:ss"
            style={{ width: '100%' }}
          />
        </Form.Item>
        
        <Form.Item label="é™„ä»¶">
          <Upload {...uploadProps} maxCount={3}>
            <Button icon={<UploadOutlined />}>ä¸Šä¼ é™„ä»¶</Button>
          </Upload>
          <div style={{ color: '#999', fontSize: '12px', marginTop: '4px' }}>
            æ”¯æŒ PDFã€Word æ–‡æ¡£ï¼Œæœ€å¤š3ä¸ªæ–‡ä»¶ï¼Œæ¯ä¸ªæ–‡ä»¶ä¸è¶…è¿‡10MB
          </div>
        </Form.Item>
        
        <Form.Item>
          <Space>
            <Button type="primary" htmlType="submit" loading={loading}>
              {announcement ? 'æ›´æ–°' : 'åˆ›å»º'}
            </Button>
            <Button onClick={onCancel}>
              å–æ¶ˆ
            </Button>
          </Space>
        </Form.Item>
      </Form>
    </Card>
  );
};
```

#### 2.6.2 åç«¯APIæ¥å£è®¾è®¡

##### å…¬å‘Šç®¡ç†æ¥å£

```python
# routers/announcements.py
from fastapi import APIRouter, Depends, HTTPException, Query, UploadFile, File
from sqlalchemy.orm import Session
from typing import List, Optional
from datetime import datetime
import uuid

router = APIRouter(prefix="/announcements", tags=["announcements"])

# æ•°æ®æ¨¡å‹
class AnnouncementCreate(BaseModel):
    title: str = Field(..., max_length=50, description="å…¬å‘Šæ ‡é¢˜")
    content: str = Field(..., description="å…¬å‘Šå†…å®¹")
    type: str = Field(default="info", regex="^(info|warning|error|success)$")
    priority: str = Field(default="medium", regex="^(low|medium|high|urgent)$")
    target_type: str = Field(default="all", regex="^(all|application|license_rule|user_role)$")
    target_ids: List[str] = Field(default=[], description="ç›®æ ‡IDåˆ—è¡¨")
    display_type: str = Field(default="banner", regex="^(popup|banner|notification)$")
    is_force_read: bool = Field(default=False, description="æ˜¯å¦å¼ºåˆ¶é˜…è¯»")
    start_time: datetime = Field(..., description="ç”Ÿæ•ˆæ—¶é—´")
    end_time: datetime = Field(..., description="è¿‡æœŸæ—¶é—´")
    attachments: List[dict] = Field(default=[], description="é™„ä»¶åˆ—è¡¨")

class AnnouncementUpdate(BaseModel):
    title: Optional[str] = Field(None, max_length=50)
    content: Optional[str] = None
    type: Optional[str] = Field(None, regex="^(info|warning|error|success)$")
    priority: Optional[str] = Field(None, regex="^(low|medium|high|urgent)$")
    target_type: Optional[str] = Field(None, regex="^(all|application|license_rule|user_role)$")
    target_ids: Optional[List[str]] = None
    display_type: Optional[str] = Field(None, regex="^(popup|banner|notification)$")
    is_force_read: Optional[bool] = None
    start_time: Optional[datetime] = None
    end_time: Optional[datetime] = None
    status: Optional[str] = Field(None, regex="^(draft|published|expired|deleted)$")

class AnnouncementResponse(BaseModel):
    id: str
    title: str
    content: str
    type: str
    priority: str
    target_type: str
    target_ids: List[str]
    display_type: str
    is_force_read: bool
    start_time: datetime
    end_time: datetime
    attachments: List[dict]
    created_by: str
    created_at: datetime
    updated_at: datetime
    status: str
    read_count: int
    total_targets: int

@router.get("/", response_model=List[AnnouncementResponse])
async def get_announcements(
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user),
    status: Optional[str] = Query(None, regex="^(draft|published|expired|deleted)$"),
    type: Optional[str] = Query(None, regex="^(info|warning|error|success)$"),
    priority: Optional[str] = Query(None, regex="^(low|medium|high|urgent)$"),
    page: int = Query(1, ge=1),
    size: int = Query(20, ge=1, le=100)
):
    """
    è·å–å…¬å‘Šåˆ—è¡¨
    - æ”¯æŒæŒ‰çŠ¶æ€ã€ç±»å‹ã€ä¼˜å…ˆçº§ç­›é€‰
    - æ”¯æŒåˆ†é¡µæŸ¥è¯¢
    - æ™®é€šç”¨æˆ·åªèƒ½çœ‹åˆ°é’ˆå¯¹è‡ªå·±çš„æœ‰æ•ˆå…¬å‘Š
    - ç®¡ç†å‘˜å¯ä»¥çœ‹åˆ°æ‰€æœ‰å…¬å‘Š
    """
    try:
        query = db.query(Announcement)
        
        # æƒé™è¿‡æ»¤
        if current_user.role not in ['super_admin', 'admin']:
            # æ™®é€šç”¨æˆ·åªèƒ½çœ‹åˆ°é’ˆå¯¹è‡ªå·±çš„æœ‰æ•ˆå…¬å‘Š
            now = datetime.utcnow()
            query = query.filter(
                and_(
                    Announcement.status == 'published',
                    Announcement.start_time <= now,
                    Announcement.end_time >= now,
                    or_(
                        Announcement.target_type == 'all',
                        and_(
                            Announcement.target_type == 'user_role',
                            Announcement.target_ids.contains([current_user.role])
                        ),
                        and_(
                            Announcement.target_type == 'application',
                            # æ ¹æ®ç”¨æˆ·çš„åº”ç”¨æƒé™è¿‡æ»¤
                        )
                    )
                )
            )
        
        # æ¡ä»¶è¿‡æ»¤
        if status:
            query = query.filter(Announcement.status == status)
        if type:
            query = query.filter(Announcement.type == type)
        if priority:
            query = query.filter(Announcement.priority == priority)
        
        # åˆ†é¡µ
        total = query.count()
        announcements = query.offset((page - 1) * size).limit(size).all()
        
        # è®¡ç®—é˜…è¯»ç»Ÿè®¡
        result = []
        for announcement in announcements:
            read_count = db.query(AnnouncementRead).filter(
                AnnouncementRead.announcement_id == announcement.id
            ).count()
            
            total_targets = calculate_target_count(db, announcement)
            
            result.append(AnnouncementResponse(
                **announcement.__dict__,
                read_count=read_count,
                total_targets=total_targets
            ))
        
        return {
            "data": result,
            "total": total,
            "page": page,
            "size": size
        }
        
    except Exception as e:
        logger.error(f"Failed to get announcements: {str(e)}")
        raise HTTPException(status_code=500, detail="è·å–å…¬å‘Šåˆ—è¡¨å¤±è´¥")

@router.post("/", response_model=AnnouncementResponse)
async def create_announcement(
    announcement: AnnouncementCreate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    åˆ›å»ºå…¬å‘Š
    - åªæœ‰ç®¡ç†å‘˜å¯ä»¥åˆ›å»ºå…¬å‘Š
    - è‡ªåŠ¨è¿›è¡Œæ•æ„Ÿè¯æ£€æµ‹
    - éªŒè¯ç›®æ ‡ç”¨æˆ·/åº”ç”¨çš„æœ‰æ•ˆæ€§
    """
    # æƒé™æ£€æŸ¥
    if current_user.role not in ['super_admin', 'admin']:
        raise HTTPException(status_code=403, detail="æƒé™ä¸è¶³")
    
    try:
        # æ•æ„Ÿè¯æ£€æµ‹
        if contains_sensitive_words(announcement.title) or contains_sensitive_words(announcement.content):
            raise HTTPException(status_code=400, detail="å†…å®¹åŒ…å«æ•æ„Ÿè¯ï¼Œè¯·ä¿®æ”¹åé‡è¯•")
        
        # éªŒè¯æ—¶é—´èŒƒå›´
        if announcement.start_time >= announcement.end_time:
            raise HTTPException(status_code=400, detail="ç”Ÿæ•ˆæ—¶é—´å¿…é¡»æ—©äºè¿‡æœŸæ—¶é—´")
        
        # éªŒè¯ç›®æ ‡IDçš„æœ‰æ•ˆæ€§
        if announcement.target_type != 'all' and announcement.target_ids:
            validate_target_ids(db, announcement.target_type, announcement.target_ids)
        
        # åˆ›å»ºå…¬å‘Š
        db_announcement = Announcement(
            id=str(uuid.uuid4()),
            **announcement.dict(),
            created_by=current_user.id,
            created_at=datetime.utcnow(),
            updated_at=datetime.utcnow(),
            status='published'
        )
        
        db.add(db_announcement)
        db.commit()
        db.refresh(db_announcement)
        
        # è§¦å‘æ¨é€äº‹ä»¶
        await trigger_announcement_push(db_announcement)
        
        # è®°å½•æ“ä½œæ—¥å¿—
        log_operation(
            db, current_user.id, 
            "CREATE_ANNOUNCEMENT", 
            f"åˆ›å»ºå…¬å‘Š: {announcement.title}",
            {"announcement_id": db_announcement.id}
        )
        
        return AnnouncementResponse(
            **db_announcement.__dict__,
            read_count=0,
            total_targets=calculate_target_count(db, db_announcement)
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to create announcement: {str(e)}")
        db.rollback()
        raise HTTPException(status_code=500, detail="åˆ›å»ºå…¬å‘Šå¤±è´¥")

@router.put("/{announcement_id}", response_model=AnnouncementResponse)
async def update_announcement(
    announcement_id: str,
    announcement: AnnouncementUpdate,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    æ›´æ–°å…¬å‘Š
    - åªæœ‰ç®¡ç†å‘˜å’Œå…¬å‘Šåˆ›å»ºè€…å¯ä»¥æ›´æ–°
    - å·²å‘å¸ƒçš„å…¬å‘Šä¿®æ”¹åéœ€è¦é‡æ–°å®¡æ ¸
    """
    # æƒé™æ£€æŸ¥
    if current_user.role not in ['super_admin', 'admin']:
        raise HTTPException(status_code=403, detail="æƒé™ä¸è¶³")
    
    try:
        db_announcement = db.query(Announcement).filter(
            Announcement.id == announcement_id
        ).first()
        
        if not db_announcement:
            raise HTTPException(status_code=404, detail="å…¬å‘Šä¸å­˜åœ¨")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æƒé™ä¿®æ”¹
        if (current_user.role != 'super_admin' and 
            db_announcement.created_by != current_user.id):
            raise HTTPException(status_code=403, detail="åªèƒ½ä¿®æ”¹è‡ªå·±åˆ›å»ºçš„å…¬å‘Š")
        
        # æ›´æ–°å­—æ®µ
        update_data = announcement.dict(exclude_unset=True)
        if update_data:
            # æ•æ„Ÿè¯æ£€æµ‹
            if 'title' in update_data and contains_sensitive_words(update_data['title']):
                raise HTTPException(status_code=400, detail="æ ‡é¢˜åŒ…å«æ•æ„Ÿè¯")
            if 'content' in update_data and contains_sensitive_words(update_data['content']):
                raise HTTPException(status_code=400, detail="å†…å®¹åŒ…å«æ•æ„Ÿè¯")
            
            # éªŒè¯æ—¶é—´èŒƒå›´
            start_time = update_data.get('start_time', db_announcement.start_time)
            end_time = update_data.get('end_time', db_announcement.end_time)
            if start_time >= end_time:
                raise HTTPException(status_code=400, detail="ç”Ÿæ•ˆæ—¶é—´å¿…é¡»æ—©äºè¿‡æœŸæ—¶é—´")
            
            for field, value in update_data.items():
                setattr(db_announcement, field, value)
            
            db_announcement.updated_at = datetime.utcnow()
            
            db.commit()
            db.refresh(db_announcement)
        
        # è®°å½•æ“ä½œæ—¥å¿—
        log_operation(
            db, current_user.id,
            "UPDATE_ANNOUNCEMENT",
            f"æ›´æ–°å…¬å‘Š: {db_announcement.title}",
            {"announcement_id": announcement_id, "changes": update_data}
        )
        
        return AnnouncementResponse(
            **db_announcement.__dict__,
            read_count=db.query(AnnouncementRead).filter(
                AnnouncementRead.announcement_id == announcement_id
            ).count(),
            total_targets=calculate_target_count(db, db_announcement)
        )
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to update announcement: {str(e)}")
        db.rollback()
        raise HTTPException(status_code=500, detail="æ›´æ–°å…¬å‘Šå¤±è´¥")

@router.post("/{announcement_id}/read")
async def mark_announcement_read(
    announcement_id: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    æ ‡è®°å…¬å‘Šä¸ºå·²è¯»
    """
    try:
        # æ£€æŸ¥å…¬å‘Šæ˜¯å¦å­˜åœ¨
        announcement = db.query(Announcement).filter(
            Announcement.id == announcement_id
        ).first()
        
        if not announcement:
            raise HTTPException(status_code=404, detail="å…¬å‘Šä¸å­˜åœ¨")
        
        # æ£€æŸ¥æ˜¯å¦å·²è¯»
        existing_read = db.query(AnnouncementRead).filter(
            and_(
                AnnouncementRead.announcement_id == announcement_id,
                AnnouncementRead.user_id == current_user.id
            )
        ).first()
        
        if not existing_read:
            # åˆ›å»ºé˜…è¯»è®°å½•
            read_record = AnnouncementRead(
                id=str(uuid.uuid4()),
                announcement_id=announcement_id,
                user_id=current_user.id,
                read_at=datetime.utcnow()
            )
            db.add(read_record)
            db.commit()
        
        return {"message": "æ ‡è®°æˆåŠŸ"}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to mark announcement as read: {str(e)}")
        raise HTTPException(status_code=500, detail="æ ‡è®°å¤±è´¥")

@router.delete("/{announcement_id}")
async def delete_announcement(
    announcement_id: str,
    db: Session = Depends(get_db),
    current_user: User = Depends(get_current_user)
):
    """
    åˆ é™¤å…¬å‘Šï¼ˆè½¯åˆ é™¤ï¼‰
    """
    # æƒé™æ£€æŸ¥
    if current_user.role not in ['super_admin', 'admin']:
        raise HTTPException(status_code=403, detail="æƒé™ä¸è¶³")
    
    try:
        db_announcement = db.query(Announcement).filter(
            Announcement.id == announcement_id
        ).first()
        
        if not db_announcement:
            raise HTTPException(status_code=404, detail="å…¬å‘Šä¸å­˜åœ¨")
        
        # æ£€æŸ¥æƒé™
        if (current_user.role != 'super_admin' and 
            db_announcement.created_by != current_user.id):
            raise HTTPException(status_code=403, detail="åªèƒ½åˆ é™¤è‡ªå·±åˆ›å»ºçš„å…¬å‘Š")
        
        # è½¯åˆ é™¤
        db_announcement.status = 'deleted'
        db_announcement.updated_at = datetime.utcnow()
        
        db.commit()
        
        # è®°å½•æ“ä½œæ—¥å¿—
        log_operation(
            db, current_user.id,
            "DELETE_ANNOUNCEMENT",
            f"åˆ é™¤å…¬å‘Š: {db_announcement.title}",
            {"announcement_id": announcement_id}
        )
        
        return {"message": "åˆ é™¤æˆåŠŸ"}
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to delete announcement: {str(e)}")
        db.rollback()
        raise HTTPException(status_code=500, detail="åˆ é™¤å¤±è´¥")

# è¾…åŠ©å‡½æ•°
def calculate_target_count(db: Session, announcement: Announcement) -> int:
    """è®¡ç®—å…¬å‘Šç›®æ ‡ç”¨æˆ·æ•°é‡"""
    if announcement.target_type == 'all':
        return db.query(User).filter(User.status == 'active').count()
    elif announcement.target_type == 'user_role':
        return db.query(User).filter(
            and_(
                User.role.in_(announcement.target_ids),
                User.status == 'active'
            )
        ).count()
    elif announcement.target_type == 'application':
        # è®¡ç®—ä½¿ç”¨æŒ‡å®šåº”ç”¨çš„ç”¨æˆ·æ•°
        return db.query(User).join(UserLicenseBind).join(LicenseCode).filter(
            and_(
                LicenseCode.application_id.in_(announcement.target_ids),
                User.status == 'active'
            )
        ).distinct().count()
    elif announcement.target_type == 'license_rule':
        # è®¡ç®—ä½¿ç”¨æŒ‡å®šå¡å¯†è§„åˆ™çš„ç”¨æˆ·æ•°
        return db.query(User).join(UserLicenseBind).join(LicenseCode).filter(
            and_(
                LicenseCode.rule_id.in_(announcement.target_ids),
                User.status == 'active'
            )
        ).distinct().count()
    
    return 0

def validate_target_ids(db: Session, target_type: str, target_ids: List[str]):
    """éªŒè¯ç›®æ ‡IDçš„æœ‰æ•ˆæ€§"""
    if target_type == 'application':
        valid_count = db.query(Application).filter(
            Application.id.in_(target_ids)
        ).count()
        if valid_count != len(target_ids):
            raise HTTPException(status_code=400, detail="éƒ¨åˆ†åº”ç”¨IDæ— æ•ˆ")
    elif target_type == 'license_rule':
        valid_count = db.query(LicenseRule).filter(
            LicenseRule.id.in_(target_ids)
        ).count()
        if valid_count != len(target_ids):
            raise HTTPException(status_code=400, detail="éƒ¨åˆ†å¡å¯†è§„åˆ™IDæ— æ•ˆ")
    elif target_type == 'user_role':
        valid_roles = ['super_admin', 'admin', 'user']
        invalid_roles = [role for role in target_ids if role not in valid_roles]
        if invalid_roles:
            raise HTTPException(status_code=400, detail=f"æ— æ•ˆçš„ç”¨æˆ·è§’è‰²: {invalid_roles}")

def contains_sensitive_words(text: str) -> bool:
    """æ•æ„Ÿè¯æ£€æµ‹"""
    # è¿™é‡Œå¯ä»¥é›†æˆç¬¬ä¸‰æ–¹æ•æ„Ÿè¯æ£€æµ‹æœåŠ¡
    sensitive_words = ['æ•æ„Ÿè¯1', 'æ•æ„Ÿè¯2']  # ç¤ºä¾‹
    return any(word in text for word in sensitive_words)

async def trigger_announcement_push(announcement: Announcement):
    """è§¦å‘å…¬å‘Šæ¨é€"""
    # å‘å¸ƒäº‹ä»¶åˆ°æ¶ˆæ¯é˜Ÿåˆ—
    event_data = {
        "type": "announcement_published",
        "announcement_id": announcement.id,
        "target_type": announcement.target_type,
        "target_ids": announcement.target_ids,
        "display_type": announcement.display_type,
        "priority": announcement.priority
    }
    
    await publish_event("announcement.published", event_data)
```

#### 2.6.3 æ•°æ®åº“è¡¨ç»“æ„è®¾è®¡

```sql
-- å…¬å‘Šè¡¨
CREATE TABLE announcements (
    id VARCHAR(36) PRIMARY KEY,
    title VARCHAR(50) NOT NULL COMMENT 'å…¬å‘Šæ ‡é¢˜',
    content TEXT NOT NULL COMMENT 'å…¬å‘Šå†…å®¹ï¼ˆæ”¯æŒHTMLï¼‰',
    type ENUM('info', 'warning', 'error', 'success') DEFAULT 'info' COMMENT 'å…¬å‘Šç±»å‹',
    priority ENUM('low', 'medium', 'high', 'urgent') DEFAULT 'medium' COMMENT 'ä¼˜å…ˆçº§',
    target_type ENUM('all', 'application', 'license_rule', 'user_role') DEFAULT 'all' COMMENT 'ç›®æ ‡ç±»å‹',
    target_ids JSON COMMENT 'ç›®æ ‡IDåˆ—è¡¨',
    display_type ENUM('popup', 'banner', 'notification') DEFAULT 'banner' COMMENT 'å±•ç¤ºæ–¹å¼',
    is_force_read BOOLEAN DEFAULT FALSE COMMENT 'æ˜¯å¦å¼ºåˆ¶é˜…è¯»',
    start_time DATETIME NOT NULL COMMENT 'ç”Ÿæ•ˆæ—¶é—´',
    end_time DATETIME NOT NULL COMMENT 'è¿‡æœŸæ—¶é—´',
    attachments JSON COMMENT 'é™„ä»¶ä¿¡æ¯',
    created_by VARCHAR(36) NOT NULL COMMENT 'åˆ›å»ºè€…ID',
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æ›´æ–°æ—¶é—´',
    status ENUM('draft', 'published', 'expired', 'deleted') DEFAULT 'draft' COMMENT 'çŠ¶æ€',
    
    INDEX idx_status_time (status, start_time, end_time),
    INDEX idx_target_type (target_type),
    INDEX idx_priority (priority),
    INDEX idx_created_by (created_by),
    FOREIGN KEY (created_by) REFERENCES users(id) ON DELETE CASCADE
) COMMENT='å…¬å‘Šè¡¨';

-- å…¬å‘Šé˜…è¯»è®°å½•è¡¨
CREATE TABLE announcement_reads (
    id VARCHAR(36) PRIMARY KEY,
    announcement_id VARCHAR(36) NOT NULL COMMENT 'å…¬å‘ŠID',
    user_id VARCHAR(36) NOT NULL COMMENT 'ç”¨æˆ·ID',
    read_at DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT 'é˜…è¯»æ—¶é—´',
    
    UNIQUE KEY uk_announcement_user (announcement_id, user_id),
    INDEX idx_announcement_id (announcement_id),
    INDEX idx_user_id (user_id),
    INDEX idx_read_at (read_at),
    FOREIGN KEY (announcement_id) REFERENCES announcements(id) ON DELETE CASCADE,
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
) COMMENT='å…¬å‘Šé˜…è¯»è®°å½•è¡¨';

-- å®šå‘æ¨é€è®°å½•è¡¨
CREATE TABLE announcement_pushes (
    id VARCHAR(36) PRIMARY KEY,
    announcement_id VARCHAR(36) COMMENT 'å…¬å‘ŠIDï¼ˆå¯ä¸ºç©ºï¼Œç”¨äºè‡ªåŠ¨æ¨é€ï¼‰',
    user_id VARCHAR(36) NOT NULL COMMENT 'ç›®æ ‡ç”¨æˆ·ID',
    push_type ENUM('announcement', 'license_expiry', 'device_limit', 'auth_failure') NOT NULL COMMENT 'æ¨é€ç±»å‹',
    title VARCHAR(100) NOT NULL COMMENT 'æ¨é€æ ‡é¢˜',
    content TEXT NOT NULL COMMENT 'æ¨é€å†…å®¹',
    channels JSON NOT NULL COMMENT 'æ¨é€æ¸ é“ï¼ˆdesktop, web, emailï¼‰',
    status ENUM('pending', 'sent', 'delivered', 'read', 'failed') DEFAULT 'pending' COMMENT 'æ¨é€çŠ¶æ€',
    sent_at DATETIME COMMENT 'å‘é€æ—¶é—´',
    delivered_at DATETIME COMMENT 'é€è¾¾æ—¶é—´',
    read_at DATETIME COMMENT 'é˜…è¯»æ—¶é—´',
    error_message TEXT COMMENT 'é”™è¯¯ä¿¡æ¯',
    retry_count INT DEFAULT 0 COMMENT 'é‡è¯•æ¬¡æ•°',
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
    
    INDEX idx_user_status (user_id, status),
    INDEX idx_push_type (push_type),
    INDEX idx_announcement_id (announcement_id),
    INDEX idx_sent_at (sent_at),
    FOREIGN KEY (announcement_id) REFERENCES announcements(id) ON DELETE SET NULL,
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
) COMMENT='æ¨é€è®°å½•è¡¨';

-- åé¦ˆè¡¨
CREATE TABLE feedbacks (
    id VARCHAR(36) PRIMARY KEY,
    user_id VARCHAR(36) NOT NULL COMMENT 'åé¦ˆç”¨æˆ·ID',
    type ENUM('license_issue', 'login_issue', 'feature_request', 'bug_report', 'other') NOT NULL COMMENT 'åé¦ˆç±»å‹',
    priority ENUM('low', 'medium', 'high', 'urgent') DEFAULT 'medium' COMMENT 'ç´§æ€¥ç¨‹åº¦',
    title VARCHAR(100) NOT NULL COMMENT 'åé¦ˆæ ‡é¢˜',
    content TEXT NOT NULL COMMENT 'åé¦ˆå†…å®¹',
    attachments JSON COMMENT 'é™„ä»¶ä¿¡æ¯',
    related_announcement_id VARCHAR(36) COMMENT 'å…³è”å…¬å‘ŠID',
    related_license_id VARCHAR(36) COMMENT 'å…³è”å¡å¯†ID',
    related_application_id VARCHAR(36) COMMENT 'å…³è”åº”ç”¨ID',
    device_info JSON COMMENT 'è®¾å¤‡ä¿¡æ¯',
    assigned_to VARCHAR(36) COMMENT 'åˆ†é…ç»™çš„ç®¡ç†å‘˜ID',
    status ENUM('pending', 'processing', 'resolved', 'closed', 'escalated') DEFAULT 'pending' COMMENT 'å¤„ç†çŠ¶æ€',
    admin_reply TEXT COMMENT 'ç®¡ç†å‘˜å›å¤',
    resolved_at DATETIME COMMENT 'è§£å†³æ—¶é—´',
    created_at DATETIME DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
    updated_at DATETIME DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP COMMENT 'æ›´æ–°æ—¶é—´',
    
    INDEX idx_user_status (user_id, status),
    INDEX idx_type_priority (type, priority),
    INDEX idx_assigned_to (assigned_to),
    INDEX idx_created_at (created_at),
    FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE,
    FOREIGN KEY (related_announcement_id) REFERENCES announcements(id) ON DELETE SET NULL,
    FOREIGN KEY (related_license_id) REFERENCES license_codes(id) ON DELETE SET NULL,
    FOREIGN KEY (related_application_id) REFERENCES applications(id) ON DELETE SET NULL,
    FOREIGN KEY (assigned_to) REFERENCES users(id) ON DELETE SET NULL
) COMMENT='ç”¨æˆ·åé¦ˆè¡¨';
```

#### 2.6.4 æƒé™æ§åˆ¶è®¾è®¡

```python
# æƒé™æ§åˆ¶çŸ©é˜µ
ANNOUNCEMENT_PERMISSIONS = {
    'super_admin': {
        'create': True,
        'read': True,
        'update': True,
        'delete': True,
        'manage_all': True,
        'view_statistics': True
    },
    'admin': {
        'create': True,
        'read': True,
        'update': True,  # åªèƒ½ä¿®æ”¹è‡ªå·±åˆ›å»ºçš„
        'delete': True,  # åªèƒ½åˆ é™¤è‡ªå·±åˆ›å»ºçš„
        'manage_all': False,
        'view_statistics': True
    },
    'user': {
        'create': False,
        'read': True,  # åªèƒ½çœ‹åˆ°é’ˆå¯¹è‡ªå·±çš„å…¬å‘Š
        'update': False,
        'delete': False,
        'manage_all': False,
        'view_statistics': False
    }
}

# æƒé™è£…é¥°å™¨
def require_announcement_permission(permission: str):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            current_user = kwargs.get('current_user')
            if not current_user:
                raise HTTPException(status_code=401, detail="æœªè®¤è¯")
            
            user_permissions = ANNOUNCEMENT_PERMISSIONS.get(current_user.role, {})
            if not user_permissions.get(permission, False):
                raise HTTPException(status_code=403, detail="æƒé™ä¸è¶³")
            
            return await func(*args, **kwargs)
        return wrapper
    return decorator

# æ•°æ®è¿‡æ»¤å™¨
class AnnouncementFilter:
    @staticmethod
    def filter_by_user_permission(query, user: User):
        """æ ¹æ®ç”¨æˆ·æƒé™è¿‡æ»¤å…¬å‘Š"""
        if user.role in ['super_admin', 'admin']:
            return query
        
        # æ™®é€šç”¨æˆ·åªèƒ½çœ‹åˆ°é’ˆå¯¹è‡ªå·±çš„æœ‰æ•ˆå…¬å‘Š
        now = datetime.utcnow()
        return query.filter(
            and_(
                Announcement.status == 'published',
                Announcement.start_time <= now,
                Announcement.end_time >= now,
                or_(
                    Announcement.target_type == 'all',
                    and_(
                        Announcement.target_type == 'user_role',
                        Announcement.target_ids.contains([user.role])
                    ),
                    and_(
                        Announcement.target_type == 'application',
                        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æœ‰æƒé™è®¿é—®è¿™äº›åº”ç”¨
                        exists().where(
                            and_(
                                UserLicenseBind.user_id == user.id,
                                LicenseCode.application_id.in_(Announcement.target_ids)
                            )
                        )
                    )
                )
            )
        )
```

#### 2.6.5 æ¨¡å—è”åŠ¨æœºåˆ¶

##### äº‹ä»¶æ€»çº¿è®¾è®¡

```python
# events/event_bus.py
import asyncio
import json
from typing import Dict, List, Callable, Any
from datetime import datetime
import logging
from enum import Enum

logger = logging.getLogger(__name__)

class EventType(Enum):
    """äº‹ä»¶ç±»å‹æšä¸¾"""
    # å…¬å‘Šç›¸å…³äº‹ä»¶
    ANNOUNCEMENT_PUBLISHED = "announcement.published"
    ANNOUNCEMENT_UPDATED = "announcement.updated"
    ANNOUNCEMENT_DELETED = "announcement.deleted"
    
    # å¡å¯†ç›¸å…³äº‹ä»¶
    LICENSE_ACTIVATED = "license.activated"
    LICENSE_EXPIRED = "license.expired"
    LICENSE_EXPIRING_SOON = "license.expiring_soon"
    LICENSE_DEACTIVATED = "license.deactivated"
    
    # ç”¨æˆ·ç›¸å…³äº‹ä»¶
    USER_LOGIN_FAILED = "user.login_failed"
    USER_DEVICE_LIMIT_EXCEEDED = "user.device_limit_exceeded"
    USER_BANNED = "user.banned"
    
    # åº”ç”¨ç›¸å…³äº‹ä»¶
    APPLICATION_MAINTENANCE = "application.maintenance"
    APPLICATION_VERSION_UPDATED = "application.version_updated"

class Event:
    """äº‹ä»¶æ•°æ®ç»“æ„"""
    def __init__(self, event_type: EventType, data: Dict[str, Any], user_id: str = None):
        self.id = str(uuid.uuid4())
        self.type = event_type
        self.data = data
        self.user_id = user_id
        self.timestamp = datetime.utcnow()
        self.processed = False

    def to_dict(self) -> Dict[str, Any]:
        return {
            "id": self.id,
            "type": self.type.value,
            "data": self.data,
            "user_id": self.user_id,
            "timestamp": self.timestamp.isoformat(),
            "processed": self.processed
        }

class EventBus:
    """äº‹ä»¶æ€»çº¿"""
    def __init__(self):
        self._subscribers: Dict[EventType, List[Callable]] = {}
        self._event_queue = asyncio.Queue()
        self._running = False
        self._worker_task = None

    async def start(self):
        """å¯åŠ¨äº‹ä»¶æ€»çº¿"""
        if not self._running:
            self._running = True
            self._worker_task = asyncio.create_task(self._process_events())
            logger.info("Event bus started")

    async def stop(self):
        """åœæ­¢äº‹ä»¶æ€»çº¿"""
        self._running = False
        if self._worker_task:
            self._worker_task.cancel()
            try:
                await self._worker_task
            except asyncio.CancelledError:
                pass
        logger.info("Event bus stopped")

    def subscribe(self, event_type: EventType, handler: Callable):
        """è®¢é˜…äº‹ä»¶"""
        if event_type not in self._subscribers:
            self._subscribers[event_type] = []
        self._subscribers[event_type].append(handler)
        logger.info(f"Subscribed to {event_type.value}")

    async def publish(self, event: Event):
        """å‘å¸ƒäº‹ä»¶"""
        await self._event_queue.put(event)
        logger.info(f"Published event {event.type.value} with id {event.id}")

    async def _process_events(self):
        """å¤„ç†äº‹ä»¶é˜Ÿåˆ—"""
        while self._running:
            try:
                event = await asyncio.wait_for(self._event_queue.get(), timeout=1.0)
                await self._handle_event(event)
            except asyncio.TimeoutError:
                continue
            except Exception as e:
                logger.error(f"Error processing event: {str(e)}")

    async def _handle_event(self, event: Event):
        """å¤„ç†å•ä¸ªäº‹ä»¶"""
        handlers = self._subscribers.get(event.type, [])
        if not handlers:
            logger.warning(f"No handlers for event type {event.type.value}")
            return

        for handler in handlers:
            try:
                if asyncio.iscoroutinefunction(handler):
                    await handler(event)
                else:
                    handler(event)
                logger.debug(f"Event {event.id} handled by {handler.__name__}")
            except Exception as e:
                logger.error(f"Error in event handler {handler.__name__}: {str(e)}")

        event.processed = True

# å…¨å±€äº‹ä»¶æ€»çº¿å®ä¾‹
event_bus = EventBus()
```

##### å…¬å‘Šè”åŠ¨å¤„ç†å™¨

```python
# handlers/announcement_handlers.py
from events.event_bus import event_bus, EventType, Event
from services.announcement_service import AnnouncementService
from services.notification_service import NotificationService
from database import get_db
import logging

logger = logging.getLogger(__name__)

class AnnouncementEventHandler:
    """å…¬å‘Šäº‹ä»¶å¤„ç†å™¨"""
    
    def __init__(self):
        self.announcement_service = AnnouncementService()
        self.notification_service = NotificationService()
        self._register_handlers()
    
    def _register_handlers(self):
        """æ³¨å†Œäº‹ä»¶å¤„ç†å™¨"""
        event_bus.subscribe(EventType.LICENSE_EXPIRED, self.handle_license_expired)
        event_bus.subscribe(EventType.LICENSE_EXPIRING_SOON, self.handle_license_expiring_soon)
        event_bus.subscribe(EventType.USER_LOGIN_FAILED, self.handle_login_failed)
        event_bus.subscribe(EventType.USER_DEVICE_LIMIT_EXCEEDED, self.handle_device_limit_exceeded)
        event_bus.subscribe(EventType.APPLICATION_MAINTENANCE, self.handle_application_maintenance)
        event_bus.subscribe(EventType.ANNOUNCEMENT_PUBLISHED, self.handle_announcement_published)
    
    async def handle_license_expired(self, event: Event):
        """å¤„ç†å¡å¯†è¿‡æœŸäº‹ä»¶"""
        try:
            license_data = event.data
            user_id = license_data.get('user_id')
            license_code = license_data.get('license_code')
            application_name = license_data.get('application_name')
            
            # åˆ›å»ºè¿‡æœŸé€šçŸ¥å…¬å‘Š
            announcement_data = {
                'title': f'å¡å¯†è¿‡æœŸæé†’',
                'content': f'æ‚¨çš„{application_name}æˆæƒå·²è¿‡æœŸï¼Œå¡å¯†ï¼š{license_code[:8]}***ï¼Œè¯·åŠæ—¶ç»­è´¹ä»¥ç»§ç»­ä½¿ç”¨ã€‚',
                'type': 'warning',
                'priority': 'high',
                'target_type': 'user_role',
                'target_ids': [user_id],
                'display_type': 'popup',
                'is_force_read': True,
                'start_time': datetime.utcnow(),
                'end_time': datetime.utcnow() + timedelta(days=7)
            }
            
            db = next(get_db())
            await self.announcement_service.create_system_announcement(db, announcement_data)
            
            # å‘é€æ¨é€é€šçŸ¥
            await self.notification_service.send_notification(
                user_id=user_id,
                title='å¡å¯†è¿‡æœŸæé†’',
                content=announcement_data['content'],
                channels=['desktop', 'web'],
                push_type='license_expiry'
            )
            
            logger.info(f"Created expiry announcement for user {user_id}")
            
        except Exception as e:
            logger.error(f"Failed to handle license expired event: {str(e)}")
    
    async def handle_license_expiring_soon(self, event: Event):
        """å¤„ç†å¡å¯†å³å°†è¿‡æœŸäº‹ä»¶"""
        try:
            license_data = event.data
            user_id = license_data.get('user_id')
            license_code = license_data.get('license_code')
            application_name = license_data.get('application_name')
            days_left = license_data.get('days_left', 0)
            
            # åˆ›å»ºå³å°†è¿‡æœŸæé†’å…¬å‘Š
            announcement_data = {
                'title': f'å¡å¯†å³å°†è¿‡æœŸ',
                'content': f'æ‚¨çš„{application_name}æˆæƒå°†åœ¨{days_left}å¤©åè¿‡æœŸï¼Œå¡å¯†ï¼š{license_code[:8]}***ï¼Œå»ºè®®æå‰ç»­è´¹ã€‚',
                'type': 'info',
                'priority': 'medium',
                'target_type': 'user_role',
                'target_ids': [user_id],
                'display_type': 'banner',
                'is_force_read': False,
                'start_time': datetime.utcnow(),
                'end_time': datetime.utcnow() + timedelta(days=days_left + 1)
            }
            
            db = next(get_db())
            await self.announcement_service.create_system_announcement(db, announcement_data)
            
            logger.info(f"Created expiring soon announcement for user {user_id}")
            
        except Exception as e:
            logger.error(f"Failed to handle license expiring soon event: {str(e)}")
    
    async def handle_login_failed(self, event: Event):
        """å¤„ç†ç™»å½•å¤±è´¥äº‹ä»¶"""
        try:
            login_data = event.data
            user_id = login_data.get('user_id')
            failed_attempts = login_data.get('failed_attempts', 0)
            ip_address = login_data.get('ip_address')
            
            # è¿ç»­å¤±è´¥æ¬¡æ•°è¾¾åˆ°é˜ˆå€¼æ—¶å‘é€å®‰å…¨æé†’
            if failed_attempts >= 5:
                announcement_data = {
                    'title': 'è´¦æˆ·å®‰å…¨æé†’',
                    'content': f'æ£€æµ‹åˆ°æ‚¨çš„è´¦æˆ·å­˜åœ¨å¼‚å¸¸ç™»å½•å°è¯•ï¼ˆIP: {ip_address}ï¼‰ï¼Œå¦‚éæœ¬äººæ“ä½œï¼Œè¯·ç«‹å³ä¿®æ”¹å¯†ç å¹¶è”ç³»å®¢æœã€‚',
                    'type': 'error',
                    'priority': 'urgent',
                    'target_type': 'user_role',
                    'target_ids': [user_id],
                    'display_type': 'popup',
                    'is_force_read': True,
                    'start_time': datetime.utcnow(),
                    'end_time': datetime.utcnow() + timedelta(days=3)
                }
                
                db = next(get_db())
                await self.announcement_service.create_system_announcement(db, announcement_data)
                
                # å‘é€ç´§æ€¥å®‰å…¨é€šçŸ¥
                await self.notification_service.send_notification(
                    user_id=user_id,
                    title='è´¦æˆ·å®‰å…¨è­¦å‘Š',
                    content=announcement_data['content'],
                    channels=['desktop', 'web', 'email'],
                    push_type='auth_failure'
                )
                
                logger.warning(f"Created security alert for user {user_id} after {failed_attempts} failed attempts")
        
        except Exception as e:
            logger.error(f"Failed to handle login failed event: {str(e)}")
    
    async def handle_device_limit_exceeded(self, event: Event):
        """å¤„ç†è®¾å¤‡æ•°é‡è¶…é™äº‹ä»¶"""
        try:
            device_data = event.data
            user_id = device_data.get('user_id')
            current_devices = device_data.get('current_devices', 0)
            max_devices = device_data.get('max_devices', 0)
            new_device_info = device_data.get('new_device_info', {})
            
            announcement_data = {
                'title': 'è®¾å¤‡æ•°é‡è¶…é™æé†’',
                'content': f'æ‚¨çš„è´¦æˆ·è®¾å¤‡æ•°é‡å·²è¾¾ä¸Šé™ï¼ˆ{current_devices}/{max_devices}ï¼‰ï¼Œæ–°è®¾å¤‡ç™»å½•è¢«æ‹’ç»ã€‚å¦‚éœ€åœ¨æ–°è®¾å¤‡ä½¿ç”¨ï¼Œè¯·å…ˆè§£ç»‘å…¶ä»–è®¾å¤‡ã€‚',
                'type': 'warning',
                'priority': 'high',
                'target_type': 'user_role',
                'target_ids': [user_id],
                'display_type': 'popup',
                'is_force_read': True,
                'start_time': datetime.utcnow(),
                'end_time': datetime.utcnow() + timedelta(days=1)
            }
            
            db = next(get_db())
            await self.announcement_service.create_system_announcement(db, announcement_data)
            
            # å‘é€è®¾å¤‡é™åˆ¶é€šçŸ¥
            await self.notification_service.send_notification(
                user_id=user_id,
                title='è®¾å¤‡æ•°é‡è¶…é™',
                content=announcement_data['content'],
                channels=['desktop', 'web'],
                push_type='device_limit'
            )
            
            logger.info(f"Created device limit announcement for user {user_id}")
            
        except Exception as e:
            logger.error(f"Failed to handle device limit exceeded event: {str(e)}")
    
    async def handle_application_maintenance(self, event: Event):
        """å¤„ç†åº”ç”¨ç»´æŠ¤äº‹ä»¶"""
        try:
            maintenance_data = event.data
            application_id = maintenance_data.get('application_id')
            application_name = maintenance_data.get('application_name')
            maintenance_start = maintenance_data.get('start_time')
            maintenance_end = maintenance_data.get('end_time')
            reason = maintenance_data.get('reason', 'ç³»ç»Ÿç»´æŠ¤')
            
            announcement_data = {
                'title': f'{application_name}ç»´æŠ¤é€šçŸ¥',
                'content': f'{application_name}å°†äº{maintenance_start}è‡³{maintenance_end}è¿›è¡Œ{reason}ï¼ŒæœŸé—´æœåŠ¡å¯èƒ½ä¸­æ–­ï¼Œè¯·åˆç†å®‰æ’ä½¿ç”¨æ—¶é—´ã€‚',
                'type': 'info',
                'priority': 'high',
                'target_type': 'application',
                'target_ids': [application_id],
                'display_type': 'banner',
                'is_force_read': False,
                'start_time': datetime.utcnow(),
                'end_time': datetime.fromisoformat(maintenance_end) + timedelta(hours=1)
            }
            
            db = next(get_db())
            await self.announcement_service.create_system_announcement(db, announcement_data)
            
            logger.info(f"Created maintenance announcement for application {application_id}")
            
        except Exception as e:
            logger.error(f"Failed to handle application maintenance event: {str(e)}")
    
    async def handle_announcement_published(self, event: Event):
        """å¤„ç†å…¬å‘Šå‘å¸ƒäº‹ä»¶"""
        try:
            announcement_data = event.data
            announcement_id = announcement_data.get('announcement_id')
            target_type = announcement_data.get('target_type')
            target_ids = announcement_data.get('target_ids', [])
            display_type = announcement_data.get('display_type')
            priority = announcement_data.get('priority')
            
            # æ ¹æ®å±•ç¤ºæ–¹å¼å’Œä¼˜å…ˆçº§å†³å®šæ¨é€ç­–ç•¥
            if display_type == 'popup' or priority in ['high', 'urgent']:
                # é«˜ä¼˜å…ˆçº§å…¬å‘Šç«‹å³æ¨é€
                await self._push_announcement_immediately(announcement_id, target_type, target_ids)
            else:
                # æ™®é€šå…¬å‘Šå»¶è¿Ÿæ¨é€ï¼Œé¿å…æ‰“æ‰°ç”¨æˆ·
                await self._schedule_announcement_push(announcement_id, target_type, target_ids)
            
            logger.info(f"Processed announcement published event for {announcement_id}")
            
        except Exception as e:
            logger.error(f"Failed to handle announcement published event: {str(e)}")
    
    async def _push_announcement_immediately(self, announcement_id: str, target_type: str, target_ids: List[str]):
        """ç«‹å³æ¨é€å…¬å‘Š"""
        db = next(get_db())
        target_users = await self.announcement_service.get_target_users(db, target_type, target_ids)
        
        for user_id in target_users:
            await self.notification_service.send_notification(
                user_id=user_id,
                title='æ–°å…¬å‘Šé€šçŸ¥',
                content='æ‚¨æœ‰æ–°çš„é‡è¦å…¬å‘Šï¼Œè¯·åŠæ—¶æŸ¥çœ‹ã€‚',
                channels=['desktop', 'web'],
                push_type='announcement',
                related_id=announcement_id
            )
    
    async def _schedule_announcement_push(self, announcement_id: str, target_type: str, target_ids: List[str]):
        """å»¶è¿Ÿæ¨é€å…¬å‘Š"""
        # è¿™é‡Œå¯ä»¥é›†æˆä»»åŠ¡è°ƒåº¦å™¨ï¼Œå¦‚Celery
        # æš‚æ—¶ä½¿ç”¨ç®€å•çš„å»¶è¿Ÿæ¨é€
        await asyncio.sleep(300)  # å»¶è¿Ÿ5åˆ†é’Ÿæ¨é€
        await self._push_announcement_immediately(announcement_id, target_type, target_ids)

# åˆå§‹åŒ–äº‹ä»¶å¤„ç†å™¨
announcement_handler = AnnouncementEventHandler()
```

##### é€šçŸ¥æœåŠ¡

```python
# services/notification_service.py
import asyncio
import json
from typing import List, Dict, Any
from datetime import datetime
from database import get_db
from models.announcement import AnnouncementPush
import uuid
import logging

logger = logging.getLogger(__name__)

class NotificationService:
    """é€šçŸ¥æ¨é€æœåŠ¡"""
    
    def __init__(self):
        self.websocket_manager = WebSocketManager()
        self.email_service = EmailService()
    
    async def send_notification(
        self,
        user_id: str,
        title: str,
        content: str,
        channels: List[str],
        push_type: str,
        related_id: str = None
    ):
        """å‘é€é€šçŸ¥"""
        try:
            # åˆ›å»ºæ¨é€è®°å½•
            db = next(get_db())
            push_record = AnnouncementPush(
                id=str(uuid.uuid4()),
                announcement_id=related_id,
                user_id=user_id,
                push_type=push_type,
                title=title,
                content=content,
                channels=channels,
                status='pending',
                created_at=datetime.utcnow()
            )
            
            db.add(push_record)
            db.commit()
            
            # å¹¶å‘æ¨é€åˆ°å„ä¸ªæ¸ é“
            tasks = []
            if 'desktop' in channels:
                tasks.append(self._send_desktop_notification(user_id, title, content))
            if 'web' in channels:
                tasks.append(self._send_web_notification(user_id, title, content))
            if 'email' in channels:
                tasks.append(self._send_email_notification(user_id, title, content))
            
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # æ›´æ–°æ¨é€çŠ¶æ€
            success_count = sum(1 for result in results if not isinstance(result, Exception))
            if success_count > 0:
                push_record.status = 'sent'
                push_record.sent_at = datetime.utcnow()
            else:
                push_record.status = 'failed'
                push_record.error_message = str(results[0]) if results else 'Unknown error'
            
            db.commit()
            
            logger.info(f"Notification sent to user {user_id} via {success_count}/{len(tasks)} channels")
            
        except Exception as e:
            logger.error(f"Failed to send notification: {str(e)}")
            if 'push_record' in locals():
                push_record.status = 'failed'
                push_record.error_message = str(e)
                db.commit()
    
    async def _send_desktop_notification(self, user_id: str, title: str, content: str):
        """å‘é€æ¡Œé¢é€šçŸ¥"""
        # è¿™é‡Œé›†æˆæ¡Œé¢åº”ç”¨çš„é€šçŸ¥API
        # å¯ä»¥é€šè¿‡WebSocketæˆ–HTTP APIæ¨é€åˆ°æ¡Œé¢å®¢æˆ·ç«¯
        notification_data = {
            'type': 'desktop_notification',
            'title': title,
            'content': content,
            'timestamp': datetime.utcnow().isoformat()
        }
        
        # å‘é€åˆ°æ¡Œé¢å®¢æˆ·ç«¯
        await self._send_to_desktop_client(user_id, notification_data)
    
    async def _send_web_notification(self, user_id: str, title: str, content: str):
        """å‘é€Webé€šçŸ¥"""
        notification_data = {
            'type': 'web_notification',
            'title': title,
            'content': content,
            'timestamp': datetime.utcnow().isoformat()
        }
        
        # é€šè¿‡WebSocketæ¨é€åˆ°Webå®¢æˆ·ç«¯
        await self.websocket_manager.send_to_user(user_id, notification_data)
    
    async def _send_email_notification(self, user_id: str, title: str, content: str):
        """å‘é€é‚®ä»¶é€šçŸ¥"""
        # è·å–ç”¨æˆ·é‚®ç®±
        db = next(get_db())
        user = db.query(User).filter(User.id == user_id).first()
        if not user or not user.email:
            raise Exception("User email not found")
        
        # å‘é€é‚®ä»¶
        await self.email_service.send_email(
            to_email=user.email,
            subject=title,
            content=content
        )
    
    async def _send_to_desktop_client(self, user_id: str, data: Dict[str, Any]):
        """å‘é€åˆ°æ¡Œé¢å®¢æˆ·ç«¯"""
        # è¿™é‡Œéœ€è¦æ ¹æ®å®é™…çš„æ¡Œé¢åº”ç”¨é€šä¿¡æ–¹å¼å®ç°
        # å¯èƒ½æ˜¯HTTP APIã€WebSocketæˆ–å…¶ä»–IPCæ–¹å¼
        pass

class WebSocketManager:
    """WebSocketè¿æ¥ç®¡ç†å™¨"""
    
    def __init__(self):
        self.connections: Dict[str, List[WebSocket]] = {}
    
    async def connect(self, websocket: WebSocket, user_id: str):
        """å»ºç«‹WebSocketè¿æ¥"""
        await websocket.accept()
        if user_id not in self.connections:
            self.connections[user_id] = []
        self.connections[user_id].append(websocket)
        logger.info(f"WebSocket connected for user {user_id}")
    
    def disconnect(self, websocket: WebSocket, user_id: str):
        """æ–­å¼€WebSocketè¿æ¥"""
        if user_id in self.connections:
            self.connections[user_id].remove(websocket)
            if not self.connections[user_id]:
                del self.connections[user_id]
        logger.info(f"WebSocket disconnected for user {user_id}")
    
    async def send_to_user(self, user_id: str, data: Dict[str, Any]):
        """å‘é€æ¶ˆæ¯ç»™æŒ‡å®šç”¨æˆ·"""
        if user_id in self.connections:
            message = json.dumps(data)
            disconnected = []
            
            for websocket in self.connections[user_id]:
                try:
                    await websocket.send_text(message)
                except Exception as e:
                    logger.error(f"Failed to send WebSocket message: {str(e)}")
                    disconnected.append(websocket)
            
            # æ¸…ç†æ–­å¼€çš„è¿æ¥
            for websocket in disconnected:
                self.disconnect(websocket, user_id)

# å…¨å±€WebSocketç®¡ç†å™¨å®ä¾‹
websocket_manager = WebSocketManager()
```

### 2.5 ä¸»è¦ç•Œé¢äº¤äº’é€»è¾‘

#### ç™»å½•æµç¨‹

```mermaid
sequenceDiagram
    participant U as ç”¨æˆ·
    participant F as å‰ç«¯
    participant A as API
    
    U->>F: è¾“å…¥ç”¨æˆ·åå¯†ç 
    F->>F: è¡¨å•éªŒè¯
    F->>A: POST /auth/login
    A->>F: è¿”å›JWT Token
    F->>F: å­˜å‚¨Tokenåˆ°Cookie
    F->>F: è·³è½¬åˆ°Dashboard
    F->>A: GET /auth/me (éªŒè¯Token)
    A->>F: è¿”å›ç”¨æˆ·ä¿¡æ¯
    F->>F: æ›´æ–°å…¨å±€çŠ¶æ€
```

#### å¡å¯†æ¿€æ´»æµç¨‹

```mermaid
sequenceDiagram
    participant C as å®¢æˆ·ç«¯
    participant F as å‰ç«¯
    participant A as API
    participant D as æ•°æ®åº“
    
    C->>F: è¾“å…¥å¡å¯†
    F->>F: å¡å¯†æ ¼å¼éªŒè¯
    F->>A: POST /auth/activate
    A->>D: æŸ¥è¯¢å¡å¯†çŠ¶æ€
    D->>A: è¿”å›å¡å¯†ä¿¡æ¯
    A->>A: éªŒè¯è®¾å¤‡æŒ‡çº¹
    A->>D: æ›´æ–°å¡å¯†çŠ¶æ€
    A->>F: è¿”å›æ¿€æ´»ç»“æœ
    F->>C: æ˜¾ç¤ºæ¿€æ´»çŠ¶æ€
```

---

## 3. åç«¯å¼€å‘éƒ¨åˆ†

### 3.1 é…ç½®ç®¡ç†ä¼˜åŒ–

#### 3.1.1 ç¯å¢ƒå˜é‡é…ç½®æ–¹æ¡ˆ

##### é…ç½®æ–‡ä»¶ç»“æ„

```bash
# .env.example - ç¯å¢ƒå˜é‡æ¨¡æ¿æ–‡ä»¶
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://username:password@localhost:5432/goldfish_license
DATABASE_POOL_SIZE=20
DATABASE_MAX_OVERFLOW=30
DATABASE_POOL_TIMEOUT=30
DATABASE_POOL_RECYCLE=3600

# Redisé…ç½®
REDIS_URL=redis://localhost:6379/0
REDIS_PASSWORD=
REDIS_MAX_CONNECTIONS=50
REDIS_SOCKET_TIMEOUT=5
REDIS_SOCKET_CONNECT_TIMEOUT=5

# JWTé…ç½®
JWT_SECRET_KEY=your-super-secret-jwt-key-change-in-production
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30
JWT_REFRESH_TOKEN_EXPIRE_DAYS=7

# åŠ å¯†é…ç½®
ENCRYPTION_KEY=your-32-byte-encryption-key-here
PASSWORD_SALT_ROUNDS=12

# æœåŠ¡å™¨é…ç½®
SERVER_HOST=0.0.0.0
SERVER_PORT=
SERVER_WORKERS=4
DEBUG_MODE=false
LOG_LEVEL=INFO

# è·¨åŸŸé…ç½®
CORS_ORIGINS=http://localhost:3000,http://127.0.0.1:3000
CORS_ALLOW_CREDENTIALS=true

# é™æµé…ç½®
RATE_LIMIT_REQUESTS_PER_MINUTE=60
RATE_LIMIT_BURST_SIZE=10

# é‚®ä»¶é…ç½®
SMTP_SERVER=smtp.gmail.com
SMTP_PORT=587
SMTP_USERNAME=your-email@gmail.com
SMTP_PASSWORD=your-app-password
SMTP_USE_TLS=true

# æ–‡ä»¶ä¸Šä¼ é…ç½®
UPLOAD_MAX_SIZE_MB=10
UPLOAD_ALLOWED_EXTENSIONS=jpg,jpeg,png,gif,pdf,doc,docx
UPLOAD_PATH=./uploads

# ç¼“å­˜é…ç½®
CACHE_DEFAULT_TIMEOUT=300
CACHE_LICENSE_TIMEOUT=3600
CACHE_USER_SESSION_TIMEOUT=1800

# ç›‘æ§é…ç½®
MONITORING_ENABLED=true
METRICS_PORT=9090
HEALTH_CHECK_INTERVAL=30

# å¤–éƒ¨æœåŠ¡é…ç½®
LICENSE_VALIDATION_URL=https://api.license-provider.com/validate
NOTIFICATION_SERVICE_URL=https://api.notification-service.com
AUDIT_LOG_WEBHOOK_URL=https://api.audit-service.com/webhook

# å®‰å…¨é…ç½®
SECURE_COOKIES=true
CSRF_PROTECTION_ENABLED=true
API_KEY_HEADER_NAME=X-API-Key
ADMIN_API_KEY=your-admin-api-key-here

# å¼€å‘ç¯å¢ƒé…ç½®
ENVIRONMENT=development
PROFILING_ENABLED=false
SQL_ECHO=false
```

##### é…ç½®ç®¡ç†ç±»

```python
# config/settings.py
import os
from typing import List, Optional
from pydantic import BaseSettings, validator
from functools import lru_cache
import secrets

class Settings(BaseSettings):
    """åº”ç”¨é…ç½®ç®¡ç†ç±»"""
    
    # æ•°æ®åº“é…ç½®
    database_url: str
    database_pool_size: int = 20
    database_max_overflow: int = 30
    database_pool_timeout: int = 30
    database_pool_recycle: int = 3600
    
    # Redisé…ç½®
    redis_url: str = "redis://localhost:6379/0"
    redis_password: Optional[str] = None
    redis_max_connections: int = 50
    redis_socket_timeout: int = 5
    redis_socket_connect_timeout: int = 5
    
    # JWTé…ç½®
    jwt_secret_key: str
    jwt_algorithm: str = "HS256"
    jwt_access_token_expire_minutes: int = 30
    jwt_refresh_token_expire_days: int = 7
    
    # åŠ å¯†é…ç½®
    encryption_key: str
    password_salt_rounds: int = 12
    
    # æœåŠ¡å™¨é…ç½®
    server_host: str = "0.0.0.0"
    server_port: int = 8000
    server_workers: int = 4
    debug_mode: bool = False
    log_level: str = "INFO"
    
    # è·¨åŸŸé…ç½®
    cors_origins: List[str] = ["http://localhost:3000"]
    cors_allow_credentials: bool = True
    
    # é™æµé…ç½®
    rate_limit_requests_per_minute: int = 60
    rate_limit_burst_size: int = 10
    
    # é‚®ä»¶é…ç½®
    smtp_server: Optional[str] = None
    smtp_port: int = 587
    smtp_username: Optional[str] = None
    smtp_password: Optional[str] = None
    smtp_use_tls: bool = True
    
    # æ–‡ä»¶ä¸Šä¼ é…ç½®
    upload_max_size_mb: int = 10
    upload_allowed_extensions: List[str] = ["jpg", "jpeg", "png", "gif", "pdf", "doc", "docx"]
    upload_path: str = "./uploads"
    
    # ç¼“å­˜é…ç½®
    cache_default_timeout: int = 300
    cache_license_timeout: int = 3600
    cache_user_session_timeout: int = 1800
    
    # ç›‘æ§é…ç½®
    monitoring_enabled: bool = True
    metrics_port: int = 9090
    health_check_interval: int = 30
    
    # å¤–éƒ¨æœåŠ¡é…ç½®
    license_validation_url: Optional[str] = None
    notification_service_url: Optional[str] = None
    audit_log_webhook_url: Optional[str] = None
    
    # å®‰å…¨é…ç½®
    secure_cookies: bool = True
    csrf_protection_enabled: bool = True
    api_key_header_name: str = "X-API-Key"
    admin_api_key: Optional[str] = None
    
    # å¼€å‘ç¯å¢ƒé…ç½®
    environment: str = "development"
    profiling_enabled: bool = False
    sql_echo: bool = False
    
    @validator('jwt_secret_key')
    def validate_jwt_secret_key(cls, v):
        if len(v) < 32:
            raise ValueError('JWTå¯†é’¥é•¿åº¦ä¸èƒ½å°‘äº32ä¸ªå­—ç¬¦')
        return v
    
    @validator('encryption_key')
    def validate_encryption_key(cls, v):
        if len(v) != 32:
            raise ValueError('åŠ å¯†å¯†é’¥å¿…é¡»ä¸º32å­—èŠ‚')
        return v
    
    @validator('cors_origins', pre=True)
    def parse_cors_origins(cls, v):
        if isinstance(v, str):
            return [origin.strip() for origin in v.split(',')]
        return v
    
    @validator('upload_allowed_extensions', pre=True)
    def parse_upload_extensions(cls, v):
        if isinstance(v, str):
            return [ext.strip().lower() for ext in v.split(',')]
        return v
    
    def generate_secret_key(self) -> str:
        """ç”Ÿæˆå®‰å…¨çš„å¯†é’¥"""
        return secrets.token_urlsafe(32)
    
    @property
    def is_production(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºç”Ÿäº§ç¯å¢ƒ"""
        return self.environment.lower() == 'production'
    
    @property
    def is_development(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºå¼€å‘ç¯å¢ƒ"""
        return self.environment.lower() == 'development'
    
    class Config:
        env_file = ".env"
        env_file_encoding = 'utf-8'
        case_sensitive = False
        # ç¯å¢ƒå˜é‡å‰ç¼€
        env_prefix = ""
        # å…è®¸ä»ç¯å¢ƒå˜é‡ä¸­è¯»å–åµŒå¥—é…ç½®
        env_nested_delimiter = "__"

@lru_cache()
def get_settings() -> Settings:
    """è·å–é…ç½®å®ä¾‹ï¼ˆå•ä¾‹æ¨¡å¼ï¼‰"""
    return Settings()

# å…¨å±€é…ç½®å®ä¾‹
settings = get_settings()
```

##### é…ç½®éªŒè¯å’Œåˆå§‹åŒ–

```python
# config/validator.py
import os
import sys
from pathlib import Path
from typing import List, Dict, Any
from config.settings import settings
import logging

logger = logging.getLogger(__name__)

class ConfigValidator:
    """é…ç½®éªŒè¯å™¨"""
    
    def __init__(self):
        self.errors: List[str] = []
        self.warnings: List[str] = []
    
    def validate_all(self) -> bool:
        """éªŒè¯æ‰€æœ‰é…ç½®é¡¹"""
        self.validate_database_config()
        self.validate_security_config()
        self.validate_file_paths()
        self.validate_network_config()
        self.validate_external_services()
        
        if self.errors:
            logger.error("é…ç½®éªŒè¯å¤±è´¥:")
            for error in self.errors:
                logger.error(f"  - {error}")
            return False
        
        if self.warnings:
            logger.warning("é…ç½®è­¦å‘Š:")
            for warning in self.warnings:
                logger.warning(f"  - {warning}")
        
        logger.info("é…ç½®éªŒè¯é€šè¿‡")
        return True
    
    def validate_database_config(self):
        """éªŒè¯æ•°æ®åº“é…ç½®"""
        if not settings.database_url:
            self.errors.append("æ•°æ®åº“URLæœªé…ç½®")
        
        if settings.database_pool_size <= 0:
            self.errors.append("æ•°æ®åº“è¿æ¥æ± å¤§å°å¿…é¡»å¤§äº0")
        
        if settings.database_pool_size > 100:
            self.warnings.append("æ•°æ®åº“è¿æ¥æ± å¤§å°è¿‡å¤§ï¼Œå¯èƒ½å½±å“æ€§èƒ½")
    
    def validate_security_config(self):
        """éªŒè¯å®‰å…¨é…ç½®"""
        if len(settings.jwt_secret_key) < 32:
            self.errors.append("JWTå¯†é’¥é•¿åº¦ä¸è¶³ï¼Œå­˜åœ¨å®‰å…¨é£é™©")
        
        if settings.jwt_secret_key == "your-super-secret-jwt-key-change-in-production":
            self.errors.append("JWTå¯†é’¥ä½¿ç”¨é»˜è®¤å€¼ï¼Œå¿…é¡»ä¿®æ”¹")
        
        if settings.encryption_key == "your-32-byte-encryption-key-here":
            self.errors.append("åŠ å¯†å¯†é’¥ä½¿ç”¨é»˜è®¤å€¼ï¼Œå¿…é¡»ä¿®æ”¹")
        
        if settings.is_production and settings.debug_mode:
            self.warnings.append("ç”Ÿäº§ç¯å¢ƒä¸å»ºè®®å¼€å¯è°ƒè¯•æ¨¡å¼")
        
        if settings.is_production and not settings.secure_cookies:
            self.warnings.append("ç”Ÿäº§ç¯å¢ƒå»ºè®®å¯ç”¨å®‰å…¨Cookie")
    
    def validate_file_paths(self):
        """éªŒè¯æ–‡ä»¶è·¯å¾„é…ç½®"""
        upload_path = Path(settings.upload_path)
        if not upload_path.exists():
            try:
                upload_path.mkdir(parents=True, exist_ok=True)
                logger.info(f"åˆ›å»ºä¸Šä¼ ç›®å½•: {upload_path}")
            except Exception as e:
                self.errors.append(f"æ— æ³•åˆ›å»ºä¸Šä¼ ç›®å½• {upload_path}: {str(e)}")
        
        if not os.access(upload_path, os.W_OK):
            self.errors.append(f"ä¸Šä¼ ç›®å½• {upload_path} æ²¡æœ‰å†™å…¥æƒé™")
    
    def validate_network_config(self):
        """éªŒè¯ç½‘ç»œé…ç½®"""
        if settings.server_port < 1024 and os.getuid() != 0:
            self.warnings.append("ä½¿ç”¨ç‰¹æƒç«¯å£éœ€è¦ç®¡ç†å‘˜æƒé™")
        
        if settings.server_port > 65535:
            self.errors.append("æœåŠ¡å™¨ç«¯å£å·è¶…å‡ºæœ‰æ•ˆèŒƒå›´")
        
        # éªŒè¯CORSé…ç½®
        if "*" in settings.cors_origins and settings.is_production:
            self.warnings.append("ç”Ÿäº§ç¯å¢ƒä¸å»ºè®®ä½¿ç”¨é€šé…ç¬¦CORSé…ç½®")
    
    def validate_external_services(self):
        """éªŒè¯å¤–éƒ¨æœåŠ¡é…ç½®"""
        if settings.smtp_server and not settings.smtp_username:
            self.warnings.append("é…ç½®äº†SMTPæœåŠ¡å™¨ä½†æœªè®¾ç½®ç”¨æˆ·å")
        
        if settings.monitoring_enabled and settings.metrics_port == settings.server_port:
            self.errors.append("ç›‘æ§ç«¯å£ä¸èƒ½ä¸æœåŠ¡ç«¯å£ç›¸åŒ")

def validate_config() -> bool:
    """éªŒè¯é…ç½®å¹¶è¿”å›æ˜¯å¦é€šè¿‡"""
    validator = ConfigValidator()
    return validator.validate_all()

def init_config():
    """åˆå§‹åŒ–é…ç½®"""
    # æ£€æŸ¥.envæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    env_file = Path(".env")
    if not env_file.exists():
        logger.warning(".envæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨ç¯å¢ƒå˜é‡æˆ–é»˜è®¤å€¼")
        
        # æ£€æŸ¥æ˜¯å¦æœ‰.env.exampleæ–‡ä»¶
        env_example = Path(".env.example")
        if env_example.exists():
            logger.info("å‘ç°.env.exampleæ–‡ä»¶ï¼Œè¯·å¤åˆ¶å¹¶é‡å‘½åä¸º.envåé…ç½®ç›¸åº”å‚æ•°")
    
    # éªŒè¯é…ç½®
    if not validate_config():
        logger.error("é…ç½®éªŒè¯å¤±è´¥ï¼Œç¨‹åºé€€å‡º")
        sys.exit(1)
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    logging.getLogger().setLevel(getattr(logging, settings.log_level.upper()))
    
    logger.info(f"åº”ç”¨é…ç½®åˆå§‹åŒ–å®Œæˆ - ç¯å¢ƒ: {settings.environment}")
```

##### é…ç½®çƒ­é‡è½½æœºåˆ¶

```python
# config/hot_reload.py
import asyncio
import os
from pathlib import Path
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
from config.settings import get_settings
import logging
from datetime import datetime
from typing import List

logger = logging.getLogger(__name__)

class ConfigReloadHandler(FileSystemEventHandler):
    """é…ç½®æ–‡ä»¶å˜æ›´å¤„ç†å™¨"""
    
    def __init__(self, callback):
        self.callback = callback
        self.last_modified = {}
    
    def on_modified(self, event):
        if event.is_directory:
            return
        
        file_path = Path(event.src_path)
        if file_path.name in [".env", "settings.py"]:
            # é˜²æ­¢é‡å¤è§¦å‘
            current_time = os.path.getmtime(file_path)
            if file_path in self.last_modified:
                if current_time - self.last_modified[file_path] < 1:
                    return
            
            self.last_modified[file_path] = current_time
            logger.info(f"æ£€æµ‹åˆ°é…ç½®æ–‡ä»¶å˜æ›´: {file_path}")
            
            # å¼‚æ­¥æ‰§è¡Œå›è°ƒ
            asyncio.create_task(self.callback())

class ConfigHotReload:
    """é…ç½®çƒ­é‡è½½ç®¡ç†å™¨"""
    
    def __init__(self):
        self.observer = None
        self.enabled = False
    
    async def start(self, watch_paths: List[str] = None):
        """å¯åŠ¨é…ç½®çƒ­é‡è½½"""
        if watch_paths is None:
            watch_paths = ["."]
        
        self.observer = Observer()
        handler = ConfigReloadHandler(self._reload_config)
        
        for path in watch_paths:
            self.observer.schedule(handler, path, recursive=False)
        
        self.observer.start()
        self.enabled = True
        logger.info("é…ç½®çƒ­é‡è½½å·²å¯åŠ¨")
    
    def stop(self):
        """åœæ­¢é…ç½®çƒ­é‡è½½"""
        if self.observer:
            self.observer.stop()
            self.observer.join()
            self.enabled = False
            logger.info("é…ç½®çƒ­é‡è½½å·²åœæ­¢")
    
    async def _reload_config(self):
        """é‡æ–°åŠ è½½é…ç½®"""
        try:
            # æ¸…é™¤ç¼“å­˜çš„é…ç½®
            get_settings.cache_clear()
            
            # é‡æ–°éªŒè¯é…ç½®
            from config.validator import validate_config
            if validate_config():
                logger.info("é…ç½®é‡æ–°åŠ è½½æˆåŠŸ")
                # è¿™é‡Œå¯ä»¥è§¦å‘å…¶ä»–éœ€è¦é‡æ–°åˆå§‹åŒ–çš„ç»„ä»¶
                await self._notify_config_change()
            else:
                logger.error("é…ç½®é‡æ–°åŠ è½½å¤±è´¥ï¼Œä¿æŒåŸæœ‰é…ç½®")
        
        except Exception as e:
            logger.error(f"é…ç½®é‡æ–°åŠ è½½å¼‚å¸¸: {str(e)}")
    
    async def _notify_config_change(self):
        """é€šçŸ¥é…ç½®å˜æ›´"""
        # è¿™é‡Œå¯ä»¥å‘é€äº‹ä»¶é€šçŸ¥å…¶ä»–æ¨¡å—é…ç½®å·²å˜æ›´
        from events.event_bus import event_bus, Event, EventType
        
        event = Event(
            event_type=EventType.CONFIG_CHANGED,
            data={"timestamp": datetime.utcnow().isoformat()}
        )
        await event_bus.publish(event)

# å…¨å±€çƒ­é‡è½½å®ä¾‹
config_hot_reload = ConfigHotReload()
```

#### 3.1.2 åº”ç”¨å¯åŠ¨é…ç½®é›†æˆ

```python
# main.py
from fastapi import FastAPI
from config.settings import settings
from config.validator import init_config
from config.hot_reload import config_hot_reload
import uvicorn
import logging

# åˆå§‹åŒ–é…ç½®
init_config()

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="é‡‘é±¼æ™ºç›’å¡å¯†æˆæƒç³»ç»Ÿ",
    description="ä¼ä¸šçº§å¡å¯†æˆæƒç®¡ç†ç³»ç»Ÿ",
    version="1.0.0",
    debug=settings.debug_mode
)

@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨äº‹ä»¶"""
    logger = logging.getLogger(__name__)
    logger.info(f"åº”ç”¨å¯åŠ¨ - ç¯å¢ƒ: {settings.environment}")
    logger.info(f"æœåŠ¡åœ°å€: {settings.server_host}:{settings.server_port}")
    
    # å¼€å‘ç¯å¢ƒå¯ç”¨é…ç½®çƒ­é‡è½½
    if settings.is_development:
        await config_hot_reload.start()
        logger.info("å¼€å‘ç¯å¢ƒé…ç½®çƒ­é‡è½½å·²å¯ç”¨")

@app.on_event("shutdown")
async def shutdown_event():
    """åº”ç”¨å…³é—­äº‹ä»¶"""
    if config_hot_reload.enabled:
        config_hot_reload.stop()
    
    logger = logging.getLogger(__name__)
    logger.info("åº”ç”¨å·²å…³é—­")

if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host=settings.server_host,
        port=settings.server_port,
        workers=settings.server_workers if settings.is_production else 1,
        reload=settings.is_development,
        log_level=settings.log_level.lower()
    )
```

### 3.2 é”™è¯¯å¤„ç†æœºåˆ¶å®Œå–„

#### 3.2.1 å…¨å±€å¼‚å¸¸æ‹¦æˆªå™¨

##### å¼‚å¸¸å¤„ç†ä¸­é—´ä»¶

```python
# middleware/exception_handler.py
from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from fastapi.exceptions import RequestValidationError
from starlette.exceptions import HTTPException as StarletteHTTPException
from starlette.middleware.base import BaseHTTPMiddleware
from typing import Union
import logging
import traceback
from datetime import datetime
import uuid
from config.settings import settings

logger = logging.getLogger(__name__)

class GlobalExceptionHandler(BaseHTTPMiddleware):
    """å…¨å±€å¼‚å¸¸å¤„ç†ä¸­é—´ä»¶"""
    
    async def dispatch(self, request: Request, call_next):
        try:
            response = await call_next(request)
            return response
        except Exception as exc:
            return await self.handle_exception(request, exc)
    
    async def handle_exception(self, request: Request, exc: Exception) -> JSONResponse:
        """å¤„ç†å¼‚å¸¸å¹¶è¿”å›æ ‡å‡†åŒ–å“åº”"""
        error_id = str(uuid.uuid4())
        
        # è®°å½•å¼‚å¸¸ä¿¡æ¯
        logger.error(
            f"å¼‚å¸¸ID: {error_id} | è·¯å¾„: {request.url.path} | "
            f"æ–¹æ³•: {request.method} | å¼‚å¸¸: {str(exc)}",
            exc_info=True
        )
        
        # æ ¹æ®å¼‚å¸¸ç±»å‹è¿”å›ä¸åŒçš„é”™è¯¯å“åº”
        if isinstance(exc, HTTPException):
            return await self._handle_http_exception(exc, error_id)
        elif isinstance(exc, RequestValidationError):
            return await self._handle_validation_error(exc, error_id)
        elif isinstance(exc, ValueError):
            return await self._handle_value_error(exc, error_id)
        elif isinstance(exc, PermissionError):
            return await self._handle_permission_error(exc, error_id)
        else:
            return await self._handle_internal_error(exc, error_id)
    
    async def _handle_http_exception(self, exc: HTTPException, error_id: str) -> JSONResponse:
        """å¤„ç†HTTPå¼‚å¸¸"""
        return JSONResponse(
            status_code=exc.status_code,
            content={
                "success": False,
                "error_code": f"HTTP_{exc.status_code}",
                "message": exc.detail,
                "error_id": error_id,
                "timestamp": datetime.utcnow().isoformat()
            }
        )
    
    async def _handle_validation_error(self, exc: RequestValidationError, error_id: str) -> JSONResponse:
        """å¤„ç†è¯·æ±‚éªŒè¯é”™è¯¯"""
        errors = []
        for error in exc.errors():
            field = ".".join(str(loc) for loc in error["loc"])
            errors.append({
                "field": field,
                "message": error["msg"],
                "type": error["type"]
            })
        
        return JSONResponse(
            status_code=422,
            content={
                "success": False,
                "error_code": "VALIDATION_ERROR",
                "message": "è¯·æ±‚å‚æ•°éªŒè¯å¤±è´¥",
                "details": errors,
                "error_id": error_id,
                "timestamp": datetime.utcnow().isoformat()
            }
        )
    
    async def _handle_value_error(self, exc: ValueError, error_id: str) -> JSONResponse:
        """å¤„ç†å€¼é”™è¯¯"""
        return JSONResponse(
            status_code=400,
            content={
                "success": False,
                "error_code": "VALUE_ERROR",
                "message": str(exc),
                "error_id": error_id,
                "timestamp": datetime.utcnow().isoformat()
            }
        )
    
    async def _handle_permission_error(self, exc: PermissionError, error_id: str) -> JSONResponse:
        """å¤„ç†æƒé™é”™è¯¯"""
        return JSONResponse(
            status_code=403,
            content={
                "success": False,
                "error_code": "PERMISSION_DENIED",
                "message": "æƒé™ä¸è¶³",
                "error_id": error_id,
                "timestamp": datetime.utcnow().isoformat()
            }
        )
    
    async def _handle_internal_error(self, exc: Exception, error_id: str) -> JSONResponse:
        """å¤„ç†å†…éƒ¨æœåŠ¡å™¨é”™è¯¯"""
        # ç”Ÿäº§ç¯å¢ƒä¸æš´éœ²è¯¦ç»†é”™è¯¯ä¿¡æ¯
        message = "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯" if settings.is_production else str(exc)
        
        return JSONResponse(
            status_code=500,
            content={
                "success": False,
                "error_code": "INTERNAL_ERROR",
                "message": message,
                "error_id": error_id,
                "timestamp": datetime.utcnow().isoformat()
            }
        )
```

##### ä¸šåŠ¡å¼‚å¸¸å®šä¹‰

```python
# exceptions/business_exceptions.py
from fastapi import HTTPException
from typing import Optional, Dict, Any

class BusinessException(HTTPException):
    """ä¸šåŠ¡å¼‚å¸¸åŸºç±»"""
    
    def __init__(
        self,
        status_code: int,
        error_code: str,
        message: str,
        details: Optional[Dict[str, Any]] = None
    ):
        self.error_code = error_code
        self.details = details or {}
        super().__init__(status_code=status_code, detail=message)

# è®¤è¯ç›¸å…³å¼‚å¸¸
class AuthenticationException(BusinessException):
    """è®¤è¯å¼‚å¸¸"""
    
    def __init__(self, message: str = "è®¤è¯å¤±è´¥"):
        super().__init__(
            status_code=401,
            error_code="AUTH_FAILED",
            message=message
        )

class TokenExpiredException(BusinessException):
    """Tokenè¿‡æœŸå¼‚å¸¸"""
    
    def __init__(self, message: str = "è®¿é—®ä»¤ç‰Œå·²è¿‡æœŸ"):
        super().__init__(
            status_code=401,
            error_code="TOKEN_EXPIRED",
            message=message
        )

class InvalidTokenException(BusinessException):
    """æ— æ•ˆTokenå¼‚å¸¸"""
    
    def __init__(self, message: str = "æ— æ•ˆçš„è®¿é—®ä»¤ç‰Œ"):
        super().__init__(
            status_code=401,
            error_code="INVALID_TOKEN",
            message=message
        )

# æˆæƒç›¸å…³å¼‚å¸¸
class AuthorizationException(BusinessException):
    """æˆæƒå¼‚å¸¸"""
    
    def __init__(self, message: str = "æƒé™ä¸è¶³"):
        super().__init__(
            status_code=403,
            error_code="PERMISSION_DENIED",
            message=message
        )

class RoleRequiredException(BusinessException):
    """è§’è‰²æƒé™ä¸è¶³å¼‚å¸¸"""
    
    def __init__(self, required_role: str):
        super().__init__(
            status_code=403,
            error_code="ROLE_REQUIRED",
            message=f"éœ€è¦ {required_role} è§’è‰²æƒé™",
            details={"required_role": required_role}
        )

# å¡å¯†ç›¸å…³å¼‚å¸¸
class LicenseNotFoundException(BusinessException):
    """å¡å¯†ä¸å­˜åœ¨å¼‚å¸¸"""
    
    def __init__(self, license_key: str):
        super().__init__(
            status_code=404,
            error_code="LICENSE_NOT_FOUND",
            message=f"å¡å¯† {license_key} ä¸å­˜åœ¨",
            details={"license_key": license_key}
        )

class LicenseExpiredException(BusinessException):
    """å¡å¯†è¿‡æœŸå¼‚å¸¸"""
    
    def __init__(self, license_key: str, expired_at: str):
        super().__init__(
            status_code=400,
            error_code="LICENSE_EXPIRED",
            message=f"å¡å¯† {license_key} å·²äº {expired_at} è¿‡æœŸ",
            details={"license_key": license_key, "expired_at": expired_at}
        )

class LicenseAlreadyActivatedException(BusinessException):
    """å¡å¯†å·²æ¿€æ´»å¼‚å¸¸"""
    
    def __init__(self, license_key: str):
        super().__init__(
            status_code=400,
            error_code="LICENSE_ALREADY_ACTIVATED",
            message=f"å¡å¯† {license_key} å·²è¢«æ¿€æ´»",
            details={"license_key": license_key}
        )

class DeviceLimitExceededException(BusinessException):
    """è®¾å¤‡æ•°é‡è¶…é™å¼‚å¸¸"""
    
    def __init__(self, current_count: int, max_count: int):
        super().__init__(
            status_code=400,
            error_code="DEVICE_LIMIT_EXCEEDED",
            message=f"è®¾å¤‡æ•°é‡å·²è¾¾ä¸Šé™ ({current_count}/{max_count})",
            details={"current_count": current_count, "max_count": max_count}
        )

# ç”¨æˆ·ç›¸å…³å¼‚å¸¸
class UserNotFoundException(BusinessException):
    """ç”¨æˆ·ä¸å­˜åœ¨å¼‚å¸¸"""
    
    def __init__(self, identifier: str):
        super().__init__(
            status_code=404,
            error_code="USER_NOT_FOUND",
            message=f"ç”¨æˆ· {identifier} ä¸å­˜åœ¨",
            details={"identifier": identifier}
        )

class UserAlreadyExistsException(BusinessException):
    """ç”¨æˆ·å·²å­˜åœ¨å¼‚å¸¸"""
    
    def __init__(self, username: str):
        super().__init__(
            status_code=409,
            error_code="USER_ALREADY_EXISTS",
            message=f"ç”¨æˆ·å {username} å·²å­˜åœ¨",
            details={"username": username}
        )

class InvalidCredentialsException(BusinessException):
    """å‡­æ®æ— æ•ˆå¼‚å¸¸"""
    
    def __init__(self, message: str = "ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯"):
        super().__init__(
            status_code=401,
            error_code="INVALID_CREDENTIALS",
            message=message
        )

# æ•°æ®åº“ç›¸å…³å¼‚å¸¸
class DatabaseException(BusinessException):
    """æ•°æ®åº“å¼‚å¸¸"""
    
    def __init__(self, message: str = "æ•°æ®åº“æ“ä½œå¤±è´¥"):
        super().__init__(
            status_code=500,
            error_code="DATABASE_ERROR",
            message=message
        )

class DuplicateKeyException(BusinessException):
    """é‡å¤é”®å¼‚å¸¸"""
    
    def __init__(self, field: str, value: str):
        super().__init__(
            status_code=409,
            error_code="DUPLICATE_KEY",
            message=f"{field} '{value}' å·²å­˜åœ¨",
            details={"field": field, "value": value}
        )

# å¤–éƒ¨æœåŠ¡å¼‚å¸¸
class ExternalServiceException(BusinessException):
    """å¤–éƒ¨æœåŠ¡å¼‚å¸¸"""
    
    def __init__(self, service_name: str, message: str = "å¤–éƒ¨æœåŠ¡è°ƒç”¨å¤±è´¥"):
        super().__init__(
            status_code=503,
            error_code="EXTERNAL_SERVICE_ERROR",
            message=f"{service_name}: {message}",
            details={"service_name": service_name}
        )

# é™æµå¼‚å¸¸
class RateLimitException(BusinessException):
    """é™æµå¼‚å¸¸"""
    
    def __init__(self, retry_after: int = 60):
        super().__init__(
            status_code=429,
            error_code="RATE_LIMIT_EXCEEDED",
            message=f"è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯· {retry_after} ç§’åé‡è¯•",
            details={"retry_after": retry_after}
        )
```

#### 3.2.2 é”™è¯¯ç è§„èŒƒä½“ç³»

##### é”™è¯¯ç å®šä¹‰

```python
# constants/error_codes.py
from enum import Enum
from typing import Dict, Any

class ErrorCode(Enum):
    """é”™è¯¯ç æšä¸¾"""
    
    # é€šç”¨é”™è¯¯ç  (1000-1999)
    SUCCESS = ("SUCCESS", "æ“ä½œæˆåŠŸ")
    UNKNOWN_ERROR = ("UNKNOWN_ERROR", "æœªçŸ¥é”™è¯¯")
    INVALID_PARAMETER = ("INVALID_PARAMETER", "å‚æ•°æ— æ•ˆ")
    MISSING_PARAMETER = ("MISSING_PARAMETER", "ç¼ºå°‘å¿…è¦å‚æ•°")
    VALIDATION_ERROR = ("VALIDATION_ERROR", "æ•°æ®éªŒè¯å¤±è´¥")
    INTERNAL_ERROR = ("INTERNAL_ERROR", "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯")
    SERVICE_UNAVAILABLE = ("SERVICE_UNAVAILABLE", "æœåŠ¡ä¸å¯ç”¨")
    
    # è®¤è¯é”™è¯¯ç  (2000-2999)
    AUTH_FAILED = ("AUTH_FAILED", "è®¤è¯å¤±è´¥")
    TOKEN_EXPIRED = ("TOKEN_EXPIRED", "è®¿é—®ä»¤ç‰Œå·²è¿‡æœŸ")
    TOKEN_INVALID = ("TOKEN_INVALID", "æ— æ•ˆçš„è®¿é—®ä»¤ç‰Œ")
    TOKEN_MISSING = ("TOKEN_MISSING", "ç¼ºå°‘è®¿é—®ä»¤ç‰Œ")
    REFRESH_TOKEN_EXPIRED = ("REFRESH_TOKEN_EXPIRED", "åˆ·æ–°ä»¤ç‰Œå·²è¿‡æœŸ")
    REFRESH_TOKEN_INVALID = ("REFRESH_TOKEN_INVALID", "æ— æ•ˆçš„åˆ·æ–°ä»¤ç‰Œ")
    LOGIN_REQUIRED = ("LOGIN_REQUIRED", "éœ€è¦ç™»å½•")
    LOGOUT_REQUIRED = ("LOGOUT_REQUIRED", "éœ€è¦æ³¨é”€")
    
    # æˆæƒé”™è¯¯ç  (3000-3999)
    PERMISSION_DENIED = ("PERMISSION_DENIED", "æƒé™ä¸è¶³")
    ROLE_REQUIRED = ("ROLE_REQUIRED", "éœ€è¦ç‰¹å®šè§’è‰²æƒé™")
    RESOURCE_ACCESS_DENIED = ("RESOURCE_ACCESS_DENIED", "èµ„æºè®¿é—®è¢«æ‹’ç»")
    OPERATION_NOT_ALLOWED = ("OPERATION_NOT_ALLOWED", "æ“ä½œä¸è¢«å…è®¸")
    
    # ç”¨æˆ·é”™è¯¯ç  (4000-4999)
    USER_NOT_FOUND = ("USER_NOT_FOUND", "ç”¨æˆ·ä¸å­˜åœ¨")
    USER_ALREADY_EXISTS = ("USER_ALREADY_EXISTS", "ç”¨æˆ·å·²å­˜åœ¨")
    INVALID_CREDENTIALS = ("INVALID_CREDENTIALS", "ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯")
    USER_DISABLED = ("USER_DISABLED", "ç”¨æˆ·å·²è¢«ç¦ç”¨")
    USER_LOCKED = ("USER_LOCKED", "ç”¨æˆ·å·²è¢«é”å®š")
    PASSWORD_EXPIRED = ("PASSWORD_EXPIRED", "å¯†ç å·²è¿‡æœŸ")
    PASSWORD_TOO_WEAK = ("PASSWORD_TOO_WEAK", "å¯†ç å¼ºåº¦ä¸è¶³")
    
    # å¡å¯†é”™è¯¯ç  (5000-5999)
    LICENSE_NOT_FOUND = ("LICENSE_NOT_FOUND", "å¡å¯†ä¸å­˜åœ¨")
    LICENSE_EXPIRED = ("LICENSE_EXPIRED", "å¡å¯†å·²è¿‡æœŸ")
    LICENSE_NOT_ACTIVATED = ("LICENSE_NOT_ACTIVATED", "å¡å¯†æœªæ¿€æ´»")
    LICENSE_ALREADY_ACTIVATED = ("LICENSE_ALREADY_ACTIVATED", "å¡å¯†å·²æ¿€æ´»")
    LICENSE_SUSPENDED = ("LICENSE_SUSPENDED", "å¡å¯†å·²æš‚åœ")
    LICENSE_REVOKED = ("LICENSE_REVOKED", "å¡å¯†å·²æ’¤é”€")
    DEVICE_LIMIT_EXCEEDED = ("DEVICE_LIMIT_EXCEEDED", "è®¾å¤‡æ•°é‡è¶…é™")
    DEVICE_NOT_AUTHORIZED = ("DEVICE_NOT_AUTHORIZED", "è®¾å¤‡æœªæˆæƒ")
    LICENSE_QUOTA_EXCEEDED = ("LICENSE_QUOTA_EXCEEDED", "å¡å¯†é…é¢å·²ç”¨å®Œ")
    
    # åº”ç”¨é”™è¯¯ç  (6000-6999)
    APPLICATION_NOT_FOUND = ("APPLICATION_NOT_FOUND", "åº”ç”¨ä¸å­˜åœ¨")
    APPLICATION_DISABLED = ("APPLICATION_DISABLED", "åº”ç”¨å·²ç¦ç”¨")
    APPLICATION_MAINTENANCE = ("APPLICATION_MAINTENANCE", "åº”ç”¨ç»´æŠ¤ä¸­")
    VERSION_NOT_SUPPORTED = ("VERSION_NOT_SUPPORTED", "ç‰ˆæœ¬ä¸æ”¯æŒ")
    
    # æ•°æ®åº“é”™è¯¯ç  (7000-7999)
    DATABASE_ERROR = ("DATABASE_ERROR", "æ•°æ®åº“é”™è¯¯")
    DUPLICATE_KEY = ("DUPLICATE_KEY", "é‡å¤é”®å†²çª")
    FOREIGN_KEY_CONSTRAINT = ("FOREIGN_KEY_CONSTRAINT", "å¤–é”®çº¦æŸè¿å")
    DATA_INTEGRITY_ERROR = ("DATA_INTEGRITY_ERROR", "æ•°æ®å®Œæ•´æ€§é”™è¯¯")
    CONNECTION_TIMEOUT = ("CONNECTION_TIMEOUT", "æ•°æ®åº“è¿æ¥è¶…æ—¶")
    
    # å¤–éƒ¨æœåŠ¡é”™è¯¯ç  (8000-8999)
    EXTERNAL_SERVICE_ERROR = ("EXTERNAL_SERVICE_ERROR", "å¤–éƒ¨æœåŠ¡é”™è¯¯")
    PAYMENT_SERVICE_ERROR = ("PAYMENT_SERVICE_ERROR", "æ”¯ä»˜æœåŠ¡é”™è¯¯")
    EMAIL_SERVICE_ERROR = ("EMAIL_SERVICE_ERROR", "é‚®ä»¶æœåŠ¡é”™è¯¯")
    SMS_SERVICE_ERROR = ("SMS_SERVICE_ERROR", "çŸ­ä¿¡æœåŠ¡é”™è¯¯")
    
    # é™æµé”™è¯¯ç  (9000-9999)
    RATE_LIMIT_EXCEEDED = ("RATE_LIMIT_EXCEEDED", "è¯·æ±‚é¢‘ç‡è¶…é™")
    CONCURRENT_LIMIT_EXCEEDED = ("CONCURRENT_LIMIT_EXCEEDED", "å¹¶å‘æ•°è¶…é™")
    QUOTA_EXCEEDED = ("QUOTA_EXCEEDED", "é…é¢å·²ç”¨å®Œ")
    
    def __init__(self, code: str, message: str):
        self.code = code
        self.message = message
    
    @classmethod
    def get_error_info(cls, error_code: str) -> Dict[str, Any]:
        """æ ¹æ®é”™è¯¯ç è·å–é”™è¯¯ä¿¡æ¯"""
        for error in cls:
            if error.code == error_code:
                return {
                    "code": error.code,
                    "message": error.message
                }
        return {
            "code": "UNKNOWN_ERROR",
            "message": "æœªçŸ¥é”™è¯¯ç "
        }
```

##### ç”¨æˆ·å‹å¥½é”™è¯¯æ¶ˆæ¯æ¨¡æ¿

```python
# utils/error_messages.py
from typing import Dict, Any, Optional
from constants.error_codes import ErrorCode

class ErrorMessageTemplate:
    """é”™è¯¯æ¶ˆæ¯æ¨¡æ¿ç±»"""
    
    # ç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯æ¨¡æ¿
    USER_FRIENDLY_MESSAGES = {
        # è®¤è¯ç›¸å…³
        "AUTH_FAILED": "ç™»å½•å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç”¨æˆ·åå’Œå¯†ç ",
        "TOKEN_EXPIRED": "ç™»å½•å·²è¿‡æœŸï¼Œè¯·é‡æ–°ç™»å½•",
        "TOKEN_INVALID": "ç™»å½•çŠ¶æ€å¼‚å¸¸ï¼Œè¯·é‡æ–°ç™»å½•",
        "LOGIN_REQUIRED": "è¯·å…ˆç™»å½•åå†è¿›è¡Œæ“ä½œ",
        
        # æƒé™ç›¸å…³
        "PERMISSION_DENIED": "æ‚¨æ²¡æœ‰æƒé™æ‰§è¡Œæ­¤æ“ä½œ",
        "ROLE_REQUIRED": "æ‚¨çš„æƒé™ä¸è¶³ï¼Œæ— æ³•æ‰§è¡Œæ­¤æ“ä½œ",
        
        # ç”¨æˆ·ç›¸å…³
        "USER_NOT_FOUND": "ç”¨æˆ·ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥ç”¨æˆ·ä¿¡æ¯",
        "USER_ALREADY_EXISTS": "ç”¨æˆ·åå·²è¢«ä½¿ç”¨ï¼Œè¯·é€‰æ‹©å…¶ä»–ç”¨æˆ·å",
        "INVALID_CREDENTIALS": "ç”¨æˆ·åæˆ–å¯†ç é”™è¯¯ï¼Œè¯·é‡æ–°è¾“å…¥",
        "USER_DISABLED": "è´¦æˆ·å·²è¢«ç¦ç”¨ï¼Œè¯·è”ç³»ç®¡ç†å‘˜",
        "USER_LOCKED": "è´¦æˆ·å·²è¢«é”å®šï¼Œè¯·è”ç³»ç®¡ç†å‘˜",
        
        # å¡å¯†ç›¸å…³
        "LICENSE_NOT_FOUND": "å¡å¯†ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥å¡å¯†æ˜¯å¦æ­£ç¡®",
        "LICENSE_EXPIRED": "å¡å¯†å·²è¿‡æœŸï¼Œè¯·è”ç³»å®¢æœç»­è´¹",
        "LICENSE_ALREADY_ACTIVATED": "å¡å¯†å·²è¢«æ¿€æ´»ï¼Œæ— æ³•é‡å¤ä½¿ç”¨",
        "DEVICE_LIMIT_EXCEEDED": "è®¾å¤‡æ•°é‡å·²è¾¾ä¸Šé™ï¼Œè¯·å…ˆè§£ç»‘å…¶ä»–è®¾å¤‡",
        "DEVICE_NOT_AUTHORIZED": "å½“å‰è®¾å¤‡æœªæˆæƒï¼Œè¯·å…ˆæ¿€æ´»å¡å¯†",
        
        # åº”ç”¨ç›¸å…³
        "APPLICATION_NOT_FOUND": "åº”ç”¨ä¸å­˜åœ¨æˆ–å·²ä¸‹çº¿",
        "APPLICATION_DISABLED": "åº”ç”¨å·²æš‚åœæœåŠ¡ï¼Œè¯·ç¨åå†è¯•",
        "APPLICATION_MAINTENANCE": "åº”ç”¨æ­£åœ¨ç»´æŠ¤ä¸­ï¼Œè¯·ç¨åå†è¯•",
        
        # ç³»ç»Ÿç›¸å…³
        "INTERNAL_ERROR": "ç³»ç»Ÿç¹å¿™ï¼Œè¯·ç¨åå†è¯•",
        "SERVICE_UNAVAILABLE": "æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åå†è¯•",
        "RATE_LIMIT_EXCEEDED": "æ“ä½œè¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•",
        "VALIDATION_ERROR": "è¾“å…¥ä¿¡æ¯æœ‰è¯¯ï¼Œè¯·æ£€æŸ¥åé‡æ–°æäº¤",
    }
    
    # æŠ€æœ¯é”™è¯¯æ¶ˆæ¯ï¼ˆç”¨äºæ—¥å¿—è®°å½•ï¼‰
    TECHNICAL_MESSAGES = {
        "DATABASE_ERROR": "Database operation failed",
        "CONNECTION_TIMEOUT": "Database connection timeout",
        "EXTERNAL_SERVICE_ERROR": "External service call failed",
        "DUPLICATE_KEY": "Duplicate key constraint violation",
    }
    
    @classmethod
    def get_user_message(
        cls, 
        error_code: str, 
        context: Optional[Dict[str, Any]] = None
    ) -> str:
        """è·å–ç”¨æˆ·å‹å¥½çš„é”™è¯¯æ¶ˆæ¯"""
        base_message = cls.USER_FRIENDLY_MESSAGES.get(
            error_code, 
            "æ“ä½œå¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
        )
        
        # æ ¹æ®ä¸Šä¸‹æ–‡ä¿¡æ¯å®šåˆ¶æ¶ˆæ¯
        if context:
            if error_code == "DEVICE_LIMIT_EXCEEDED":
                current = context.get("current_count", 0)
                max_count = context.get("max_count", 0)
                return f"è®¾å¤‡æ•°é‡å·²è¾¾ä¸Šé™ ({current}/{max_count})ï¼Œè¯·å…ˆè§£ç»‘å…¶ä»–è®¾å¤‡"
            
            elif error_code == "LICENSE_EXPIRED":
                expired_at = context.get("expired_at", "")
                if expired_at:
                    return f"å¡å¯†å·²äº {expired_at} è¿‡æœŸï¼Œè¯·è”ç³»å®¢æœç»­è´¹"
            
            elif error_code == "RATE_LIMIT_EXCEEDED":
                retry_after = context.get("retry_after", 60)
                return f"æ“ä½œè¿‡äºé¢‘ç¹ï¼Œè¯· {retry_after} ç§’åé‡è¯•"
        
        return base_message
    
    @classmethod
    def get_technical_message(
        cls, 
        error_code: str, 
        original_error: Optional[str] = None
    ) -> str:
        """è·å–æŠ€æœ¯é”™è¯¯æ¶ˆæ¯"""
        base_message = cls.TECHNICAL_MESSAGES.get(
            error_code, 
            f"Technical error: {error_code}"
        )
        
        if original_error:
            return f"{base_message}: {original_error}"
        
        return base_message
    
    @classmethod
    def format_validation_errors(cls, errors: list) -> str:
        """æ ¼å¼åŒ–éªŒè¯é”™è¯¯æ¶ˆæ¯"""
        if not errors:
            return "æ•°æ®éªŒè¯å¤±è´¥"
        
        if len(errors) == 1:
            error = errors[0]
            field = error.get("field", "æœªçŸ¥å­—æ®µ")
            message = error.get("message", "æ ¼å¼é”™è¯¯")
            return f"{field}: {message}"
        
        # å¤šä¸ªé”™è¯¯æ—¶è¿”å›æ±‡æ€»æ¶ˆæ¯
        return f"å‘ç° {len(errors)} ä¸ªè¾“å…¥é”™è¯¯ï¼Œè¯·æ£€æŸ¥åé‡æ–°æäº¤"
```

### 3.3 å®‰å…¨å¢å¼ºæªæ–½

#### 3.3.1 å¯†é’¥è½®æ¢æœºåˆ¶

##### å¯†é’¥ç®¡ç†æœåŠ¡

```python
# security/key_manager.py
from typing import Dict, Optional, Tuple
from datetime import datetime, timedelta
from cryptography.fernet import Fernet
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.kdf.pbkdf2 import PBKDF2HMAC
from cryptography.hazmat.primitives.asymmetric import rsa, padding
from cryptography.hazmat.primitives import serialization
import secrets
import base64
import json
import asyncio
from sqlalchemy.ext.asyncio import AsyncSession
from database.models import SecurityKey
from config.settings import settings
import logging

logger = logging.getLogger(__name__)

class KeyManager:
    """å¯†é’¥ç®¡ç†å™¨"""
    
    def __init__(self):
        self._current_keys: Dict[str, Dict] = {}
        self._rotation_tasks: Dict[str, asyncio.Task] = {}
        self._lock = asyncio.Lock()
    
    async def initialize(self, db: AsyncSession):
        """åˆå§‹åŒ–å¯†é’¥ç®¡ç†å™¨"""
        await self._load_keys_from_db(db)
        await self._start_rotation_tasks()
    
    async def _load_keys_from_db(self, db: AsyncSession):
        """ä»æ•°æ®åº“åŠ è½½å¯†é’¥"""
        try:
            # æŸ¥è¯¢æ‰€æœ‰æ´»è·ƒçš„å¯†é’¥
            result = await db.execute(
                "SELECT * FROM security_keys WHERE status = 'active' ORDER BY created_at DESC"
            )
            keys = result.fetchall()
            
            for key_record in keys:
                self._current_keys[key_record.key_type] = {
                    'id': key_record.id,
                    'key_data': key_record.key_data,
                    'created_at': key_record.created_at,
                    'expires_at': key_record.expires_at,
                    'algorithm': key_record.algorithm
                }
            
            logger.info(f"å·²åŠ è½½ {len(keys)} ä¸ªå¯†é’¥")
        except Exception as e:
            logger.error(f"åŠ è½½å¯†é’¥å¤±è´¥: {e}")
            raise
    
    async def _start_rotation_tasks(self):
        """å¯åŠ¨å¯†é’¥è½®æ¢ä»»åŠ¡"""
        key_types = ['jwt_signing', 'data_encryption', 'api_signing']
        
        for key_type in key_types:
            task = asyncio.create_task(self._rotation_worker(key_type))
            self._rotation_tasks[key_type] = task
            logger.info(f"å·²å¯åŠ¨ {key_type} å¯†é’¥è½®æ¢ä»»åŠ¡")
    
    async def _rotation_worker(self, key_type: str):
        """å¯†é’¥è½®æ¢å·¥ä½œè¿›ç¨‹"""
        while True:
            try:
                await self._check_and_rotate_key(key_type)
                # æ¯å°æ—¶æ£€æŸ¥ä¸€æ¬¡
                await asyncio.sleep(3600)
            except Exception as e:
                logger.error(f"å¯†é’¥è½®æ¢ä»»åŠ¡ {key_type} å‡ºé”™: {e}")
                await asyncio.sleep(300)  # å‡ºé”™å5åˆ†é’Ÿé‡è¯•
    
    async def _check_and_rotate_key(self, key_type: str):
        """æ£€æŸ¥å¹¶è½®æ¢å¯†é’¥"""
        async with self._lock:
            current_key = self._current_keys.get(key_type)
            
            if not current_key:
                # æ²¡æœ‰å½“å‰å¯†é’¥ï¼Œç”Ÿæˆæ–°çš„
                await self._generate_new_key(key_type)
                return
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦è½®æ¢
            expires_at = current_key['expires_at']
            now = datetime.utcnow()
            
            # æå‰24å°æ—¶å¼€å§‹è½®æ¢
            rotation_time = expires_at - timedelta(hours=24)
            
            if now >= rotation_time:
                logger.info(f"å¼€å§‹è½®æ¢ {key_type} å¯†é’¥")
                await self._rotate_key(key_type)
    
    async def _generate_new_key(self, key_type: str) -> Dict:
        """ç”Ÿæˆæ–°å¯†é’¥"""
        if key_type == 'jwt_signing':
            return await self._generate_rsa_key_pair(key_type)
        elif key_type in ['data_encryption', 'api_signing']:
            return await self._generate_symmetric_key(key_type)
        else:
            raise ValueError(f"ä¸æ”¯æŒçš„å¯†é’¥ç±»å‹: {key_type}")
    
    async def _generate_rsa_key_pair(self, key_type: str) -> Dict:
        """ç”ŸæˆRSAå¯†é’¥å¯¹"""
        # ç”Ÿæˆç§é’¥
        private_key = rsa.generate_private_key(
            public_exponent=65537,
            key_size=2048
        )
        
        # åºåˆ—åŒ–ç§é’¥
        private_pem = private_key.private_bytes(
            encoding=serialization.Encoding.PEM,
            format=serialization.PrivateFormat.PKCS8,
            encryption_algorithm=serialization.NoEncryption()
        )
        
        # è·å–å…¬é’¥
        public_key = private_key.public_key()
        public_pem = public_key.public_bytes(
            encoding=serialization.Encoding.PEM,
            format=serialization.PublicFormat.SubjectPublicKeyInfo
        )
        
        key_data = {
            'private_key': base64.b64encode(private_pem).decode('utf-8'),
            'public_key': base64.b64encode(public_pem).decode('utf-8')
        }
        
        return await self._save_key_to_db(
            key_type=key_type,
            key_data=json.dumps(key_data),
            algorithm='RSA-2048'
        )
    
    async def _generate_symmetric_key(self, key_type: str) -> Dict:
        """ç”Ÿæˆå¯¹ç§°å¯†é’¥"""
        # ç”Ÿæˆ32å­—èŠ‚çš„éšæœºå¯†é’¥
        key = secrets.token_bytes(32)
        key_data = {
            'key': base64.b64encode(key).decode('utf-8')
        }
        
        return await self._save_key_to_db(
            key_type=key_type,
            key_data=json.dumps(key_data),
            algorithm='AES-256'
        )
    
    async def _save_key_to_db(self, key_type: str, key_data: str, algorithm: str) -> Dict:
        """ä¿å­˜å¯†é’¥åˆ°æ•°æ®åº“"""
        from database.connection import get_db
        
        async with get_db() as db:
            try:
                # åˆ›å»ºæ–°å¯†é’¥è®°å½•
                new_key = SecurityKey(
                    key_type=key_type,
                    key_data=key_data,
                    algorithm=algorithm,
                    created_at=datetime.utcnow(),
                    expires_at=datetime.utcnow() + timedelta(days=30),  # 30å¤©è¿‡æœŸ
                    status='active'
                )
                
                db.add(new_key)
                await db.commit()
                await db.refresh(new_key)
                
                # æ›´æ–°å†…å­˜ä¸­çš„å¯†é’¥
                key_info = {
                    'id': new_key.id,
                    'key_data': key_data,
                    'created_at': new_key.created_at,
                    'expires_at': new_key.expires_at,
                    'algorithm': algorithm
                }
                
                self._current_keys[key_type] = key_info
                
                logger.info(f"å·²ç”Ÿæˆæ–°çš„ {key_type} å¯†é’¥ï¼ŒID: {new_key.id}")
                return key_info
                
            except Exception as e:
                await db.rollback()
                logger.error(f"ä¿å­˜å¯†é’¥å¤±è´¥: {e}")
                raise
    
    async def _rotate_key(self, key_type: str):
        """è½®æ¢å¯†é’¥"""
        from database.connection import get_db
        
        async with get_db() as db:
            try:
                # å°†å½“å‰å¯†é’¥æ ‡è®°ä¸ºå³å°†è¿‡æœŸ
                current_key = self._current_keys.get(key_type)
                if current_key:
                    await db.execute(
                        "UPDATE security_keys SET status = 'rotating' WHERE id = :key_id",
                        {'key_id': current_key['id']}
                    )
                
                # ç”Ÿæˆæ–°å¯†é’¥
                new_key = await self._generate_new_key(key_type)
                
                # ç­‰å¾…ä¸€æ®µæ—¶é—´è®©æ–°å¯†é’¥ç”Ÿæ•ˆ
                await asyncio.sleep(60)
                
                # å°†æ—§å¯†é’¥æ ‡è®°ä¸ºå·²è¿‡æœŸ
                if current_key:
                    await db.execute(
                        "UPDATE security_keys SET status = 'expired' WHERE id = :key_id",
                        {'key_id': current_key['id']}
                    )
                
                await db.commit()
                
                logger.info(f"å¯†é’¥ {key_type} è½®æ¢å®Œæˆ")
                
                # å‘é€å¯†é’¥è½®æ¢é€šçŸ¥
                await self._notify_key_rotation(key_type, new_key)
                
            except Exception as e:
                await db.rollback()
                logger.error(f"å¯†é’¥è½®æ¢å¤±è´¥: {e}")
                raise
    
    async def _notify_key_rotation(self, key_type: str, new_key: Dict):
        """é€šçŸ¥å¯†é’¥è½®æ¢"""
        # è¿™é‡Œå¯ä»¥å‘é€é€šçŸ¥ç»™ç›¸å…³æœåŠ¡
        # ä¾‹å¦‚ï¼šæ›´æ–°ç¼“å­˜ã€é€šçŸ¥å…¶ä»–å¾®æœåŠ¡ç­‰
        logger.info(f"å¯†é’¥è½®æ¢é€šçŸ¥: {key_type} -> {new_key['id']}")
    
    def get_current_key(self, key_type: str) -> Optional[Dict]:
        """è·å–å½“å‰å¯†é’¥"""
        return self._current_keys.get(key_type)
    
    def get_jwt_signing_key(self) -> Optional[str]:
        """è·å–JWTç­¾åå¯†é’¥"""
        key_info = self.get_current_key('jwt_signing')
        if key_info:
            key_data = json.loads(key_info['key_data'])
            return key_data.get('private_key')
        return None
    
    def get_jwt_public_key(self) -> Optional[str]:
        """è·å–JWTå…¬é’¥"""
        key_info = self.get_current_key('jwt_signing')
        if key_info:
            key_data = json.loads(key_info['key_data'])
            return key_data.get('public_key')
        return None
    
    def get_encryption_key(self) -> Optional[bytes]:
        """è·å–æ•°æ®åŠ å¯†å¯†é’¥"""
        key_info = self.get_current_key('data_encryption')
        if key_info:
            key_data = json.loads(key_info['key_data'])
            return base64.b64decode(key_data['key'].encode('utf-8'))
        return None
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        # å–æ¶ˆæ‰€æœ‰è½®æ¢ä»»åŠ¡
        for task in self._rotation_tasks.values():
            task.cancel()
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        await asyncio.gather(*self._rotation_tasks.values(), return_exceptions=True)
        
        logger.info("å¯†é’¥ç®¡ç†å™¨å·²æ¸…ç†")

# å…¨å±€å¯†é’¥ç®¡ç†å™¨å®ä¾‹
key_manager = KeyManager()
```

##### å¯†é’¥è½®æ¢æ•°æ®åº“è¡¨

```sql
-- å¯†é’¥ç®¡ç†è¡¨
CREATE TABLE security_keys (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    key_type VARCHAR(50) NOT NULL COMMENT 'å¯†é’¥ç±»å‹ï¼šjwt_signing, data_encryption, api_signing',
    key_data TEXT NOT NULL COMMENT 'å¯†é’¥æ•°æ®ï¼ˆJSONæ ¼å¼ï¼‰',
    algorithm VARCHAR(20) NOT NULL COMMENT 'åŠ å¯†ç®—æ³•',
    status ENUM('active', 'rotating', 'expired') DEFAULT 'active' COMMENT 'å¯†é’¥çŠ¶æ€',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
    expires_at TIMESTAMP NOT NULL COMMENT 'è¿‡æœŸæ—¶é—´',
    rotated_at TIMESTAMP NULL COMMENT 'è½®æ¢æ—¶é—´',
    created_by VARCHAR(50) DEFAULT 'system' COMMENT 'åˆ›å»ºè€…',
    
    INDEX idx_key_type_status (key_type, status),
    INDEX idx_expires_at (expires_at),
    INDEX idx_created_at (created_at)
) COMMENT='å®‰å…¨å¯†é’¥ç®¡ç†è¡¨';

-- å¯†é’¥ä½¿ç”¨è®°å½•è¡¨
CREATE TABLE key_usage_logs (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    key_id BIGINT NOT NULL,
    operation VARCHAR(50) NOT NULL COMMENT 'æ“ä½œç±»å‹ï¼šsign, encrypt, decrypt, verify',
    user_id BIGINT NULL COMMENT 'ç”¨æˆ·ID',
    ip_address VARCHAR(45) NULL COMMENT 'IPåœ°å€',
    user_agent TEXT NULL COMMENT 'ç”¨æˆ·ä»£ç†',
    success BOOLEAN DEFAULT TRUE COMMENT 'æ“ä½œæ˜¯å¦æˆåŠŸ',
    error_message TEXT NULL COMMENT 'é”™è¯¯ä¿¡æ¯',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'æ“ä½œæ—¶é—´',
    
    FOREIGN KEY (key_id) REFERENCES security_keys(id),
    INDEX idx_key_id (key_id),
    INDEX idx_created_at (created_at),
    INDEX idx_user_id (user_id)
) COMMENT='å¯†é’¥ä½¿ç”¨æ—¥å¿—è¡¨';
```

#### 3.3.2 APIé˜²æŠ¤ç­–ç•¥

##### é™æµä¸­é—´ä»¶

```python
# middleware/rate_limiter.py
from fastapi import Request, HTTPException
from fastapi.responses import JSONResponse
from starlette.middleware.base import BaseHTTPMiddleware
from typing import Dict, Optional, Tuple
import time
import asyncio
from collections import defaultdict, deque
import redis.asyncio as redis
from config.settings import settings
import logging
import hashlib
import json

logger = logging.getLogger(__name__)

class RateLimiter:
    """é™æµå™¨"""
    
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
        self.local_cache = defaultdict(lambda: deque())
        self.cache_lock = asyncio.Lock()
    
    async def is_allowed(
        self, 
        key: str, 
        limit: int, 
        window: int,
        identifier: str = "default"
    ) -> Tuple[bool, Dict]:
        """æ£€æŸ¥æ˜¯å¦å…è®¸è¯·æ±‚"""
        now = time.time()
        
        # ä½¿ç”¨æ»‘åŠ¨çª—å£ç®—æ³•
        return await self._sliding_window_check(key, limit, window, now, identifier)
    
    async def _sliding_window_check(
        self, 
        key: str, 
        limit: int, 
        window: int, 
        now: float,
        identifier: str
    ) -> Tuple[bool, Dict]:
        """æ»‘åŠ¨çª—å£é™æµæ£€æŸ¥"""
        try:
            # Redis Luaè„šæœ¬å®ç°åŸå­æ€§æ»‘åŠ¨çª—å£
            lua_script = """
            local key = KEYS[1]
            local window = tonumber(ARGV[1])
            local limit = tonumber(ARGV[2])
            local now = tonumber(ARGV[3])
            local identifier = ARGV[4]
            
            -- æ¸…ç†è¿‡æœŸè®°å½•
            redis.call('ZREMRANGEBYSCORE', key, 0, now - window)
            
            -- è·å–å½“å‰çª—å£å†…çš„è¯·æ±‚æ•°
            local current = redis.call('ZCARD', key)
            
            if current < limit then
                -- æ·»åŠ å½“å‰è¯·æ±‚
                redis.call('ZADD', key, now, identifier .. ':' .. now)
                redis.call('EXPIRE', key, window + 1)
                return {1, current + 1, limit - current - 1}
            else
                return {0, current, 0}
            end
            """
            
            result = await self.redis.eval(
                lua_script,
                1,
                key,
                window,
                limit,
                now,
                identifier
            )
            
            allowed = bool(result[0])
            current_requests = int(result[1])
            remaining = int(result[2])
            
            # è®¡ç®—é‡ç½®æ—¶é—´
            reset_time = int(now + window)
            
            return allowed, {
                'allowed': allowed,
                'limit': limit,
                'remaining': remaining,
                'reset_time': reset_time,
                'current': current_requests
            }
            
        except Exception as e:
            logger.error(f"é™æµæ£€æŸ¥å¤±è´¥: {e}")
            # é™çº§åˆ°æœ¬åœ°ç¼“å­˜
            return await self._local_fallback_check(key, limit, window, now)
    
    async def _local_fallback_check(
        self, 
        key: str, 
        limit: int, 
        window: int, 
        now: float
    ) -> Tuple[bool, Dict]:
        """æœ¬åœ°ç¼“å­˜é™çº§æ£€æŸ¥"""
        async with self.cache_lock:
            requests = self.local_cache[key]
            
            # æ¸…ç†è¿‡æœŸè¯·æ±‚
            while requests and requests[0] <= now - window:
                requests.popleft()
            
            current_requests = len(requests)
            
            if current_requests < limit:
                requests.append(now)
                return True, {
                    'allowed': True,
                    'limit': limit,
                    'remaining': limit - current_requests - 1,
                    'reset_time': int(now + window),
                    'current': current_requests + 1
                }
            else:
                return False, {
                    'allowed': False,
                    'limit': limit,
                    'remaining': 0,
                    'reset_time': int(now + window),
                    'current': current_requests
                }

class RateLimitMiddleware(BaseHTTPMiddleware):
    """é™æµä¸­é—´ä»¶"""
    
    def __init__(self, app, redis_client: redis.Redis):
        super().__init__(app)
        self.limiter = RateLimiter(redis_client)
        
        # é™æµè§„åˆ™é…ç½®
        self.rules = {
            # å…¨å±€é™æµ
            'global': {'limit': 1000, 'window': 60},  # æ¯åˆ†é’Ÿ1000æ¬¡
            
            # IPé™æµ
            'ip': {'limit': 100, 'window': 60},  # æ¯åˆ†é’Ÿ100æ¬¡
            
            # ç”¨æˆ·é™æµ
            'user': {'limit': 200, 'window': 60},  # æ¯åˆ†é’Ÿ200æ¬¡
            
            # APIç«¯ç‚¹é™æµ
            'endpoint': {
                '/api/auth/login': {'limit': 5, 'window': 300},  # ç™»å½•ï¼š5åˆ†é’Ÿ5æ¬¡
                '/api/licenses/activate': {'limit': 10, 'window': 60},  # æ¿€æ´»ï¼šæ¯åˆ†é’Ÿ10æ¬¡
                '/api/licenses/verify': {'limit': 1000, 'window': 60},  # éªŒè¯ï¼šæ¯åˆ†é’Ÿ1000æ¬¡
            }
        }
    
    async def dispatch(self, request: Request, call_next):
        # è·å–å®¢æˆ·ç«¯æ ‡è¯†
        client_ip = self._get_client_ip(request)
        user_id = await self._get_user_id(request)
        endpoint = request.url.path
        
        # æ£€æŸ¥å„ç§é™æµè§„åˆ™
        checks = [
            ('global', 'global', 'global'),
            ('ip', f'ip:{client_ip}', client_ip),
            ('endpoint', f'endpoint:{endpoint}', f'{client_ip}:{endpoint}')
        ]
        
        if user_id:
            checks.append(('user', f'user:{user_id}', str(user_id)))
        
        # æ‰§è¡Œé™æµæ£€æŸ¥
        for rule_type, key, identifier in checks:
            if not await self._check_rate_limit(rule_type, key, identifier, endpoint):
                return await self._rate_limit_response(rule_type, key)
        
        # è®°å½•è¯·æ±‚
        await self._log_request(request, client_ip, user_id)
        
        response = await call_next(request)
        return response
    
    async def _check_rate_limit(
        self, 
        rule_type: str, 
        key: str, 
        identifier: str,
        endpoint: str
    ) -> bool:
        """æ£€æŸ¥é™æµè§„åˆ™"""
        try:
            # è·å–é™æµé…ç½®
            if rule_type == 'endpoint' and endpoint in self.rules['endpoint']:
                config = self.rules['endpoint'][endpoint]
            else:
                config = self.rules.get(rule_type, {'limit': 100, 'window': 60})
            
            allowed, info = await self.limiter.is_allowed(
                key=key,
                limit=config['limit'],
                window=config['window'],
                identifier=identifier
            )
            
            if not allowed:
                logger.warning(
                    f"é™æµè§¦å‘: {rule_type} | {key} | "
                    f"å½“å‰: {info['current']} | é™åˆ¶: {info['limit']}"
                )
            
            return allowed
            
        except Exception as e:
            logger.error(f"é™æµæ£€æŸ¥å¼‚å¸¸: {e}")
            return True  # å¼‚å¸¸æ—¶å…è®¸é€šè¿‡
    
    async def _rate_limit_response(self, rule_type: str, key: str) -> JSONResponse:
        """è¿”å›é™æµå“åº”"""
        return JSONResponse(
            status_code=429,
            content={
                'success': False,
                'error_code': 'RATE_LIMIT_EXCEEDED',
                'message': 'è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åé‡è¯•',
                'details': {
                    'rule_type': rule_type,
                    'retry_after': 60
                }
            },
            headers={
                'Retry-After': '60',
                'X-RateLimit-Rule': rule_type
            }
        )
    
    def _get_client_ip(self, request: Request) -> str:
        """è·å–å®¢æˆ·ç«¯IP"""
        # æ£€æŸ¥ä»£ç†å¤´
        forwarded_for = request.headers.get('X-Forwarded-For')
        if forwarded_for:
            return forwarded_for.split(',')[0].strip()
        
        real_ip = request.headers.get('X-Real-IP')
        if real_ip:
            return real_ip
        
        return request.client.host if request.client else '127.0.0.1'
    
    async def _get_user_id(self, request: Request) -> Optional[str]:
        """è·å–ç”¨æˆ·ID"""
        try:
            # ä»JWT tokenä¸­æå–ç”¨æˆ·ID
            auth_header = request.headers.get('Authorization')
            if auth_header and auth_header.startswith('Bearer '):
                token = auth_header[7:]
                # è¿™é‡Œåº”è¯¥è§£æJWTè·å–ç”¨æˆ·ID
                # ç®€åŒ–ç¤ºä¾‹ï¼Œå®é™…åº”è¯¥ä½¿ç”¨JWTåº“
                return 'user_from_token'
        except Exception:
            pass
        return None
    
    async def _log_request(self, request: Request, client_ip: str, user_id: Optional[str]):
        """è®°å½•è¯·æ±‚æ—¥å¿—"""
        try:
            log_data = {
                'timestamp': time.time(),
                'method': request.method,
                'path': request.url.path,
                'client_ip': client_ip,
                'user_id': user_id,
                'user_agent': request.headers.get('User-Agent', ''),
                'referer': request.headers.get('Referer', '')
            }
            
            # å¼‚æ­¥è®°å½•åˆ°æ—¥å¿—ç³»ç»Ÿ
            logger.info(f"APIè¯·æ±‚: {json.dumps(log_data)}")
            
        except Exception as e:
            logger.error(f"è®°å½•è¯·æ±‚æ—¥å¿—å¤±è´¥: {e}")
 ```

##### å®¡è®¡æ—¥å¿—å¢å¼º

```python
# security/audit_logger.py
from typing import Dict, Any, Optional, List
from datetime import datetime
from enum import Enum
import json
import hashlib
import hmac
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.primitives.asymmetric import rsa, padding
from cryptography.hazmat.primitives import serialization
from sqlalchemy.ext.asyncio import AsyncSession
from database.models import AuditLog, AuditLogSignature
from config.settings import settings
import logging
import asyncio
from concurrent.futures import ThreadPoolExecutor

logger = logging.getLogger(__name__)

class AuditEventType(Enum):
    """å®¡è®¡äº‹ä»¶ç±»å‹"""
    USER_LOGIN = "user_login"
    USER_LOGOUT = "user_logout"
    LICENSE_ACTIVATE = "license_activate"
    LICENSE_VERIFY = "license_verify"
    LICENSE_CREATE = "license_create"
    LICENSE_DELETE = "license_delete"
    USER_CREATE = "user_create"
    USER_UPDATE = "user_update"
    USER_DELETE = "user_delete"
    PERMISSION_CHANGE = "permission_change"
    SYSTEM_CONFIG = "system_config"
    DATA_EXPORT = "data_export"
    DATA_IMPORT = "data_import"
    SECURITY_ALERT = "security_alert"

class AuditSeverity(Enum):
    """å®¡è®¡ä¸¥é‡çº§åˆ«"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class AuditLogger:
    """å®¡è®¡æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self):
        self._executor = ThreadPoolExecutor(max_workers=2)
        self._signing_key = None
        self._batch_logs: List[Dict] = []
        self._batch_lock = asyncio.Lock()
        self._batch_task = None
        self._initialize_signing_key()
    
    def _initialize_signing_key(self):
        """åˆå§‹åŒ–ç­¾åå¯†é’¥"""
        try:
            # ä»å¯†é’¥ç®¡ç†å™¨è·å–ç­¾åå¯†é’¥
            from security.key_manager import key_manager
            self._signing_key = key_manager.get_current_key('api_signing')
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–å®¡è®¡æ—¥å¿—ç­¾åå¯†é’¥å¤±è´¥: {e}")
    
    async def log_event(
        self,
        event_type: AuditEventType,
        user_id: Optional[int] = None,
        resource_type: Optional[str] = None,
        resource_id: Optional[str] = None,
        action: str = "",
        details: Optional[Dict[str, Any]] = None,
        severity: AuditSeverity = AuditSeverity.MEDIUM,
        ip_address: Optional[str] = None,
        user_agent: Optional[str] = None,
        session_id: Optional[str] = None
    ):
        """è®°å½•å®¡è®¡äº‹ä»¶"""
        try:
            # æ„å»ºå®¡è®¡æ—¥å¿—è®°å½•
            log_entry = {
                'event_type': event_type.value,
                'user_id': user_id,
                'resource_type': resource_type,
                'resource_id': resource_id,
                'action': action,
                'details': details or {},
                'severity': severity.value,
                'ip_address': ip_address,
                'user_agent': user_agent,
                'session_id': session_id,
                'timestamp': datetime.utcnow().isoformat(),
                'server_id': settings.SERVER_ID,
                'version': settings.APP_VERSION
            }
            
            # ç”Ÿæˆæ—¥å¿—ç­¾å
            signature = await self._generate_signature(log_entry)
            log_entry['signature'] = signature
            
            # æ·»åŠ åˆ°æ‰¹å¤„ç†é˜Ÿåˆ—
            await self._add_to_batch(log_entry)
            
        except Exception as e:
            logger.error(f"è®°å½•å®¡è®¡æ—¥å¿—å¤±è´¥: {e}")
    
    async def _generate_signature(self, log_entry: Dict) -> str:
        """ç”Ÿæˆæ—¥å¿—ç­¾å"""
        try:
            # åˆ›å»ºè§„èŒƒåŒ–çš„æ—¥å¿—å†…å®¹
            canonical_content = self._canonicalize_log_entry(log_entry)
            
            # ä½¿ç”¨HMAC-SHA256ç”Ÿæˆç­¾å
            if self._signing_key:
                key_data = json.loads(self._signing_key['key_data'])
                signing_key = key_data['key'].encode('utf-8')
                
                signature = hmac.new(
                    signing_key,
                    canonical_content.encode('utf-8'),
                    hashlib.sha256
                ).hexdigest()
                
                return signature
            else:
                logger.warning("å®¡è®¡æ—¥å¿—ç­¾åå¯†é’¥æœªæ‰¾åˆ°")
                return ""
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆå®¡è®¡æ—¥å¿—ç­¾åå¤±è´¥: {e}")
            return ""
    
    def _canonicalize_log_entry(self, log_entry: Dict) -> str:
        """è§„èŒƒåŒ–æ—¥å¿—æ¡ç›®"""
        # æ’é™¤ç­¾åå­—æ®µï¼ŒæŒ‰é”®æ’åº
        canonical_dict = {k: v for k, v in log_entry.items() if k != 'signature'}
        
        # é€’å½’æ’åºå­—å…¸
        def sort_dict(obj):
            if isinstance(obj, dict):
                return {k: sort_dict(v) for k, v in sorted(obj.items())}
            elif isinstance(obj, list):
                return [sort_dict(item) for item in obj]
            else:
                return obj
        
        sorted_dict = sort_dict(canonical_dict)
        return json.dumps(sorted_dict, separators=(',', ':'), ensure_ascii=False)
    
    async def _add_to_batch(self, log_entry: Dict):
        """æ·»åŠ åˆ°æ‰¹å¤„ç†é˜Ÿåˆ—"""
        async with self._batch_lock:
            self._batch_logs.append(log_entry)
            
            # å¦‚æœæ‰¹å¤„ç†é˜Ÿåˆ—è¾¾åˆ°é˜ˆå€¼æˆ–è€…æ²¡æœ‰æ­£åœ¨è¿è¡Œçš„æ‰¹å¤„ç†ä»»åŠ¡ï¼Œå¯åŠ¨æ‰¹å¤„ç†
            if len(self._batch_logs) >= 10 or not self._batch_task:
                if not self._batch_task or self._batch_task.done():
                    self._batch_task = asyncio.create_task(self._process_batch())
    
    async def _process_batch(self):
        """å¤„ç†æ‰¹å¤„ç†é˜Ÿåˆ—"""
        # ç­‰å¾…ä¸€å°æ®µæ—¶é—´æ”¶é›†æ›´å¤šæ—¥å¿—
        await asyncio.sleep(1)
        
        async with self._batch_lock:
            if not self._batch_logs:
                return
            
            logs_to_process = self._batch_logs.copy()
            self._batch_logs.clear()
        
        try:
            await self._save_logs_to_database(logs_to_process)
        except Exception as e:
            logger.error(f"æ‰¹å¤„ç†ä¿å­˜å®¡è®¡æ—¥å¿—å¤±è´¥: {e}")
            # é‡æ–°æ·»åŠ åˆ°é˜Ÿåˆ—
            async with self._batch_lock:
                self._batch_logs.extend(logs_to_process)
    
    async def _save_logs_to_database(self, logs: List[Dict]):
        """ä¿å­˜æ—¥å¿—åˆ°æ•°æ®åº“"""
        from database.connection import get_db
        
        async with get_db() as db:
            try:
                # æ‰¹é‡æ’å…¥å®¡è®¡æ—¥å¿—
                audit_logs = []
                signatures = []
                
                for log_entry in logs:
                    # åˆ›å»ºå®¡è®¡æ—¥å¿—è®°å½•
                    audit_log = AuditLog(
                        event_type=log_entry['event_type'],
                        user_id=log_entry.get('user_id'),
                        resource_type=log_entry.get('resource_type'),
                        resource_id=log_entry.get('resource_id'),
                        action=log_entry['action'],
                        details=json.dumps(log_entry['details']),
                        severity=log_entry['severity'],
                        ip_address=log_entry.get('ip_address'),
                        user_agent=log_entry.get('user_agent'),
                        session_id=log_entry.get('session_id'),
                        timestamp=datetime.fromisoformat(log_entry['timestamp']),
                        server_id=log_entry['server_id'],
                        version=log_entry['version']
                    )
                    audit_logs.append(audit_log)
                
                # æ‰¹é‡æ’å…¥
                db.add_all(audit_logs)
                await db.flush()  # è·å–ç”Ÿæˆçš„ID
                
                # åˆ›å»ºç­¾åè®°å½•
                for i, log_entry in enumerate(logs):
                    if log_entry.get('signature'):
                        signature_record = AuditLogSignature(
                            audit_log_id=audit_logs[i].id,
                            signature=log_entry['signature'],
                            algorithm='HMAC-SHA256',
                            key_id=self._signing_key['id'] if self._signing_key else None
                        )
                        signatures.append(signature_record)
                
                if signatures:
                    db.add_all(signatures)
                
                await db.commit()
                
                logger.info(f"æˆåŠŸä¿å­˜ {len(logs)} æ¡å®¡è®¡æ—¥å¿—")
                
            except Exception as e:
                await db.rollback()
                logger.error(f"ä¿å­˜å®¡è®¡æ—¥å¿—åˆ°æ•°æ®åº“å¤±è´¥: {e}")
                raise
    
    async def verify_log_integrity(
        self, 
        log_id: int, 
        expected_signature: str
    ) -> bool:
        """éªŒè¯æ—¥å¿—å®Œæ•´æ€§"""
        try:
            from database.connection import get_db
            
            async with get_db() as db:
                # è·å–å®¡è®¡æ—¥å¿—
                result = await db.execute(
                    "SELECT * FROM audit_logs WHERE id = :log_id",
                    {'log_id': log_id}
                )
                log_record = result.fetchone()
                
                if not log_record:
                    return False
                
                # é‡æ„æ—¥å¿—æ¡ç›®
                log_entry = {
                    'event_type': log_record.event_type,
                    'user_id': log_record.user_id,
                    'resource_type': log_record.resource_type,
                    'resource_id': log_record.resource_id,
                    'action': log_record.action,
                    'details': json.loads(log_record.details) if log_record.details else {},
                    'severity': log_record.severity,
                    'ip_address': log_record.ip_address,
                    'user_agent': log_record.user_agent,
                    'session_id': log_record.session_id,
                    'timestamp': log_record.timestamp.isoformat(),
                    'server_id': log_record.server_id,
                    'version': log_record.version
                }
                
                # é‡æ–°ç”Ÿæˆç­¾å
                regenerated_signature = await self._generate_signature(log_entry)
                
                # æ¯”è¾ƒç­¾å
                return regenerated_signature == expected_signature
                
        except Exception as e:
            logger.error(f"éªŒè¯æ—¥å¿—å®Œæ•´æ€§å¤±è´¥: {e}")
            return False
    
    async def get_audit_trail(
        self,
        user_id: Optional[int] = None,
        resource_type: Optional[str] = None,
        event_type: Optional[str] = None,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None,
        limit: int = 100
    ) -> List[Dict]:
        """è·å–å®¡è®¡è½¨è¿¹"""
        try:
            from database.connection import get_db
            
            async with get_db() as db:
                query = "SELECT * FROM audit_logs WHERE 1=1"
                params = {}
                
                if user_id:
                    query += " AND user_id = :user_id"
                    params['user_id'] = user_id
                
                if resource_type:
                    query += " AND resource_type = :resource_type"
                    params['resource_type'] = resource_type
                
                if event_type:
                    query += " AND event_type = :event_type"
                    params['event_type'] = event_type
                
                if start_time:
                    query += " AND timestamp >= :start_time"
                    params['start_time'] = start_time
                
                if end_time:
                    query += " AND timestamp <= :end_time"
                    params['end_time'] = end_time
                
                query += " ORDER BY timestamp DESC LIMIT :limit"
                params['limit'] = limit
                
                result = await db.execute(query, params)
                records = result.fetchall()
                
                return [
                    {
                        'id': record.id,
                        'event_type': record.event_type,
                        'user_id': record.user_id,
                        'resource_type': record.resource_type,
                        'resource_id': record.resource_id,
                        'action': record.action,
                        'details': json.loads(record.details) if record.details else {},
                        'severity': record.severity,
                        'ip_address': record.ip_address,
                        'user_agent': record.user_agent,
                        'session_id': record.session_id,
                        'timestamp': record.timestamp.isoformat(),
                        'server_id': record.server_id,
                        'version': record.version
                    }
                    for record in records
                ]
                
        except Exception as e:
            logger.error(f"è·å–å®¡è®¡è½¨è¿¹å¤±è´¥: {e}")
            return []
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        # å¤„ç†å‰©ä½™çš„æ‰¹å¤„ç†æ—¥å¿—
        if self._batch_task and not self._batch_task.done():
            await self._batch_task
        
        # å¤„ç†å‰©ä½™çš„æ—¥å¿—
        if self._batch_logs:
            await self._save_logs_to_database(self._batch_logs)
        
        # å…³é—­çº¿ç¨‹æ± 
        self._executor.shutdown(wait=True)
        
        logger.info("å®¡è®¡æ—¥å¿—è®°å½•å™¨å·²æ¸…ç†")

# å…¨å±€å®¡è®¡æ—¥å¿—è®°å½•å™¨å®ä¾‹
audit_logger = AuditLogger()
```

##### å®¡è®¡æ—¥å¿—æ•°æ®åº“è¡¨

```sql
-- å®¡è®¡æ—¥å¿—è¡¨
CREATE TABLE audit_logs (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    event_type VARCHAR(50) NOT NULL COMMENT 'äº‹ä»¶ç±»å‹',
    user_id BIGINT NULL COMMENT 'ç”¨æˆ·ID',
    resource_type VARCHAR(50) NULL COMMENT 'èµ„æºç±»å‹',
    resource_id VARCHAR(100) NULL COMMENT 'èµ„æºID',
    action VARCHAR(100) NOT NULL COMMENT 'æ“ä½œæè¿°',
    details JSON NULL COMMENT 'è¯¦ç»†ä¿¡æ¯',
    severity ENUM('low', 'medium', 'high', 'critical') DEFAULT 'medium' COMMENT 'ä¸¥é‡çº§åˆ«',
    ip_address VARCHAR(45) NULL COMMENT 'IPåœ°å€',
    user_agent TEXT NULL COMMENT 'ç”¨æˆ·ä»£ç†',
    session_id VARCHAR(100) NULL COMMENT 'ä¼šè¯ID',
    timestamp TIMESTAMP(6) DEFAULT CURRENT_TIMESTAMP(6) COMMENT 'æ—¶é—´æˆ³',
    server_id VARCHAR(50) NULL COMMENT 'æœåŠ¡å™¨ID',
    version VARCHAR(20) NULL COMMENT 'åº”ç”¨ç‰ˆæœ¬',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
    
    INDEX idx_event_type (event_type),
    INDEX idx_user_id (user_id),
    INDEX idx_resource (resource_type, resource_id),
    INDEX idx_timestamp (timestamp),
    INDEX idx_severity (severity),
    INDEX idx_ip_address (ip_address)
) COMMENT='å®¡è®¡æ—¥å¿—è¡¨';

-- å®¡è®¡æ—¥å¿—ç­¾åè¡¨
CREATE TABLE audit_log_signatures (
    id BIGINT PRIMARY KEY AUTO_INCREMENT,
    audit_log_id BIGINT NOT NULL,
    signature VARCHAR(512) NOT NULL COMMENT 'æ—¥å¿—ç­¾å',
    algorithm VARCHAR(50) NOT NULL COMMENT 'ç­¾åç®—æ³•',
    key_id BIGINT NULL COMMENT 'ç­¾åå¯†é’¥ID',
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP COMMENT 'åˆ›å»ºæ—¶é—´',
    
    FOREIGN KEY (audit_log_id) REFERENCES audit_logs(id) ON DELETE CASCADE,
    FOREIGN KEY (key_id) REFERENCES security_keys(id),
    UNIQUE KEY uk_audit_log_id (audit_log_id),
    INDEX idx_key_id (key_id)
) COMMENT='å®¡è®¡æ—¥å¿—ç­¾åè¡¨';
```

#### 3.3.3 æ•°æ®åº“è¿æ¥æ± ä¼˜åŒ–

##### è¿æ¥æ± é…ç½®ç®¡ç†

```python
# database/pool_manager.py
from typing import Dict, Optional, Any
from sqlalchemy.ext.asyncio import create_async_engine, AsyncEngine
from sqlalchemy.pool import QueuePool, NullPool
from sqlalchemy import event
from config.settings import settings
import logging
import asyncio
import time
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)

class PoolStatus(Enum):
    """è¿æ¥æ± çŠ¶æ€"""
    HEALTHY = "healthy"
    WARNING = "warning"
    CRITICAL = "critical"
    UNAVAILABLE = "unavailable"

@dataclass
class PoolMetrics:
    """è¿æ¥æ± æŒ‡æ ‡"""
    total_connections: int = 0
    active_connections: int = 0
    idle_connections: int = 0
    checked_out_connections: int = 0
    overflow_connections: int = 0
    invalid_connections: int = 0
    pool_size: int = 0
    max_overflow: int = 0
    status: PoolStatus = PoolStatus.HEALTHY
    last_updated: float = 0

class DatabasePoolManager:
    """æ•°æ®åº“è¿æ¥æ± ç®¡ç†å™¨"""
    
    def __init__(self):
        self._engines: Dict[str, AsyncEngine] = {}
        self._metrics: Dict[str, PoolMetrics] = {}
        self._monitor_task: Optional[asyncio.Task] = None
        self._health_check_interval = 30  # 30ç§’æ£€æŸ¥ä¸€æ¬¡
    
    async def initialize(self):
        """åˆå§‹åŒ–è¿æ¥æ± ç®¡ç†å™¨"""
        try:
            # åˆ›å»ºä¸»æ•°æ®åº“è¿æ¥æ± 
            await self._create_engine(
                'primary',
                settings.DATABASE_URL,
                {
                    'pool_size': settings.DB_POOL_SIZE,
                    'max_overflow': settings.DB_MAX_OVERFLOW,
                    'pool_timeout': settings.DB_POOL_TIMEOUT,
                    'pool_recycle': settings.DB_POOL_RECYCLE,
                    'pool_pre_ping': True,
                    'poolclass': QueuePool
                }
            )
            
            # å¦‚æœé…ç½®äº†åªè¯»æ•°æ®åº“ï¼Œåˆ›å»ºåªè¯»è¿æ¥æ± 
            if hasattr(settings, 'DATABASE_READONLY_URL') and settings.DATABASE_READONLY_URL:
                await self._create_engine(
                    'readonly',
                    settings.DATABASE_READONLY_URL,
                    {
                        'pool_size': settings.DB_READONLY_POOL_SIZE or 5,
                        'max_overflow': settings.DB_READONLY_MAX_OVERFLOW or 10,
                        'pool_timeout': 30,
                        'pool_recycle': 3600,
                        'pool_pre_ping': True,
                        'poolclass': QueuePool
                    }
                )
            
            # å¯åŠ¨ç›‘æ§ä»»åŠ¡
            self._monitor_task = asyncio.create_task(self._monitor_pools())
            
            logger.info("æ•°æ®åº“è¿æ¥æ± ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"åˆå§‹åŒ–æ•°æ®åº“è¿æ¥æ± å¤±è´¥: {e}")
            raise
    
    async def _create_engine(self, name: str, url: str, pool_config: Dict[str, Any]):
        """åˆ›å»ºæ•°æ®åº“å¼•æ“"""
        try:
            engine = create_async_engine(
                url,
                echo=settings.DEBUG,
                **pool_config
            )
            
            # æ³¨å†Œè¿æ¥æ± äº‹ä»¶ç›‘å¬å™¨
            self._register_pool_events(engine, name)
            
            self._engines[name] = engine
            self._metrics[name] = PoolMetrics(
                pool_size=pool_config.get('pool_size', 5),
                max_overflow=pool_config.get('max_overflow', 10)
            )
            
            logger.info(f"å·²åˆ›å»ºæ•°æ®åº“å¼•æ“: {name}")
            
        except Exception as e:
            logger.error(f"åˆ›å»ºæ•°æ®åº“å¼•æ“ {name} å¤±è´¥: {e}")
            raise
    
    def _register_pool_events(self, engine: AsyncEngine, name: str):
        """æ³¨å†Œè¿æ¥æ± äº‹ä»¶ç›‘å¬å™¨"""
        
        @event.listens_for(engine.sync_engine.pool, "connect")
        def on_connect(dbapi_conn, connection_record):
            logger.debug(f"è¿æ¥æ±  {name}: æ–°è¿æ¥å»ºç«‹")
        
        @event.listens_for(engine.sync_engine.pool, "checkout")
        def on_checkout(dbapi_conn, connection_record, connection_proxy):
            logger.debug(f"è¿æ¥æ±  {name}: è¿æ¥è¢«æ£€å‡º")
        
        @event.listens_for(engine.sync_engine.pool, "checkin")
        def on_checkin(dbapi_conn, connection_record):
            logger.debug(f"è¿æ¥æ±  {name}: è¿æ¥è¢«å½’è¿˜")
        
        @event.listens_for(engine.sync_engine.pool, "invalidate")
        def on_invalidate(dbapi_conn, connection_record, exception):
            logger.warning(f"è¿æ¥æ±  {name}: è¿æ¥è¢«æ ‡è®°ä¸ºæ— æ•ˆ - {exception}")
    
    async def _monitor_pools(self):
        """ç›‘æ§è¿æ¥æ± çŠ¶æ€"""
        while True:
            try:
                await self._update_metrics()
                await self._check_pool_health()
                await asyncio.sleep(self._health_check_interval)
            except Exception as e:
                logger.error(f"è¿æ¥æ± ç›‘æ§ä»»åŠ¡å‡ºé”™: {e}")
                await asyncio.sleep(5)
    
    async def _update_metrics(self):
        """æ›´æ–°è¿æ¥æ± æŒ‡æ ‡"""
        for name, engine in self._engines.items():
            try:
                pool = engine.pool
                metrics = self._metrics[name]
                
                # æ›´æ–°è¿æ¥æ± æŒ‡æ ‡
                metrics.total_connections = pool.size()
                metrics.checked_out_connections = pool.checkedout()
                metrics.overflow_connections = pool.overflow()
                metrics.invalid_connections = pool.invalidated()
                metrics.idle_connections = metrics.total_connections - metrics.checked_out_connections
                metrics.active_connections = metrics.checked_out_connections
                metrics.last_updated = time.time()
                
                # è¯„ä¼°è¿æ¥æ± çŠ¶æ€
                metrics.status = self._evaluate_pool_status(metrics)
                
            except Exception as e:
                logger.error(f"æ›´æ–°è¿æ¥æ±  {name} æŒ‡æ ‡å¤±è´¥: {e}")
    
    def _evaluate_pool_status(self, metrics: PoolMetrics) -> PoolStatus:
        """è¯„ä¼°è¿æ¥æ± çŠ¶æ€"""
        total_capacity = metrics.pool_size + metrics.max_overflow
        usage_ratio = metrics.active_connections / total_capacity if total_capacity > 0 else 0
        
        if metrics.invalid_connections > 0:
            return PoolStatus.CRITICAL
        elif usage_ratio >= 0.9:
            return PoolStatus.CRITICAL
        elif usage_ratio >= 0.7:
            return PoolStatus.WARNING
        else:
            return PoolStatus.HEALTHY
    
    async def _check_pool_health(self):
        """æ£€æŸ¥è¿æ¥æ± å¥åº·çŠ¶æ€"""
        for name, metrics in self._metrics.items():
            if metrics.status in [PoolStatus.CRITICAL, PoolStatus.WARNING]:
                logger.warning(
                    f"è¿æ¥æ±  {name} çŠ¶æ€å¼‚å¸¸: {metrics.status.value} | "
                    f"æ´»è·ƒè¿æ¥: {metrics.active_connections}/{metrics.pool_size + metrics.max_overflow} | "
                    f"æ— æ•ˆè¿æ¥: {metrics.invalid_connections}"
                )
                
                # å¦‚æœæ˜¯ä¸¥é‡çŠ¶æ€ï¼Œå°è¯•æ¢å¤
                if metrics.status == PoolStatus.CRITICAL:
                    await self._attempt_pool_recovery(name)
    
    async def _attempt_pool_recovery(self, pool_name: str):
        """å°è¯•æ¢å¤è¿æ¥æ± """
        try:
            engine = self._engines.get(pool_name)
            if engine:
                # æ¸…ç†æ— æ•ˆè¿æ¥
                await engine.dispose()
                logger.info(f"å·²æ¸…ç†è¿æ¥æ±  {pool_name} çš„æ— æ•ˆè¿æ¥")
        except Exception as e:
            logger.error(f"æ¢å¤è¿æ¥æ±  {pool_name} å¤±è´¥: {e}")
    
    def get_engine(self, name: str = 'primary') -> Optional[AsyncEngine]:
        """è·å–æ•°æ®åº“å¼•æ“"""
        return self._engines.get(name)
    
    def get_metrics(self, name: str = 'primary') -> Optional[PoolMetrics]:
        """è·å–è¿æ¥æ± æŒ‡æ ‡"""
        return self._metrics.get(name)
    
    def get_all_metrics(self) -> Dict[str, PoolMetrics]:
        """è·å–æ‰€æœ‰è¿æ¥æ± æŒ‡æ ‡"""
        return self._metrics.copy()
    
    async def health_check(self) -> Dict[str, Any]:
        """å¥åº·æ£€æŸ¥"""
        health_status = {
            'overall_status': 'healthy',
            'pools': {},
            'timestamp': time.time()
        }
        
        critical_count = 0
        warning_count = 0
        
        for name, metrics in self._metrics.items():
            pool_health = {
                'status': metrics.status.value,
                'active_connections': metrics.active_connections,
                'total_connections': metrics.total_connections,
                'pool_size': metrics.pool_size,
                'max_overflow': metrics.max_overflow,
                'usage_ratio': metrics.active_connections / (metrics.pool_size + metrics.max_overflow) if (metrics.pool_size + metrics.max_overflow) > 0 else 0
            }
            
            health_status['pools'][name] = pool_health
            
            if metrics.status == PoolStatus.CRITICAL:
                critical_count += 1
            elif metrics.status == PoolStatus.WARNING:
                warning_count += 1
        
        # ç¡®å®šæ•´ä½“çŠ¶æ€
        if critical_count > 0:
            health_status['overall_status'] = 'critical'
        elif warning_count > 0:
            health_status['overall_status'] = 'warning'
        
        return health_status
    
    async def cleanup(self):
        """æ¸…ç†èµ„æº"""
        # åœæ­¢ç›‘æ§ä»»åŠ¡
        if self._monitor_task:
            self._monitor_task.cancel()
            try:
                await self._monitor_task
            except asyncio.CancelledError:
                pass
        
        # å…³é—­æ‰€æœ‰æ•°æ®åº“å¼•æ“
        for name, engine in self._engines.items():
            try:
                await engine.dispose()
                logger.info(f"å·²å…³é—­æ•°æ®åº“å¼•æ“: {name}")
            except Exception as e:
                logger.error(f"å…³é—­æ•°æ®åº“å¼•æ“ {name} å¤±è´¥: {e}")
        
        self._engines.clear()
        self._metrics.clear()
        
        logger.info("æ•°æ®åº“è¿æ¥æ± ç®¡ç†å™¨å·²æ¸…ç†")

# å…¨å±€è¿æ¥æ± ç®¡ç†å™¨å®ä¾‹
pool_manager = DatabasePoolManager()
```

##### è¿æ¥æ± ç›‘æ§API

```python
# api/monitoring/pool_status.py
from fastapi import APIRouter, Depends, HTTPException
from typing import Dict, Any
from database.pool_manager import pool_manager
from auth.dependencies import require_admin
from utils.response import success_response

router = APIRouter(prefix="/api/monitoring", tags=["ç›‘æ§"])

@router.get("/pool/health")
async def get_pool_health(
    current_user = Depends(require_admin)
) -> Dict[str, Any]:
    """è·å–è¿æ¥æ± å¥åº·çŠ¶æ€"""
    try:
        health_status = await pool_manager.health_check()
        return success_response(data=health_status)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–è¿æ¥æ± çŠ¶æ€å¤±è´¥: {str(e)}")

@router.get("/pool/metrics")
async def get_pool_metrics(
    current_user = Depends(require_admin)
) -> Dict[str, Any]:
    """è·å–è¿æ¥æ± è¯¦ç»†æŒ‡æ ‡"""
    try:
        all_metrics = pool_manager.get_all_metrics()
        metrics_data = {}
        
        for name, metrics in all_metrics.items():
            metrics_data[name] = {
                'total_connections': metrics.total_connections,
                'active_connections': metrics.active_connections,
                'idle_connections': metrics.idle_connections,
                'checked_out_connections': metrics.checked_out_connections,
                'overflow_connections': metrics.overflow_connections,
                'invalid_connections': metrics.invalid_connections,
                'pool_size': metrics.pool_size,
                'max_overflow': metrics.max_overflow,
                'status': metrics.status.value,
                'last_updated': metrics.last_updated
            }
        
        return success_response(data=metrics_data)
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"è·å–è¿æ¥æ± æŒ‡æ ‡å¤±è´¥: {str(e)}")
```

#### 3.3.4 æ€§èƒ½ä¼˜åŒ–ä¸“é¡¹

##### å¡å¯†æŸ¥è¯¢ä¼˜åŒ–

```python
# services/license_service_optimized.py
from typing import List, Dict, Any, Optional, Tuple
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, func, and_, or_, text
from sqlalchemy.orm import selectinload, joinedload
from database.models import License, User, Application
from database.connection import get_db
from utils.cache import cache_manager
from utils.pagination import PaginationParams, PaginationResult
import logging
import asyncio
from datetime import datetime, timedelta

logger = logging.getLogger(__name__)

class OptimizedLicenseService:
    """ä¼˜åŒ–çš„å¡å¯†æœåŠ¡"""
    
    def __init__(self):
        self._cache_ttl = 300  # 5åˆ†é’Ÿç¼“å­˜
        self._batch_size = 1000  # æ‰¹å¤„ç†å¤§å°
    
    async def search_licenses_optimized(
        self,
        pagination: PaginationParams,
        filters: Optional[Dict[str, Any]] = None,
        sort_by: str = "created_at",
        sort_order: str = "desc"
    ) -> PaginationResult:
        """ä¼˜åŒ–çš„å¡å¯†æœç´¢"""
        try:
            # æ„å»ºç¼“å­˜é”®
            cache_key = self._build_search_cache_key(pagination, filters, sort_by, sort_order)
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = await cache_manager.get(cache_key)
            if cached_result:
                logger.debug(f"ä»ç¼“å­˜è·å–å¡å¯†æœç´¢ç»“æœ: {cache_key}")
                return PaginationResult.from_dict(cached_result)
            
            async with get_db() as db:
                # æ„å»ºä¼˜åŒ–çš„æŸ¥è¯¢
                query = await self._build_optimized_query(db, filters, sort_by, sort_order)
                
                # æ‰§è¡Œè®¡æ•°æŸ¥è¯¢ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼‰
                total_count = await self._get_optimized_count(db, filters)
                
                # æ‰§è¡Œåˆ†é¡µæŸ¥è¯¢
                offset = (pagination.page - 1) * pagination.page_size
                query = query.offset(offset).limit(pagination.page_size)
                
                # ä½¿ç”¨é¢„åŠ è½½ä¼˜åŒ–å…³è”æŸ¥è¯¢
                query = query.options(
                    selectinload(License.user),
                    selectinload(License.application)
                )
                
                result = await db.execute(query)
                licenses = result.scalars().all()
                
                # æ„å»ºç»“æœ
                items = [
                    {
                        'id': license.id,
                        'license_key': license.license_key,
                        'status': license.status,
                        'expires_at': license.expires_at.isoformat() if license.expires_at else None,
                        'created_at': license.created_at.isoformat(),
                        'user': {
                            'id': license.user.id,
                            'username': license.user.username
                        } if license.user else None,
                        'application': {
                            'id': license.application.id,
                            'name': license.application.name
                        } if license.application else None
                    }
                    for license in licenses
                ]
                
                pagination_result = PaginationResult(
                    items=items,
                    total=total_count,
                    page=pagination.page,
                    page_size=pagination.page_size,
                    total_pages=(total_count + pagination.page_size - 1) // pagination.page_size
                )
                
                # ç¼“å­˜ç»“æœ
                await cache_manager.set(
                    cache_key, 
                    pagination_result.to_dict(), 
                    ttl=self._cache_ttl
                )
                
                return pagination_result
                
        except Exception as e:
            logger.error(f"ä¼˜åŒ–å¡å¯†æœç´¢å¤±è´¥: {e}")
            raise
    
    async def _build_optimized_query(
        self, 
        db: AsyncSession, 
        filters: Optional[Dict[str, Any]], 
        sort_by: str, 
        sort_order: str
    ):
        """æ„å»ºä¼˜åŒ–çš„æŸ¥è¯¢"""
        # åŸºç¡€æŸ¥è¯¢
        query = select(License)
        
        # åº”ç”¨è¿‡æ»¤æ¡ä»¶
        if filters:
            conditions = []
            
            if filters.get('status'):
                conditions.append(License.status == filters['status'])
            
            if filters.get('user_id'):
                conditions.append(License.user_id == filters['user_id'])
            
            if filters.get('application_id'):
                conditions.append(License.application_id == filters['application_id'])
            
            if filters.get('license_key'):
                # ä½¿ç”¨ç´¢å¼•å‹å¥½çš„å‰ç¼€åŒ¹é…
                conditions.append(License.license_key.like(f"{filters['license_key']}%"))
            
            if filters.get('created_after'):
                conditions.append(License.created_at >= filters['created_after'])
            
            if filters.get('created_before'):
                conditions.append(License.created_at <= filters['created_before'])
            
            if filters.get('expires_after'):
                conditions.append(License.expires_at >= filters['expires_after'])
            
            if filters.get('expires_before'):
                conditions.append(License.expires_at <= filters['expires_before'])
            
            if conditions:
                query = query.where(and_(*conditions))
        
        # åº”ç”¨æ’åº
        sort_column = getattr(License, sort_by, License.created_at)
        if sort_order.lower() == 'desc':
            query = query.order_by(sort_column.desc())
        else:
            query = query.order_by(sort_column.asc())
        
        return query
    
    async def _get_optimized_count(
        self, 
        db: AsyncSession, 
        filters: Optional[Dict[str, Any]]
    ) -> int:
        """è·å–ä¼˜åŒ–çš„è®¡æ•°"""
        # æ„å»ºè®¡æ•°æŸ¥è¯¢
        count_query = select(func.count(License.id))
        
        # åº”ç”¨ç›¸åŒçš„è¿‡æ»¤æ¡ä»¶
        if filters:
            conditions = []
            
            if filters.get('status'):
                conditions.append(License.status == filters['status'])
            
            if filters.get('user_id'):
                conditions.append(License.user_id == filters['user_id'])
            
            if filters.get('application_id'):
                conditions.append(License.application_id == filters['application_id'])
            
            if filters.get('license_key'):
                conditions.append(License.license_key.like(f"{filters['license_key']}%"))
            
            if filters.get('created_after'):
                conditions.append(License.created_at >= filters['created_after'])
            
            if filters.get('created_before'):
                conditions.append(License.created_at <= filters['created_before'])
            
            if filters.get('expires_after'):
                conditions.append(License.expires_at >= filters['expires_after'])
            
            if filters.get('expires_before'):
                conditions.append(License.expires_at <= filters['expires_before'])
            
            if conditions:
                count_query = count_query.where(and_(*conditions))
        
        result = await db.execute(count_query)
        return result.scalar() or 0
    
    def _build_search_cache_key(
        self, 
        pagination: PaginationParams, 
        filters: Optional[Dict[str, Any]], 
        sort_by: str, 
        sort_order: str
    ) -> str:
        """æ„å»ºæœç´¢ç¼“å­˜é”®"""
        import hashlib
        import json
        
        cache_data = {
            'page': pagination.page,
            'page_size': pagination.page_size,
            'filters': filters or {},
            'sort_by': sort_by,
            'sort_order': sort_order
        }
        
        cache_str = json.dumps(cache_data, sort_keys=True)
        cache_hash = hashlib.md5(cache_str.encode()).hexdigest()
        
        return f"license_search:{cache_hash}"
    
    async def batch_update_licenses(
        self, 
        license_ids: List[int], 
        update_data: Dict[str, Any]
    ) -> Dict[str, Any]:
        """æ‰¹é‡æ›´æ–°å¡å¯†"""
        try:
            async with get_db() as db:
                # åˆ†æ‰¹å¤„ç†
                total_updated = 0
                failed_ids = []
                
                for i in range(0, len(license_ids), self._batch_size):
                    batch_ids = license_ids[i:i + self._batch_size]
                    
                    try:
                        # æ‰¹é‡æ›´æ–°
                        update_query = (
                            License.__table__.update()
                            .where(License.id.in_(batch_ids))
                            .values(**update_data)
                        )
                        
                        result = await db.execute(update_query)
                        total_updated += result.rowcount
                        
                    except Exception as e:
                        logger.error(f"æ‰¹é‡æ›´æ–°å¡å¯†å¤±è´¥ (æ‰¹æ¬¡ {i//self._batch_size + 1}): {e}")
                        failed_ids.extend(batch_ids)
                
                await db.commit()
                
                # æ¸…ç†ç›¸å…³ç¼“å­˜
                await self._clear_license_cache()
                
                return {
                    'total_updated': total_updated,
                    'failed_count': len(failed_ids),
                    'failed_ids': failed_ids
                }
                
        except Exception as e:
            logger.error(f"æ‰¹é‡æ›´æ–°å¡å¯†å¤±è´¥: {e}")
            raise
    
    async def get_license_statistics(
        self, 
        date_range: Optional[Tuple[datetime, datetime]] = None
    ) -> Dict[str, Any]:
        """è·å–å¡å¯†ç»Ÿè®¡ä¿¡æ¯"""
        try:
            cache_key = f"license_stats:{date_range[0].date() if date_range else 'all'}:{date_range[1].date() if date_range else 'all'}"
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_stats = await cache_manager.get(cache_key)
            if cached_stats:
                return cached_stats
            
            async with get_db() as db:
                # åŸºç¡€ç»Ÿè®¡æŸ¥è¯¢
                base_query = select(License)
                
                if date_range:
                    base_query = base_query.where(
                        and_(
                            License.created_at >= date_range[0],
                            License.created_at <= date_range[1]
                        )
                    )
                
                # æ€»æ•°ç»Ÿè®¡
                total_query = select(func.count(License.id)).select_from(base_query.subquery())
                total_result = await db.execute(total_query)
                total_count = total_result.scalar() or 0
                
                # çŠ¶æ€ç»Ÿè®¡
                status_query = (
                    select(License.status, func.count(License.id))
                    .select_from(base_query.subquery())
                    .group_by(License.status)
                )
                status_result = await db.execute(status_query)
                status_stats = {row[0]: row[1] for row in status_result.fetchall()}
                
                # åº”ç”¨ç»Ÿè®¡
                app_query = (
                    select(Application.name, func.count(License.id))
                    .select_from(
                        base_query.subquery().join(Application, License.application_id == Application.id)
                    )
                    .group_by(Application.name)
                    .order_by(func.count(License.id).desc())
                    .limit(10)
                )
                app_result = await db.execute(app_query)
                app_stats = {row[0]: row[1] for row in app_result.fetchall()}
                
                # æ—¶é—´è¶‹åŠ¿ç»Ÿè®¡ï¼ˆæœ€è¿‘30å¤©ï¼‰
                if not date_range:
                    trend_start = datetime.utcnow() - timedelta(days=30)
                    trend_query = (
                        select(
                            func.date(License.created_at).label('date'),
                            func.count(License.id).label('count')
                        )
                        .where(License.created_at >= trend_start)
                        .group_by(func.date(License.created_at))
                        .order_by(func.date(License.created_at))
                    )
                    trend_result = await db.execute(trend_query)
                    trend_stats = [
                        {'date': row.date.isoformat(), 'count': row.count}
                        for row in trend_result.fetchall()
                    ]
                else:
                    trend_stats = []
                
                stats = {
                    'total_count': total_count,
                    'status_distribution': status_stats,
                    'top_applications': app_stats,
                    'daily_trend': trend_stats,
                    'generated_at': datetime.utcnow().isoformat()
                }
                
                # ç¼“å­˜ç»Ÿè®¡ç»“æœ
                await cache_manager.set(cache_key, stats, ttl=600)  # 10åˆ†é’Ÿç¼“å­˜
                
                return stats
                
        except Exception as e:
            logger.error(f"è·å–å¡å¯†ç»Ÿè®¡å¤±è´¥: {e}")
            raise
    
    async def _clear_license_cache(self):
        """æ¸…ç†å¡å¯†ç›¸å…³ç¼“å­˜"""
        try:
            # æ¸…ç†æœç´¢ç¼“å­˜
            await cache_manager.delete_pattern("license_search:*")
            # æ¸…ç†ç»Ÿè®¡ç¼“å­˜
            await cache_manager.delete_pattern("license_stats:*")
            logger.info("å·²æ¸…ç†å¡å¯†ç›¸å…³ç¼“å­˜")
        except Exception as e:
            logger.error(f"æ¸…ç†å¡å¯†ç¼“å­˜å¤±è´¥: {e}")

# å…¨å±€ä¼˜åŒ–æœåŠ¡å®ä¾‹
optimized_license_service = OptimizedLicenseService()
```

##### æ•°æ®åº“ç´¢å¼•ä¼˜åŒ–

```sql
-- å¡å¯†è¡¨ç´¢å¼•ä¼˜åŒ–
-- å¤åˆç´¢å¼•ï¼šçŠ¶æ€ + åˆ›å»ºæ—¶é—´
CREATE INDEX idx_licenses_status_created ON licenses(status, created_at DESC);

-- å¤åˆç´¢å¼•ï¼šç”¨æˆ·ID + çŠ¶æ€
CREATE INDEX idx_licenses_user_status ON licenses(user_id, status);

-- å¤åˆç´¢å¼•ï¼šåº”ç”¨ID + çŠ¶æ€ + åˆ›å»ºæ—¶é—´
CREATE INDEX idx_licenses_app_status_created ON licenses(application_id, status, created_at DESC);

-- å¤åˆç´¢å¼•ï¼šè¿‡æœŸæ—¶é—´ + çŠ¶æ€ï¼ˆç”¨äºè¿‡æœŸæ£€æŸ¥ï¼‰
CREATE INDEX idx_licenses_expires_status ON licenses(expires_at, status);

-- å¡å¯†å‰ç¼€ç´¢å¼•ï¼ˆç”¨äºæ¨¡ç³Šæœç´¢ä¼˜åŒ–ï¼‰
CREATE INDEX idx_licenses_key_prefix ON licenses(license_key(10));

-- ç”¨æˆ·è¡¨ç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_users_username_status ON users(username, status);
CREATE INDEX idx_users_email_status ON users(email, status);
CREATE INDEX idx_users_created_at ON users(created_at DESC);

-- åº”ç”¨è¡¨ç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_applications_name_status ON applications(name, status);
CREATE INDEX idx_applications_created_at ON applications(created_at DESC);

-- å®¡è®¡æ—¥å¿—è¡¨ç´¢å¼•ä¼˜åŒ–
CREATE INDEX idx_audit_logs_user_event_time ON audit_logs(user_id, event_type, timestamp DESC);
CREATE INDEX idx_audit_logs_resource_time ON audit_logs(resource_type, resource_id, timestamp DESC);
CREATE INDEX idx_audit_logs_severity_time ON audit_logs(severity, timestamp DESC);
```

#### 3.3.5 å‰ç«¯ç±»å‹å®šä¹‰å®Œå–„

##### APIå“åº”ç±»å‹å®šä¹‰

```typescript
// types/api.ts
export interface ApiResponse<T = any> {
  success: boolean;
  message: string;
  data?: T;
  error?: string;
  timestamp: string;
}

export interface PaginationParams {
  page: number;
  page_size: number;
}

export interface PaginationResponse<T> {
  items: T[];
  total: number;
  page: number;
  page_size: number;
  total_pages: number;
}

// ç”¨æˆ·ç›¸å…³ç±»å‹
export interface User {
  id: number;
  username: string;
  email: string;
  role: 'admin' | 'user';
  status: 'active' | 'inactive' | 'banned';
  created_at: string;
  updated_at: string;
  last_login?: string;
  profile?: UserProfile;
}

export interface UserProfile {
  avatar?: string;
  nickname?: string;
  phone?: string;
  bio?: string;
}

export interface CreateUserRequest {
  username: string;
  email: string;
  password: string;
  role?: 'admin' | 'user';
  profile?: Partial<UserProfile>;
}

export interface UpdateUserRequest {
  email?: string;
  role?: 'admin' | 'user';
  status?: 'active' | 'inactive' | 'banned';
  profile?: Partial<UserProfile>;
}

// å¡å¯†ç›¸å…³ç±»å‹
export interface License {
  id: number;
  license_key: string;
  status: 'active' | 'inactive' | 'expired' | 'banned';
  type: 'trial' | 'standard' | 'premium' | 'enterprise';
  duration_days: number;
  max_devices: number;
  expires_at?: string;
  created_at: string;
  updated_at: string;
  user_id?: number;
  application_id: number;
  user?: User;
  application?: Application;
  devices?: Device[];
  usage_stats?: LicenseUsageStats;
}

export interface LicenseUsageStats {
  total_activations: number;
  active_devices: number;
  last_used_at?: string;
  total_usage_hours: number;
}

export interface CreateLicenseRequest {
  type: 'trial' | 'standard' | 'premium' | 'enterprise';
  duration_days: number;
  max_devices: number;
  application_id: number;
  user_id?: number;
  batch_size?: number;
}

export interface UpdateLicenseRequest {
  status?: 'active' | 'inactive' | 'expired' | 'banned';
  duration_days?: number;
  max_devices?: number;
  expires_at?: string;
}

export interface LicenseSearchFilters {
  status?: string;
  type?: string;
  user_id?: number;
  application_id?: number;
  license_key?: string;
  created_after?: string;
  created_before?: string;
  expires_after?: string;
  expires_before?: string;
}

// åº”ç”¨ç›¸å…³ç±»å‹
export interface Application {
  id: number;
  name: string;
  description?: string;
  version: string;
  status: 'active' | 'inactive' | 'maintenance';
  api_key: string;
  webhook_url?: string;
  settings: ApplicationSettings;
  created_at: string;
  updated_at: string;
  license_count?: number;
  active_license_count?: number;
}

export interface ApplicationSettings {
  max_devices_per_license: number;
  allow_device_transfer: boolean;
  require_online_verification: boolean;
  verification_interval_hours: number;
  auto_ban_on_violation: boolean;
  custom_fields?: Record<string, any>;
}

export interface CreateApplicationRequest {
  name: string;
  description?: string;
  version: string;
  webhook_url?: string;
  settings: ApplicationSettings;
}

export interface UpdateApplicationRequest {
  name?: string;
  description?: string;
  version?: string;
  status?: 'active' | 'inactive' | 'maintenance';
  webhook_url?: string;
  settings?: Partial<ApplicationSettings>;
}

// è®¾å¤‡ç›¸å…³ç±»å‹
export interface Device {
  id: number;
  device_id: string;
  device_name: string;
  device_type: 'desktop' | 'mobile' | 'server' | 'other';
  os_info: string;
  hardware_info: string;
  status: 'active' | 'inactive' | 'banned';
  first_seen_at: string;
  last_seen_at: string;
  license_id: number;
  license?: License;
}

export interface DeviceVerificationRequest {
  device_id: string;
  device_name: string;
  device_type: 'desktop' | 'mobile' | 'server' | 'other';
  os_info: string;
  hardware_info: string;
}

// å…¬å‘Šç›¸å…³ç±»å‹
export interface Announcement {
  id: number;
  title: string;
  content: string;
  type: 'info' | 'warning' | 'error' | 'success';
  priority: 'low' | 'medium' | 'high' | 'urgent';
  status: 'draft' | 'published' | 'archived';
  target_audience: 'all' | 'users' | 'admins' | 'specific';
  target_user_ids?: number[];
  target_application_ids?: number[];
  publish_at?: string;
  expires_at?: string;
  created_at: string;
  updated_at: string;
  author_id: number;
  author?: User;
  read_count: number;
  is_read?: boolean;
}

export interface CreateAnnouncementRequest {
  title: string;
  content: string;
  type: 'info' | 'warning' | 'error' | 'success';
  priority: 'low' | 'medium' | 'high' | 'urgent';
  target_audience: 'all' | 'users' | 'admins' | 'specific';
  target_user_ids?: number[];
  target_application_ids?: number[];
  publish_at?: string;
  expires_at?: string;
}

export interface UpdateAnnouncementRequest {
  title?: string;
  content?: string;
  type?: 'info' | 'warning' | 'error' | 'success';
  priority?: 'low' | 'medium' | 'high' | 'urgent';
  status?: 'draft' | 'published' | 'archived';
  target_audience?: 'all' | 'users' | 'admins' | 'specific';
  target_user_ids?: number[];
  target_application_ids?: number[];
  publish_at?: string;
  expires_at?: string;
}

// ç»Ÿè®¡ç›¸å…³ç±»å‹
export interface DashboardStats {
  total_users: number;
  active_users: number;
  total_licenses: number;
  active_licenses: number;
  total_applications: number;
  active_applications: number;
  total_devices: number;
  active_devices: number;
  recent_activities: ActivityLog[];
  license_trend: TrendData[];
  user_trend: TrendData[];
}

export interface TrendData {
  date: string;
  count: number;
}

export interface ActivityLog {
  id: number;
  action: string;
  resource_type: string;
  resource_id: string;
  user_id: number;
  user?: User;
  timestamp: string;
  details?: Record<string, any>;
}

// ç³»ç»Ÿé…ç½®ç±»å‹
export interface SystemConfig {
  site_name: string;
  site_description: string;
  site_logo?: string;
  contact_email: string;
  max_devices_per_user: number;
  default_license_duration: number;
  enable_user_registration: boolean;
  require_email_verification: boolean;
  session_timeout_minutes: number;
  max_login_attempts: number;
  lockout_duration_minutes: number;
  enable_audit_log: boolean;
  log_retention_days: number;
}

export interface UpdateSystemConfigRequest {
  site_name?: string;
  site_description?: string;
  site_logo?: string;
  contact_email?: string;
  max_devices_per_user?: number;
  default_license_duration?: number;
  enable_user_registration?: boolean;
  require_email_verification?: boolean;
  session_timeout_minutes?: number;
  max_login_attempts?: number;
  lockout_duration_minutes?: number;
  enable_audit_log?: boolean;
  log_retention_days?: number;
}

// WebSocketæ¶ˆæ¯ç±»å‹
export interface WebSocketMessage {
  type: string;
  data: any;
  timestamp: string;
}

export interface NotificationMessage extends WebSocketMessage {
  type: 'notification';
  data: {
    id: number;
    title: string;
    message: string;
    type: 'info' | 'warning' | 'error' | 'success';
    action_url?: string;
  };
}

export interface SystemStatusMessage extends WebSocketMessage {
  type: 'system_status';
  data: {
    status: 'online' | 'maintenance' | 'offline';
    message?: string;
  };
}

// é”™è¯¯ç±»å‹
export interface ApiError {
  code: string;
  message: string;
  details?: Record<string, any>;
  timestamp: string;
}

export interface ValidationError {
  field: string;
  message: string;
  code: string;
}

// è¡¨å•ç±»å‹
export interface LoginForm {
  username: string;
  password: string;
  remember_me?: boolean;
}

export interface RegisterForm {
  username: string;
  email: string;
  password: string;
  confirm_password: string;
  agree_terms: boolean;
}

export interface ChangePasswordForm {
  current_password: string;
  new_password: string;
  confirm_password: string;
}

export interface ResetPasswordForm {
  email: string;
}

export interface ResetPasswordConfirmForm {
  token: string;
  new_password: string;
  confirm_password: string;
}
```

##### APIå®¢æˆ·ç«¯ç±»å‹å®šä¹‰

```typescript
// services/api-client.ts
import axios, { AxiosInstance, AxiosRequestConfig, AxiosResponse } from 'axios';
import { ApiResponse, PaginationResponse } from '@/types/api';

class ApiClient {
  private instance: AxiosInstance;

  constructor(baseURL: string) {
    this.instance = axios.create({
      baseURL,
      timeout: 10000,
      headers: {
        'Content-Type': 'application/json',
      },
    });

    this.setupInterceptors();
  }

  private setupInterceptors() {
    // è¯·æ±‚æ‹¦æˆªå™¨
    this.instance.interceptors.request.use(
      (config) => {
        const token = localStorage.getItem('access_token');
        if (token) {
          config.headers.Authorization = `Bearer ${token}`;
        }
        return config;
      },
      (error) => Promise.reject(error)
    );

    // å“åº”æ‹¦æˆªå™¨
    this.instance.interceptors.response.use(
      (response: AxiosResponse<ApiResponse>) => response,
      (error) => {
        if (error.response?.status === 401) {
          // å¤„ç†æœªæˆæƒé”™è¯¯
          localStorage.removeItem('access_token');
          window.location.href = '/login';
        }
        return Promise.reject(error);
      }
    );
  }

  async get<T = any>(
    url: string,
    config?: AxiosRequestConfig
  ): Promise<ApiResponse<T>> {
    const response = await this.instance.get<ApiResponse<T>>(url, config);
    return response.data;
  }

  async post<T = any>(
    url: string,
    data?: any,
    config?: AxiosRequestConfig
  ): Promise<ApiResponse<T>> {
    const response = await this.instance.post<ApiResponse<T>>(url, data, config);
    return response.data;
  }

  async put<T = any>(
    url: string,
    data?: any,
    config?: AxiosRequestConfig
  ): Promise<ApiResponse<T>> {
    const response = await this.instance.put<ApiResponse<T>>(url, data, config);
    return response.data;
  }

  async delete<T = any>(
    url: string,
    config?: AxiosRequestConfig
  ): Promise<ApiResponse<T>> {
    const response = await this.instance.delete<ApiResponse<T>>(url, config);
    return response.data;
  }

  async patch<T = any>(
    url: string,
    data?: any,
    config?: AxiosRequestConfig
  ): Promise<ApiResponse<T>> {
    const response = await this.instance.patch<ApiResponse<T>>(url, data, config);
    return response.data;
  }
}

export const apiClient = new ApiClient(process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000');
```

#### 3.3.6 æ—¥å¿—ç³»ç»Ÿå‡çº§

##### ç»“æ„åŒ–æ—¥å¿—æ¡†æ¶

```python
# utils/logging_config.py
import logging
import logging.handlers
import json
import traceback
from datetime import datetime
from typing import Dict, Any, Optional
from pathlib import Path
from enum import Enum
import asyncio
from contextlib import contextmanager

class LogLevel(Enum):
    """æ—¥å¿—çº§åˆ«æšä¸¾"""
    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"

class StructuredFormatter(logging.Formatter):
    """ç»“æ„åŒ–æ—¥å¿—æ ¼å¼åŒ–å™¨"""
    
    def format(self, record: logging.LogRecord) -> str:
        """æ ¼å¼åŒ–æ—¥å¿—è®°å½•"""
        log_data = {
            'timestamp': datetime.utcnow().isoformat() + 'Z',
            'level': record.levelname,
            'logger': record.name,
            'message': record.getMessage(),
            'module': record.module,
            'function': record.funcName,
            'line': record.lineno,
            'thread_id': record.thread,
            'process_id': record.process
        }
        
        # æ·»åŠ å¼‚å¸¸ä¿¡æ¯
        if record.exc_info:
            log_data['exception'] = {
                'type': record.exc_info[0].__name__,
                'message': str(record.exc_info[1]),
                'traceback': traceback.format_exception(*record.exc_info)
            }
        
        # æ·»åŠ è‡ªå®šä¹‰å­—æ®µ
        if hasattr(record, 'extra_data'):
            log_data.update(record.extra_data)
        
        # æ·»åŠ è¯·æ±‚ä¸Šä¸‹æ–‡ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if hasattr(record, 'request_id'):
            log_data['request_id'] = record.request_id
        
        if hasattr(record, 'user_id'):
            log_data['user_id'] = record.user_id
        
        if hasattr(record, 'session_id'):
            log_data['session_id'] = record.session_id
        
        return json.dumps(log_data, ensure_ascii=False)

class AsyncFileHandler(logging.handlers.RotatingFileHandler):
    """å¼‚æ­¥æ–‡ä»¶å¤„ç†å™¨"""
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        self._write_queue = asyncio.Queue()
        self._writer_task = None
    
    async def start_writer(self):
        """å¯åŠ¨å¼‚æ­¥å†™å…¥ä»»åŠ¡"""
        if self._writer_task is None:
            self._writer_task = asyncio.create_task(self._write_worker())
    
    async def stop_writer(self):
        """åœæ­¢å¼‚æ­¥å†™å…¥ä»»åŠ¡"""
        if self._writer_task:
            self._writer_task.cancel()
            try:
                await self._writer_task
            except asyncio.CancelledError:
                pass
            self._writer_task = None
    
    async def _write_worker(self):
        """å¼‚æ­¥å†™å…¥å·¥ä½œå™¨"""
        while True:
            try:
                record = await self._write_queue.get()
                if record is None:  # åœæ­¢ä¿¡å·
                    break
                super().emit(record)
                self._write_queue.task_done()
            except asyncio.CancelledError:
                break
            except Exception as e:
                print(f"æ—¥å¿—å†™å…¥é”™è¯¯: {e}")
    
    def emit(self, record):
        """å‘é€æ—¥å¿—è®°å½•åˆ°é˜Ÿåˆ—"""
        try:
            self._write_queue.put_nowait(record)
        except asyncio.QueueFull:
            # é˜Ÿåˆ—æ»¡æ—¶ä¸¢å¼ƒæœ€æ—§çš„è®°å½•
            try:
                self._write_queue.get_nowait()
                self._write_queue.put_nowait(record)
            except asyncio.QueueEmpty:
                pass

class LoggerManager:
    """æ—¥å¿—ç®¡ç†å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.loggers: Dict[str, logging.Logger] = {}
        self.handlers: Dict[str, logging.Handler] = {}
        self._setup_logging()
    
    def _setup_logging(self):
        """è®¾ç½®æ—¥å¿—é…ç½®"""
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        log_dir = Path(self.config.get('log_dir', 'logs'))
        log_dir.mkdir(exist_ok=True)
        
        # è®¾ç½®æ ¹æ—¥å¿—çº§åˆ«
        root_logger = logging.getLogger()
        root_logger.setLevel(getattr(logging, self.config.get('level', 'INFO')))
        
        # åˆ›å»ºæ ¼å¼åŒ–å™¨
        formatter = StructuredFormatter()
        
        # åˆ›å»ºæ§åˆ¶å°å¤„ç†å™¨
        if self.config.get('console_enabled', True):
            console_handler = logging.StreamHandler()
            console_handler.setFormatter(formatter)
            console_handler.setLevel(getattr(logging, self.config.get('console_level', 'INFO')))
            root_logger.addHandler(console_handler)
            self.handlers['console'] = console_handler
        
        # åˆ›å»ºæ–‡ä»¶å¤„ç†å™¨
        if self.config.get('file_enabled', True):
            file_config = self.config.get('file', {})
            
            # åº”ç”¨æ—¥å¿—
            app_handler = logging.handlers.RotatingFileHandler(
                filename=log_dir / file_config.get('app_file', 'app.log'),
                maxBytes=file_config.get('max_bytes', 10 * 1024 * 1024),  # 10MB
                backupCount=file_config.get('backup_count', 5),
                encoding='utf-8'
            )
            app_handler.setFormatter(formatter)
            app_handler.setLevel(getattr(logging, file_config.get('level', 'INFO')))
            root_logger.addHandler(app_handler)
            self.handlers['app'] = app_handler
            
            # é”™è¯¯æ—¥å¿—
            error_handler = logging.handlers.RotatingFileHandler(
                filename=log_dir / file_config.get('error_file', 'error.log'),
                maxBytes=file_config.get('max_bytes', 10 * 1024 * 1024),
                backupCount=file_config.get('backup_count', 5),
                encoding='utf-8'
            )
            error_handler.setFormatter(formatter)
            error_handler.setLevel(logging.ERROR)
            root_logger.addHandler(error_handler)
            self.handlers['error'] = error_handler
            
            # å®¡è®¡æ—¥å¿—
            audit_handler = logging.handlers.RotatingFileHandler(
                filename=log_dir / file_config.get('audit_file', 'audit.log'),
                maxBytes=file_config.get('max_bytes', 10 * 1024 * 1024),
                backupCount=file_config.get('backup_count', 10),
                encoding='utf-8'
            )
            audit_handler.setFormatter(formatter)
            audit_handler.setLevel(logging.INFO)
            self.handlers['audit'] = audit_handler
    
    def get_logger(self, name: str) -> logging.Logger:
        """è·å–æŒ‡å®šåç§°çš„æ—¥å¿—å™¨"""
        if name not in self.loggers:
            logger = logging.getLogger(name)
            self.loggers[name] = logger
        return self.loggers[name]
    
    def get_audit_logger(self) -> logging.Logger:
        """è·å–å®¡è®¡æ—¥å¿—å™¨"""
        audit_logger = self.get_logger('audit')
        # åªä½¿ç”¨å®¡è®¡å¤„ç†å™¨
        audit_logger.handlers = [self.handlers['audit']]
        audit_logger.propagate = False
        return audit_logger
    
    @contextmanager
    def log_context(self, **context):
        """æ—¥å¿—ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        # ä¿å­˜å½“å‰ä¸Šä¸‹æ–‡
        old_context = getattr(logging.getLoggerClass(), '_context', {})
        
        # è®¾ç½®æ–°ä¸Šä¸‹æ–‡
        for logger in self.loggers.values():
            for handler in logger.handlers:
                for key, value in context.items():
                    setattr(handler, key, value)
        
        try:
            yield
        finally:
            # æ¢å¤æ—§ä¸Šä¸‹æ–‡
            for logger in self.loggers.values():
                for handler in logger.handlers:
                    for key in context.keys():
                        if hasattr(handler, key):
                            delattr(handler, key)

# æ—¥å¿—é…ç½®
LOGGING_CONFIG = {
    'level': 'INFO',
    'log_dir': 'logs',
    'console_enabled': True,
    'console_level': 'INFO',
    'file_enabled': True,
    'file': {
        'app_file': 'app.log',
        'error_file': 'error.log',
        'audit_file': 'audit.log',
        'max_bytes': 10 * 1024 * 1024,  # 10MB
        'backup_count': 5,
        'level': 'INFO'
    }
}

# å…¨å±€æ—¥å¿—ç®¡ç†å™¨
logger_manager = LoggerManager(LOGGING_CONFIG)

# ä¾¿æ·å‡½æ•°
def get_logger(name: str) -> logging.Logger:
    """è·å–æ—¥å¿—å™¨"""
    return logger_manager.get_logger(name)

def get_audit_logger() -> logging.Logger:
    """è·å–å®¡è®¡æ—¥å¿—å™¨"""
    return logger_manager.get_audit_logger()

def log_with_context(**context):
    """å¸¦ä¸Šä¸‹æ–‡çš„æ—¥å¿—è£…é¥°å™¨"""
    def decorator(func):
        def wrapper(*args, **kwargs):
            with logger_manager.log_context(**context):
                return func(*args, **kwargs)
        return wrapper
    return decorator
```

##### å®¡è®¡æ—¥å¿—å¢å¼º

```python
# services/audit_service.py
from typing import Dict, Any, Optional, List
from datetime import datetime
from enum import Enum
import json
import hashlib
import hmac
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select, and_, or_, func
from database.models import AuditLog, User
from database.connection import get_db
from utils.logging_config import get_audit_logger
from utils.crypto import get_audit_key
from utils.pagination import PaginationParams, PaginationResult

class AuditEventType(Enum):
    """å®¡è®¡äº‹ä»¶ç±»å‹"""
    USER_LOGIN = "user_login"
    USER_LOGOUT = "user_logout"
    USER_CREATE = "user_create"
    USER_UPDATE = "user_update"
    USER_DELETE = "user_delete"
    LICENSE_CREATE = "license_create"
    LICENSE_UPDATE = "license_update"
    LICENSE_DELETE = "license_delete"
    LICENSE_ACTIVATE = "license_activate"
    APPLICATION_CREATE = "application_create"
    APPLICATION_UPDATE = "application_update"
    APPLICATION_DELETE = "application_delete"
    DEVICE_REGISTER = "device_register"
    DEVICE_UPDATE = "device_update"
    DEVICE_DELETE = "device_delete"
    ANNOUNCEMENT_CREATE = "announcement_create"
    ANNOUNCEMENT_UPDATE = "announcement_update"
    ANNOUNCEMENT_DELETE = "announcement_delete"
    SYSTEM_CONFIG_UPDATE = "system_config_update"
    SECURITY_VIOLATION = "security_violation"
    API_ACCESS = "api_access"
    DATA_EXPORT = "data_export"
    DATA_IMPORT = "data_import"

class AuditSeverity(Enum):
    """å®¡è®¡ä¸¥é‡çº§åˆ«"""
    LOW = "low"
    MEDIUM = "medium"
    HIGH = "high"
    CRITICAL = "critical"

class AuditService:
    """å®¡è®¡æœåŠ¡"""
    
    def __init__(self):
        self.logger = get_audit_logger()
        self._audit_key = get_audit_key()
    
    async def log_event(
        self,
        event_type: AuditEventType,
        user_id: Optional[int] = None,
        resource_type: Optional[str] = None,
        resource_id: Optional[str] = None,
        details: Optional[Dict[str, Any]] = None,
        severity: AuditSeverity = AuditSeverity.MEDIUM,
        ip_address: Optional[str] = None,
        user_agent: Optional[str] = None,
        session_id: Optional[str] = None
    ) -> int:
        """è®°å½•å®¡è®¡äº‹ä»¶"""
        try:
            timestamp = datetime.utcnow()
            
            # æ„å»ºå®¡è®¡æ•°æ®
            audit_data = {
                'event_type': event_type.value,
                'user_id': user_id,
                'resource_type': resource_type,
                'resource_id': resource_id,
                'details': details or {},
                'severity': severity.value,
                'ip_address': ip_address,
                'user_agent': user_agent,
                'session_id': session_id,
                'timestamp': timestamp.isoformat()
            }
            
            # ç”Ÿæˆå®Œæ•´æ€§æ ¡éªŒ
            audit_data['integrity_hash'] = self._generate_integrity_hash(audit_data)
            
            # è®°å½•åˆ°æ•°æ®åº“
            async with get_db() as db:
                audit_log = AuditLog(
                    event_type=event_type.value,
                    user_id=user_id,
                    resource_type=resource_type,
                    resource_id=resource_id,
                    details=audit_data['details'],
                    severity=severity.value,
                    ip_address=ip_address,
                    user_agent=user_agent,
                    session_id=session_id,
                    timestamp=timestamp,
                    integrity_hash=audit_data['integrity_hash']
                )
                
                db.add(audit_log)
                await db.commit()
                await db.refresh(audit_log)
                
                audit_id = audit_log.id
            
            # è®°å½•åˆ°æ—¥å¿—æ–‡ä»¶
            self.logger.info(
                f"å®¡è®¡äº‹ä»¶: {event_type.value}",
                extra={
                    'extra_data': {
                        'audit_id': audit_id,
                        'event_type': event_type.value,
                        'user_id': user_id,
                        'resource_type': resource_type,
                        'resource_id': resource_id,
                        'severity': severity.value,
                        'ip_address': ip_address,
                        'session_id': session_id,
                        'details': details
                    }
                }
            )
            
            return audit_id
            
        except Exception as e:
            self.logger.error(f"è®°å½•å®¡è®¡äº‹ä»¶å¤±è´¥: {e}", exc_info=True)
            raise
    
    def _generate_integrity_hash(self, audit_data: Dict[str, Any]) -> str:
        """ç”Ÿæˆå®Œæ•´æ€§æ ¡éªŒå“ˆå¸Œ"""
        # ç§»é™¤å“ˆå¸Œå­—æ®µæœ¬èº«
        data_copy = audit_data.copy()
        data_copy.pop('integrity_hash', None)
        
        # åºåˆ—åŒ–æ•°æ®
        data_str = json.dumps(data_copy, sort_keys=True, ensure_ascii=False)
        
        # ç”ŸæˆHMACç­¾å
        signature = hmac.new(
            self._audit_key.encode('utf-8'),
            data_str.encode('utf-8'),
            hashlib.sha256
        ).hexdigest()
        
        return signature
    
    async def verify_integrity(self, audit_id: int) -> bool:
        """éªŒè¯å®¡è®¡è®°å½•å®Œæ•´æ€§"""
        try:
            async with get_db() as db:
                query = select(AuditLog).where(AuditLog.id == audit_id)
                result = await db.execute(query)
                audit_log = result.scalar_one_or_none()
                
                if not audit_log:
                    return False
                
                # é‡æ–°æ„å»ºå®¡è®¡æ•°æ®
                audit_data = {
                    'event_type': audit_log.event_type,
                    'user_id': audit_log.user_id,
                    'resource_type': audit_log.resource_type,
                    'resource_id': audit_log.resource_id,
                    'details': audit_log.details,
                    'severity': audit_log.severity,
                    'ip_address': audit_log.ip_address,
                    'user_agent': audit_log.user_agent,
                    'session_id': audit_log.session_id,
                    'timestamp': audit_log.timestamp.isoformat()
                }
                
                # éªŒè¯å“ˆå¸Œ
                expected_hash = self._generate_integrity_hash(audit_data)
                return expected_hash == audit_log.integrity_hash
                
        except Exception as e:
            self.logger.error(f"éªŒè¯å®¡è®¡è®°å½•å®Œæ•´æ€§å¤±è´¥: {e}", exc_info=True)
            return False
    
    async def search_audit_logs(
        self,
        pagination: PaginationParams,
        filters: Optional[Dict[str, Any]] = None
    ) -> PaginationResult:
        """æœç´¢å®¡è®¡æ—¥å¿—"""
        try:
            async with get_db() as db:
                # æ„å»ºæŸ¥è¯¢
                query = select(AuditLog).join(User, AuditLog.user_id == User.id, isouter=True)
                
                # åº”ç”¨è¿‡æ»¤æ¡ä»¶
                if filters:
                    conditions = []
                    
                    if filters.get('event_type'):
                        conditions.append(AuditLog.event_type == filters['event_type'])
                    
                    if filters.get('user_id'):
                        conditions.append(AuditLog.user_id == filters['user_id'])
                    
                    if filters.get('resource_type'):
                        conditions.append(AuditLog.resource_type == filters['resource_type'])
                    
                    if filters.get('severity'):
                        conditions.append(AuditLog.severity == filters['severity'])
                    
                    if filters.get('start_time'):
                        conditions.append(AuditLog.timestamp >= filters['start_time'])
                    
                    if filters.get('end_time'):
                        conditions.append(AuditLog.timestamp <= filters['end_time'])
                    
                    if filters.get('ip_address'):
                        conditions.append(AuditLog.ip_address == filters['ip_address'])
                    
                    if conditions:
                        query = query.where(and_(*conditions))
                
                # è®¡æ•°æŸ¥è¯¢
                count_query = select(func.count(AuditLog.id))
                if filters:
                    count_query = count_query.where(and_(*conditions))
                
                count_result = await db.execute(count_query)
                total_count = count_result.scalar() or 0
                
                # åˆ†é¡µæŸ¥è¯¢
                offset = (pagination.page - 1) * pagination.page_size
                query = (
                    query.order_by(AuditLog.timestamp.desc())
                    .offset(offset)
                    .limit(pagination.page_size)
                )
                
                result = await db.execute(query)
                audit_logs = result.scalars().all()
                
                # æ„å»ºç»“æœ
                items = [
                    {
                        'id': log.id,
                        'event_type': log.event_type,
                        'user_id': log.user_id,
                        'username': log.user.username if log.user else None,
                        'resource_type': log.resource_type,
                        'resource_id': log.resource_id,
                        'details': log.details,
                        'severity': log.severity,
                        'ip_address': log.ip_address,
                        'user_agent': log.user_agent,
                        'session_id': log.session_id,
                        'timestamp': log.timestamp.isoformat(),
                        'integrity_verified': await self.verify_integrity(log.id)
                    }
                    for log in audit_logs
                ]
                
                return PaginationResult(
                    items=items,
                    total=total_count,
                    page=pagination.page,
                    page_size=pagination.page_size,
                    total_pages=(total_count + pagination.page_size - 1) // pagination.page_size
                )
                
        except Exception as e:
            self.logger.error(f"æœç´¢å®¡è®¡æ—¥å¿—å¤±è´¥: {e}", exc_info=True)
            raise
    
    async def get_audit_statistics(
        self,
        start_time: Optional[datetime] = None,
        end_time: Optional[datetime] = None
    ) -> Dict[str, Any]:
        """è·å–å®¡è®¡ç»Ÿè®¡ä¿¡æ¯"""
        try:
            async with get_db() as db:
                # åŸºç¡€æŸ¥è¯¢
                base_query = select(AuditLog)
                
                if start_time:
                    base_query = base_query.where(AuditLog.timestamp >= start_time)
                
                if end_time:
                    base_query = base_query.where(AuditLog.timestamp <= end_time)
                
                # æ€»æ•°ç»Ÿè®¡
                total_query = select(func.count(AuditLog.id)).select_from(base_query.subquery())
                total_result = await db.execute(total_query)
                total_count = total_result.scalar() or 0
                
                # äº‹ä»¶ç±»å‹ç»Ÿè®¡
                event_query = (
                    select(AuditLog.event_type, func.count(AuditLog.id))
                    .select_from(base_query.subquery())
                    .group_by(AuditLog.event_type)
                    .order_by(func.count(AuditLog.id).desc())
                )
                event_result = await db.execute(event_query)
                event_stats = {row[0]: row[1] for row in event_result.fetchall()}
                
                # ä¸¥é‡çº§åˆ«ç»Ÿè®¡
                severity_query = (
                    select(AuditLog.severity, func.count(AuditLog.id))
                    .select_from(base_query.subquery())
                    .group_by(AuditLog.severity)
                )
                severity_result = await db.execute(severity_query)
                severity_stats = {row[0]: row[1] for row in severity_result.fetchall()}
                
                # ç”¨æˆ·æ´»åŠ¨ç»Ÿè®¡
                user_query = (
                    select(User.username, func.count(AuditLog.id))
                    .select_from(
                        base_query.subquery().join(User, AuditLog.user_id == User.id)
                    )
                    .group_by(User.username)
                    .order_by(func.count(AuditLog.id).desc())
                    .limit(10)
                )
                user_result = await db.execute(user_query)
                user_stats = {row[0]: row[1] for row in user_result.fetchall()}
                
                return {
                    'total_events': total_count,
                    'event_type_distribution': event_stats,
                    'severity_distribution': severity_stats,
                    'top_active_users': user_stats,
                    'generated_at': datetime.utcnow().isoformat()
                }
                
        except Exception as e:
            self.logger.error(f"è·å–å®¡è®¡ç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
            raise

# å…¨å±€å®¡è®¡æœåŠ¡å®ä¾‹
audit_service = AuditService()

# å®¡è®¡è£…é¥°å™¨
def audit_action(
    event_type: AuditEventType,
    resource_type: Optional[str] = None,
    severity: AuditSeverity = AuditSeverity.MEDIUM
):
    """å®¡è®¡åŠ¨ä½œè£…é¥°å™¨"""
    def decorator(func):
        async def wrapper(*args, **kwargs):
            try:
                # æ‰§è¡ŒåŸå‡½æ•°
                result = await func(*args, **kwargs)
                
                # è®°å½•å®¡è®¡äº‹ä»¶
                await audit_service.log_event(
                    event_type=event_type,
                    resource_type=resource_type,
                    severity=severity,
                    details={'function': func.__name__, 'args': str(args), 'kwargs': str(kwargs)}
                )
                
                return result
            except Exception as e:
                # è®°å½•é”™è¯¯å®¡è®¡äº‹ä»¶
                await audit_service.log_event(
                    event_type=AuditEventType.SECURITY_VIOLATION,
                    resource_type=resource_type,
                    severity=AuditSeverity.HIGH,
                    details={
                        'function': func.__name__,
                        'error': str(e),
                        'args': str(args),
                        'kwargs': str(kwargs)
                    }
                )
                raise
        return wrapper
    return decorator
```

#### 3.3.7 ç¼“å­˜å¤±æ•ˆç­–ç•¥ä¼˜åŒ–

##### äº‹ä»¶é©±åŠ¨ç¼“å­˜ç®¡ç†

```python
# utils/cache_manager.py
from typing import Dict, Any, Optional, List, Set, Callable
from datetime import datetime, timedelta
import asyncio
import json
import hashlib
from enum import Enum
from dataclasses import dataclass
from abc import ABC, abstractmethod
import redis.asyncio as redis
from utils.logging_config import get_logger
from utils.events import event_bus, Event

logger = get_logger(__name__)

class CacheEventType(Enum):
    """ç¼“å­˜äº‹ä»¶ç±»å‹"""
    INVALIDATE = "cache_invalidate"
    REFRESH = "cache_refresh"
    CLEAR = "cache_clear"
    EXPIRE = "cache_expire"

@dataclass
class CacheKey:
    """ç¼“å­˜é”®å®šä¹‰"""
    namespace: str
    key: str
    tags: Set[str]
    ttl: Optional[int] = None
    
    def full_key(self) -> str:
        """è·å–å®Œæ•´ç¼“å­˜é”®"""
        return f"{self.namespace}:{self.key}"
    
    def tag_keys(self) -> List[str]:
        """è·å–æ ‡ç­¾é”®åˆ—è¡¨"""
        return [f"tag:{tag}" for tag in self.tags]

class CacheStrategy(ABC):
    """ç¼“å­˜ç­–ç•¥æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    async def should_cache(self, key: CacheKey, data: Any) -> bool:
        """åˆ¤æ–­æ˜¯å¦åº”è¯¥ç¼“å­˜"""
        pass
    
    @abstractmethod
    async def get_ttl(self, key: CacheKey, data: Any) -> Optional[int]:
        """è·å–TTL"""
        pass
    
    @abstractmethod
    async def on_hit(self, key: CacheKey, data: Any):
        """ç¼“å­˜å‘½ä¸­å›è°ƒ"""
        pass
    
    @abstractmethod
    async def on_miss(self, key: CacheKey):
        """ç¼“å­˜æœªå‘½ä¸­å›è°ƒ"""
        pass

class DefaultCacheStrategy(CacheStrategy):
    """é»˜è®¤ç¼“å­˜ç­–ç•¥"""
    
    def __init__(self, default_ttl: int = 300):
        self.default_ttl = default_ttl
    
    async def should_cache(self, key: CacheKey, data: Any) -> bool:
        return data is not None
    
    async def get_ttl(self, key: CacheKey, data: Any) -> Optional[int]:
        return key.ttl or self.default_ttl
    
    async def on_hit(self, key: CacheKey, data: Any):
        logger.debug(f"ç¼“å­˜å‘½ä¸­: {key.full_key()}")
    
    async def on_miss(self, key: CacheKey):
        logger.debug(f"ç¼“å­˜æœªå‘½ä¸­: {key.full_key()}")

class SmartCacheStrategy(CacheStrategy):
    """æ™ºèƒ½ç¼“å­˜ç­–ç•¥"""
    
    def __init__(self):
        self.hit_counts: Dict[str, int] = {}
        self.access_times: Dict[str, List[datetime]] = {}
    
    async def should_cache(self, key: CacheKey, data: Any) -> bool:
        if data is None:
            return False
        
        # æ ¹æ®è®¿é—®é¢‘ç‡å†³å®šæ˜¯å¦ç¼“å­˜
        access_count = len(self.access_times.get(key.full_key(), []))
        return access_count >= 2  # è‡³å°‘è®¿é—®2æ¬¡æ‰ç¼“å­˜
    
    async def get_ttl(self, key: CacheKey, data: Any) -> Optional[int]:
        full_key = key.full_key()
        
        # æ ¹æ®è®¿é—®é¢‘ç‡åŠ¨æ€è°ƒæ•´TTL
        access_times = self.access_times.get(full_key, [])
        if len(access_times) < 2:
            return 60  # ä½é¢‘è®¿é—®ï¼ŒçŸ­TTL
        
        # è®¡ç®—è®¿é—®é¢‘ç‡
        recent_accesses = [
            t for t in access_times 
            if t > datetime.utcnow() - timedelta(hours=1)
        ]
        
        if len(recent_accesses) >= 10:
            return 3600  # é«˜é¢‘è®¿é—®ï¼Œé•¿TTL
        elif len(recent_accesses) >= 5:
            return 1800  # ä¸­é¢‘è®¿é—®ï¼Œä¸­ç­‰TTL
        else:
            return 300   # ä½é¢‘è®¿é—®ï¼ŒçŸ­TTL
    
    async def on_hit(self, key: CacheKey, data: Any):
        full_key = key.full_key()
        self.hit_counts[full_key] = self.hit_counts.get(full_key, 0) + 1
        
        # è®°å½•è®¿é—®æ—¶é—´
        if full_key not in self.access_times:
            self.access_times[full_key] = []
        self.access_times[full_key].append(datetime.utcnow())
        
        # æ¸…ç†æ—§çš„è®¿é—®è®°å½•
        cutoff_time = datetime.utcnow() - timedelta(hours=24)
        self.access_times[full_key] = [
            t for t in self.access_times[full_key] if t > cutoff_time
        ]
    
    async def on_miss(self, key: CacheKey):
        full_key = key.full_key()
        
        # è®°å½•è®¿é—®æ—¶é—´
        if full_key not in self.access_times:
            self.access_times[full_key] = []
        self.access_times[full_key].append(datetime.utcnow())

class EnhancedCacheManager:
    """å¢å¼ºç¼“å­˜ç®¡ç†å™¨"""
    
    def __init__(self, redis_url: str = "redis://localhost:6379"):
        self.redis_pool = None
        self.redis_url = redis_url
        self.strategies: Dict[str, CacheStrategy] = {
            'default': DefaultCacheStrategy(),
            'smart': SmartCacheStrategy()
        }
        self.tag_mappings: Dict[str, Set[str]] = {}  # tag -> keys
        self.key_tags: Dict[str, Set[str]] = {}      # key -> tags
        self._invalidation_handlers: Dict[str, List[Callable]] = {}
        
        # æ³¨å†Œäº‹ä»¶ç›‘å¬å™¨
        event_bus.subscribe('user_updated', self._handle_user_updated)
        event_bus.subscribe('license_updated', self._handle_license_updated)
        event_bus.subscribe('application_updated', self._handle_application_updated)
        event_bus.subscribe('announcement_updated', self._handle_announcement_updated)
    
    async def initialize(self):
        """åˆå§‹åŒ–ç¼“å­˜ç®¡ç†å™¨"""
        self.redis_pool = redis.ConnectionPool.from_url(self.redis_url)
        logger.info("ç¼“å­˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    async def get_redis(self) -> redis.Redis:
        """è·å–Redisè¿æ¥"""
        if not self.redis_pool:
            await self.initialize()
        return redis.Redis(connection_pool=self.redis_pool)
    
    async def get(
        self, 
        key: CacheKey, 
        strategy: str = 'default'
    ) -> Optional[Any]:
        """è·å–ç¼“å­˜æ•°æ®"""
        try:
            redis_client = await self.get_redis()
            
            # è·å–ç¼“å­˜æ•°æ®
            cached_data = await redis_client.get(key.full_key())
            
            if cached_data:
                data = json.loads(cached_data)
                
                # æ‰§è¡Œç­–ç•¥å›è°ƒ
                cache_strategy = self.strategies.get(strategy, self.strategies['default'])
                await cache_strategy.on_hit(key, data)
                
                return data
            else:
                # æ‰§è¡Œç­–ç•¥å›è°ƒ
                cache_strategy = self.strategies.get(strategy, self.strategies['default'])
                await cache_strategy.on_miss(key)
                
                return None
                
        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜å¤±è´¥: {e}", exc_info=True)
            return None
    
    async def set(
        self, 
        key: CacheKey, 
        data: Any, 
        strategy: str = 'default'
    ) -> bool:
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        try:
            cache_strategy = self.strategies.get(strategy, self.strategies['default'])
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç¼“å­˜
            if not await cache_strategy.should_cache(key, data):
                return False
            
            redis_client = await self.get_redis()
            
            # åºåˆ—åŒ–æ•°æ®
            serialized_data = json.dumps(data, ensure_ascii=False, default=str)
            
            # è·å–TTL
            ttl = await cache_strategy.get_ttl(key, data)
            
            # è®¾ç½®ç¼“å­˜
            if ttl:
                await redis_client.setex(key.full_key(), ttl, serialized_data)
            else:
                await redis_client.set(key.full_key(), serialized_data)
            
            # æ›´æ–°æ ‡ç­¾æ˜ å°„
            await self._update_tag_mappings(key)
            
            logger.debug(f"è®¾ç½®ç¼“å­˜æˆåŠŸ: {key.full_key()}, TTL: {ttl}")
            return True
            
        except Exception as e:
            logger.error(f"è®¾ç½®ç¼“å­˜å¤±è´¥: {e}", exc_info=True)
            return False
    
    async def delete(self, key: CacheKey) -> bool:
        """åˆ é™¤ç¼“å­˜"""
        try:
            redis_client = await self.get_redis()
            
            # åˆ é™¤ç¼“å­˜
            result = await redis_client.delete(key.full_key())
            
            # æ¸…ç†æ ‡ç­¾æ˜ å°„
            await self._cleanup_tag_mappings(key)
            
            logger.debug(f"åˆ é™¤ç¼“å­˜: {key.full_key()}")
            return result > 0
            
        except Exception as e:
            logger.error(f"åˆ é™¤ç¼“å­˜å¤±è´¥: {e}", exc_info=True)
            return False
    
    async def delete_by_pattern(self, pattern: str) -> int:
        """æŒ‰æ¨¡å¼åˆ é™¤ç¼“å­˜"""
        try:
            redis_client = await self.get_redis()
            
            # æŸ¥æ‰¾åŒ¹é…çš„é”®
            keys = await redis_client.keys(pattern)
            
            if keys:
                # æ‰¹é‡åˆ é™¤
                result = await redis_client.delete(*keys)
                logger.info(f"æŒ‰æ¨¡å¼åˆ é™¤ç¼“å­˜: {pattern}, åˆ é™¤æ•°é‡: {result}")
                return result
            
            return 0
            
        except Exception as e:
            logger.error(f"æŒ‰æ¨¡å¼åˆ é™¤ç¼“å­˜å¤±è´¥: {e}", exc_info=True)
            return 0
    
    async def delete_by_tags(self, tags: List[str]) -> int:
        """æŒ‰æ ‡ç­¾åˆ é™¤ç¼“å­˜"""
        try:
            keys_to_delete = set()
            
            # æ”¶é›†æ‰€æœ‰éœ€è¦åˆ é™¤çš„é”®
            for tag in tags:
                if tag in self.tag_mappings:
                    keys_to_delete.update(self.tag_mappings[tag])
            
            if not keys_to_delete:
                return 0
            
            redis_client = await self.get_redis()
            
            # æ‰¹é‡åˆ é™¤
            result = await redis_client.delete(*keys_to_delete)
            
            # æ¸…ç†æ ‡ç­¾æ˜ å°„
            for tag in tags:
                if tag in self.tag_mappings:
                    for key in self.tag_mappings[tag]:
                        if key in self.key_tags:
                            self.key_tags[key].discard(tag)
                            if not self.key_tags[key]:
                                del self.key_tags[key]
                    del self.tag_mappings[tag]
            
            logger.info(f"æŒ‰æ ‡ç­¾åˆ é™¤ç¼“å­˜: {tags}, åˆ é™¤æ•°é‡: {result}")
            return result
            
        except Exception as e:
            logger.error(f"æŒ‰æ ‡ç­¾åˆ é™¤ç¼“å­˜å¤±è´¥: {e}", exc_info=True)
            return 0
    
    async def _update_tag_mappings(self, key: CacheKey):
        """æ›´æ–°æ ‡ç­¾æ˜ å°„"""
        full_key = key.full_key()
        
        # æ›´æ–°æ ‡ç­¾åˆ°é”®çš„æ˜ å°„
        for tag in key.tags:
            if tag not in self.tag_mappings:
                self.tag_mappings[tag] = set()
            self.tag_mappings[tag].add(full_key)
        
        # æ›´æ–°é”®åˆ°æ ‡ç­¾çš„æ˜ å°„
        self.key_tags[full_key] = key.tags.copy()
    
    async def _cleanup_tag_mappings(self, key: CacheKey):
        """æ¸…ç†æ ‡ç­¾æ˜ å°„"""
        full_key = key.full_key()
        
        # æ¸…ç†æ ‡ç­¾æ˜ å°„
        if full_key in self.key_tags:
            for tag in self.key_tags[full_key]:
                if tag in self.tag_mappings:
                    self.tag_mappings[tag].discard(full_key)
                    if not self.tag_mappings[tag]:
                        del self.tag_mappings[tag]
            del self.key_tags[full_key]
    
    # äº‹ä»¶å¤„ç†å™¨
    async def _handle_user_updated(self, event: Event):
        """å¤„ç†ç”¨æˆ·æ›´æ–°äº‹ä»¶"""
        user_id = event.data.get('user_id')
        if user_id:
            await self.delete_by_tags([f'user:{user_id}', 'users'])
    
    async def _handle_license_updated(self, event: Event):
        """å¤„ç†å¡å¯†æ›´æ–°äº‹ä»¶"""
        license_id = event.data.get('license_id')
        user_id = event.data.get('user_id')
        application_id = event.data.get('application_id')
        
        tags_to_invalidate = ['licenses']
        
        if license_id:
            tags_to_invalidate.append(f'license:{license_id}')
        
        if user_id:
            tags_to_invalidate.append(f'user:{user_id}')
        
        if application_id:
            tags_to_invalidate.append(f'application:{application_id}')
        
        await self.delete_by_tags(tags_to_invalidate)
    
    async def _handle_application_updated(self, event: Event):
        """å¤„ç†åº”ç”¨æ›´æ–°äº‹ä»¶"""
        application_id = event.data.get('application_id')
        if application_id:
            await self.delete_by_tags([f'application:{application_id}', 'applications'])
    
    async def _handle_announcement_updated(self, event: Event):
        """å¤„ç†å…¬å‘Šæ›´æ–°äº‹ä»¶"""
        announcement_id = event.data.get('announcement_id')
        if announcement_id:
            await self.delete_by_tags([f'announcement:{announcement_id}', 'announcements'])
    
    def register_strategy(self, name: str, strategy: CacheStrategy):
        """æ³¨å†Œç¼“å­˜ç­–ç•¥"""
        self.strategies[name] = strategy
        logger.info(f"æ³¨å†Œç¼“å­˜ç­–ç•¥: {name}")
    
    async def get_cache_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡ä¿¡æ¯"""
        try:
            redis_client = await self.get_redis()
            
            # è·å–Redisä¿¡æ¯
            info = await redis_client.info()
            
            # è·å–é”®æ•°é‡
            db_info = await redis_client.info('keyspace')
            key_count = 0
            if 'db0' in db_info:
                key_count = db_info['db0']['keys']
            
            return {
                'redis_version': info.get('redis_version'),
                'used_memory': info.get('used_memory_human'),
                'connected_clients': info.get('connected_clients'),
                'total_commands_processed': info.get('total_commands_processed'),
                'keyspace_hits': info.get('keyspace_hits'),
                'keyspace_misses': info.get('keyspace_misses'),
                'key_count': key_count,
                'tag_mappings_count': len(self.tag_mappings),
                'strategies_count': len(self.strategies)
            }
            
        except Exception as e:
            logger.error(f"è·å–ç¼“å­˜ç»Ÿè®¡å¤±è´¥: {e}", exc_info=True)
            return {}

# å…¨å±€ç¼“å­˜ç®¡ç†å™¨å®ä¾‹
cache_manager = EnhancedCacheManager()

# ä¾¿æ·å‡½æ•°
async def cached(
    namespace: str,
    key: str,
    tags: Optional[List[str]] = None,
    ttl: Optional[int] = None,
    strategy: str = 'default'
):
    """ç¼“å­˜è£…é¥°å™¨"""
    def decorator(func):
        async def wrapper(*args, **kwargs):
            # æ„å»ºç¼“å­˜é”®
            cache_key = CacheKey(
                namespace=namespace,
                key=key,
                tags=set(tags or []),
                ttl=ttl
            )
            
            # å°è¯•ä»ç¼“å­˜è·å–
            cached_result = await cache_manager.get(cache_key, strategy)
            if cached_result is not None:
                return cached_result
            
            # æ‰§è¡ŒåŸå‡½æ•°
            result = await func(*args, **kwargs)
            
            # è®¾ç½®ç¼“å­˜
            await cache_manager.set(cache_key, result, strategy)
            
            return result
        return wrapper
    return decorator
```

### 3.4 APIæ¥å£æ–‡æ¡£

#### è®¤è¯ç›¸å…³æ¥å£

##### POST /api/v1/auth/login
ç”¨æˆ·ç™»å½•æ¥å£

**è¯·æ±‚å‚æ•°ï¼š**
```json
{
  "username": "string",
  "password": "string"
}
```

**å“åº”æ•°æ®ï¼š**
```json
{
  "access_token": "string",
  "refresh_token": "string",
  "token_type": "bearer",
  "expires_in": 3600,
  "user": {
    "id": 1,
    "username": "admin",
    "role": "super_admin",
    "email": "admin@example.com"
  }
}
```

##### POST /api/v1/auth/activate
å¡å¯†æ¿€æ´»æ¥å£

**è¯·æ±‚å‚æ•°ï¼š**
```json
{
  "license_code": "string",
  "device_id": "string",
  "device_info": {
    "os": "Windows 10",
    "cpu": "Intel i7",
    "memory": "16GB"
  }
}
```

**å“åº”æ•°æ®ï¼š**
```json
{
  "success": true,
  "message": "æ¿€æ´»æˆåŠŸ",
  "license": {
    "id": 123,
    "expire_at": "2024-12-31T23:59:59Z",
    "max_bind_devices": 1,
    "current_bind_devices": 1
  }
}
```

##### POST /api/v1/auth/verify
å¡å¯†éªŒè¯æ¥å£

**è¯·æ±‚å‚æ•°ï¼š**
```json
{
  "license_code": "string",
  "device_id": "string"
}
```

**å“åº”æ•°æ®ï¼š**
```json
{
  "valid": true,
  "expire_at": "2024-12-31T23:59:59Z",
  "remaining_days": 365
}
```

#### åº”ç”¨ç®¡ç†æ¥å£

##### GET /api/v1/applications
è·å–åº”ç”¨åˆ—è¡¨

**æŸ¥è¯¢å‚æ•°ï¼š**
- `page`: é¡µç ï¼ˆé»˜è®¤1ï¼‰
- `size`: æ¯é¡µæ•°é‡ï¼ˆé»˜è®¤20ï¼‰
- `status`: åº”ç”¨çŠ¶æ€ç­›é€‰
- `search`: æœç´¢å…³é”®è¯

**å“åº”æ•°æ®ï¼š**
```json
{
  "items": [
    {
      "id": 1,
      "name": "åº”ç”¨åç§°",
      "description": "åº”ç”¨æè¿°",
      "status": "active",
      "api_key": "app_key_xxx",
      "created_at": "2024-01-01T00:00:00Z",
      "license_count": 100,
      "active_license_count": 50
    }
  ],
  "total": 100,
  "page": 1,
  "size": 20,
  "pages": 5
}
```

##### POST /api/v1/applications
åˆ›å»ºåº”ç”¨

**è¯·æ±‚å‚æ•°ï¼š**
```json
{
  "name": "string",
  "description": "string",
  "app_type": "desktop",
  "status": "active"
}
```

#### å¡å¯†ç®¡ç†æ¥å£

##### GET /api/v1/licenses
è·å–å¡å¯†åˆ—è¡¨

**æŸ¥è¯¢å‚æ•°ï¼š**
- `page`: é¡µç 
- `size`: æ¯é¡µæ•°é‡
- `application_id`: åº”ç”¨IDç­›é€‰
- `status`: çŠ¶æ€ç­›é€‰
- `batch_id`: æ‰¹æ¬¡IDç­›é€‰

##### POST /api/v1/licenses/generate
æ‰¹é‡ç”Ÿæˆå¡å¯†

**è¯·æ±‚å‚æ•°ï¼š**
```json
{
  "application_id": 1,
  "count": 100,
  "expire_days": 365,
  "max_bind_devices": 1,
  "batch_name": "æ‰¹æ¬¡åç§°"
}
```

#### ç”¨æˆ·ç®¡ç†æ¥å£

##### GET /api/v1/users
è·å–ç”¨æˆ·åˆ—è¡¨

##### POST /api/v1/users
åˆ›å»ºç”¨æˆ·

##### PUT /api/v1/users/{id}
æ›´æ–°ç”¨æˆ·ä¿¡æ¯

##### DELETE /api/v1/users/{id}
åˆ é™¤ç”¨æˆ·

### 3.2 æ•°æ®åº“è®¾è®¡

#### ERå›¾

```mermaid
erDiagram
    USERS {
        int id PK
        string username UK
        string password_hash
        string email UK
        enum role
        boolean is_active
        datetime created_at
        datetime updated_at
    }
    
    APPLICATIONS {
        int id PK
        string name UK
        string description
        enum app_type
        enum status
        string api_key UK
        string api_secret
        datetime created_at
        datetime updated_at
    }
    
    LICENSE_CODES {
        int id PK
        string code_encrypt UK
        string code_hash UK
        int application_id FK
        enum status
        datetime expire_at
        datetime activated_at
        int max_bind_devices
        int current_bind_devices
        string batch_id
        datetime created_at
        datetime updated_at
    }
    
    DEVICE_BIND {
        int id PK
        int user_id FK
        int application_id FK
        int license_id FK
        string device_id
        string device_name
        text device_info
        string device_fingerprint
        datetime bind_time
        datetime last_verify_time
        boolean is_active
    }
    
    USER_LICENSE_BIND {
        int id PK
        int user_id FK
        int license_id FK
        datetime bind_time
        datetime unbind_time
        boolean is_active
    }
    
    LICENSE_AUDIT_LOG {
        int id PK
        int license_id FK
        int user_id FK
        string action
        text details
        string ip_address
        datetime created_at
    }
    
    USERS ||--o{ USER_LICENSE_BIND : "has"
    USERS ||--o{ DEVICE_BIND : "owns"
    APPLICATIONS ||--o{ LICENSE_CODES : "contains"
    APPLICATIONS ||--o{ DEVICE_BIND : "binds"
    LICENSE_CODES ||--o{ USER_LICENSE_BIND : "bound_to"
    LICENSE_CODES ||--o{ DEVICE_BIND : "activates"
    LICENSE_CODES ||--o{ LICENSE_AUDIT_LOG : "logs"
```

#### ä¸»è¦è¡¨ç»“æ„

##### users è¡¨
```sql
CREATE TABLE users (
    id SERIAL PRIMARY KEY,
    username VARCHAR(50) UNIQUE NOT NULL,
    password_hash VARCHAR(255) NOT NULL,
    email VARCHAR(100) UNIQUE,
    role VARCHAR(20) DEFAULT 'user',
    is_active BOOLEAN DEFAULT true,
    last_login_at TIMESTAMP WITH TIME ZONE,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_users_role ON users(role);
```

##### applications è¡¨
```sql
CREATE TABLE applications (
    id SERIAL PRIMARY KEY,
    name VARCHAR(100) UNIQUE NOT NULL,
    description TEXT,
    app_type VARCHAR(20) DEFAULT 'desktop',
    status VARCHAR(20) DEFAULT 'active',
    api_key VARCHAR(64) UNIQUE NOT NULL,
    api_secret VARCHAR(128) NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_applications_name ON applications(name);
CREATE INDEX idx_applications_status ON applications(status);
CREATE INDEX idx_applications_api_key ON applications(api_key);
```

##### license_codes è¡¨
```sql
CREATE TABLE license_codes (
    id SERIAL PRIMARY KEY,
    code_encrypt VARCHAR(255) UNIQUE NOT NULL,
    code_hash VARCHAR(64) UNIQUE NOT NULL,
    application_id INTEGER REFERENCES applications(id) ON DELETE CASCADE,
    status INTEGER DEFAULT 0,
    expire_at TIMESTAMP WITH TIME ZONE NOT NULL,
    activated_at TIMESTAMP WITH TIME ZONE,
    max_bind_devices INTEGER DEFAULT 1,
    current_bind_devices INTEGER DEFAULT 0,
    batch_id VARCHAR(36),
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
    
    CONSTRAINT ck_max_bind_devices_positive CHECK (max_bind_devices >= 1),
    CONSTRAINT ck_current_bind_devices_non_negative CHECK (current_bind_devices >= 0),
    CONSTRAINT ck_current_bind_within_max CHECK (current_bind_devices <= max_bind_devices)
);

CREATE INDEX idx_license_app_status ON license_codes(application_id, status);
CREATE INDEX idx_license_expire_status ON license_codes(expire_at, status);
CREATE INDEX idx_license_batch_status ON license_codes(batch_id, status);
```

### 3.3 ä¸šåŠ¡é€»è¾‘æµç¨‹å›¾

#### å¡å¯†æ¿€æ´»æµç¨‹

```mermaid
flowchart TD
    A[å®¢æˆ·ç«¯è¯·æ±‚æ¿€æ´»] --> B[éªŒè¯è¯·æ±‚å‚æ•°]
    B --> C{å‚æ•°æœ‰æ•ˆ?}
    C -->|å¦| D[è¿”å›å‚æ•°é”™è¯¯]
    C -->|æ˜¯| E[æŸ¥è¯¢å¡å¯†ä¿¡æ¯]
    E --> F{å¡å¯†å­˜åœ¨?}
    F -->|å¦| G[è¿”å›å¡å¯†ä¸å­˜åœ¨]
    F -->|æ˜¯| H{å¡å¯†çŠ¶æ€æ£€æŸ¥}
    H -->|æœªæ¿€æ´»| I[æ£€æŸ¥è®¾å¤‡ç»‘å®š]
    H -->|å·²æ¿€æ´»| J{è®¾å¤‡åŒ¹é…?}
    H -->|å·²ç¦ç”¨| K[è¿”å›å¡å¯†å·²ç¦ç”¨]
    H -->|å·²è¿‡æœŸ| L[è¿”å›å¡å¯†å·²è¿‡æœŸ]
    
    I --> M{è®¾å¤‡æ•°é‡é™åˆ¶?}
    M -->|è¶…é™| N[è¿”å›è®¾å¤‡æ•°é‡è¶…é™]
    M -->|æœªè¶…é™| O[åˆ›å»ºè®¾å¤‡ç»‘å®š]
    
    J -->|åŒ¹é…| P[æ›´æ–°æœ€åéªŒè¯æ—¶é—´]
    J -->|ä¸åŒ¹é…| Q[è¿”å›è®¾å¤‡ä¸åŒ¹é…]
    
    O --> R[æ›´æ–°å¡å¯†çŠ¶æ€]
    R --> S[è®°å½•å®¡è®¡æ—¥å¿—]
    S --> T[è¿”å›æ¿€æ´»æˆåŠŸ]
    
    P --> U[è®°å½•éªŒè¯æ—¥å¿—]
    U --> V[è¿”å›éªŒè¯æˆåŠŸ]
```

#### ç”¨æˆ·æƒé™éªŒè¯æµç¨‹

```mermaid
flowchart TD
    A[APIè¯·æ±‚] --> B[æå–JWT Token]
    B --> C{Tokenå­˜åœ¨?}
    C -->|å¦| D[è¿”å›401æœªæˆæƒ]
    C -->|æ˜¯| E[éªŒè¯Tokenç­¾å]
    E --> F{ç­¾åæœ‰æ•ˆ?}
    F -->|å¦| G[è¿”å›401 Tokenæ— æ•ˆ]
    F -->|æ˜¯| H[æ£€æŸ¥Tokenè¿‡æœŸ]
    H --> I{Tokenè¿‡æœŸ?}
    I -->|æ˜¯| J[è¿”å›401 Tokenè¿‡æœŸ]
    I -->|å¦| K[æå–ç”¨æˆ·ä¿¡æ¯]
    K --> L[æ£€æŸ¥ç”¨æˆ·çŠ¶æ€]
    L --> M{ç”¨æˆ·æ¿€æ´»?}
    M -->|å¦| N[è¿”å›403ç”¨æˆ·å·²ç¦ç”¨]
    M -->|æ˜¯| O[æ£€æŸ¥æ¥å£æƒé™]
    O --> P{æƒé™è¶³å¤Ÿ?}
    P -->|å¦| Q[è¿”å›403æƒé™ä¸è¶³]
    P -->|æ˜¯| R[ç»§ç»­å¤„ç†è¯·æ±‚]
```

### 3.4 è®¤è¯æˆæƒæœºåˆ¶

#### JWT Token ç»“æ„

```json
{
  "header": {
    "alg": "HS256",
    "typ": "JWT"
  },
  "payload": {
    "user_id": 1,
    "username": "admin",
    "role": "super_admin",
    "exp": 1640995200,
    "iat": 1640908800,
    "jti": "unique-token-id"
  },
  "signature": "HMACSHA256(base64UrlEncode(header) + "." + base64UrlEncode(payload), secret)"
}
```

#### æƒé™æ§åˆ¶çŸ©é˜µ

| åŠŸèƒ½æ¨¡å— | super_admin | admin | user |
|---------|-------------|-------|------|
| ä»ªè¡¨ç›˜ | âœ… | âœ… | âœ… |
| åº”ç”¨ç®¡ç† | âœ… | âœ… | âŒ |
| å¡å¯†ç®¡ç† | âœ… | âœ… | âŒ |
| ç”¨æˆ·ç®¡ç† | âœ… | âœ… | âŒ |
| å®‰å…¨æ§åˆ¶ | âœ… | âŒ | âŒ |
| ç³»ç»Ÿè®¾ç½® | âœ… | âŒ | âŒ |
| ä¸ªäººèµ„æ–™ | âœ… | âœ… | âœ… |

#### åŠ å¯†ç­–ç•¥

```python
# å¯†ç åŠ å¯†
from passlib.context import CryptContext
pwd_context = CryptContext(schemes=["bcrypt"], deprecated="auto")

# å¡å¯†åŠ å¯†
from cryptography.fernet import Fernet
cipher_suite = Fernet(encryption_key)

# JWTç­¾å
import jwt
token = jwt.encode(payload, secret_key, algorithm="HS256")
```

### 3.5 ç¬¬ä¸‰æ–¹æœåŠ¡é›†æˆè¯´æ˜

#### Redis ç¼“å­˜æœåŠ¡

**ç”¨é€”ï¼š**
- Sessionå­˜å‚¨
- APIé™æµ
- çƒ­ç‚¹æ•°æ®ç¼“å­˜
- åˆ†å¸ƒå¼é”

**é…ç½®ï¼š**
```python
REDIS_CONFIG = {
    "host": "localhost",
    "port": 6379,
    "db": 0,
    "password": None,
    "decode_responses": True,
    "max_connections": 20
}
```

#### PostgreSQL æ•°æ®åº“

**è¿æ¥é…ç½®ï¼š**
```python
DATABASE_CONFIG = {
    "host": "localhost",
    "port": 5432,
    "database": "license_system",
    "username": "postgres",
    "password": "password",
    "pool_size": 20,
    "max_overflow": 30
}
```

#### é‚®ä»¶æœåŠ¡ï¼ˆå¯é€‰ï¼‰

**SMTPé…ç½®ï¼š**
```python
EMAIL_CONFIG = {
    "smtp_server": "smtp.gmail.com",
    "smtp_port": 587,
    "username": "your-email@gmail.com",
    "password": "your-app-password",
    "use_tls": True
}
```

---

## 4. æ•°æ®éƒ¨åˆ†

### 4.1 æ•°æ®æ¨¡å‹å®šä¹‰

#### ç”¨æˆ·æ¨¡å‹ (User)

```python
class User(Base, TimestampMixin):
    """ç”¨æˆ·æ¨¡å‹"""
    __tablename__ = "users"
    
    id = Column(Integer, primary_key=True, index=True)
    username = Column(String(50), unique=True, nullable=False, index=True)
    password_hash = Column(String(255), nullable=False)
    email = Column(String(100), unique=True, nullable=True, index=True)
    role = Column(SQLEnum(UserRole), default=UserRole.USER, nullable=False)
    is_active = Column(Boolean, default=True, nullable=False)
    last_login_at = Column(DateTime(timezone=True), nullable=True)
    
    # å…³ç³»
    license_binds = relationship("UserLicenseBind", back_populates="user")
    device_binds = relationship("DeviceBind", back_populates="user")
```

#### åº”ç”¨æ¨¡å‹ (Application)

```python
class Application(Base, TimestampMixin):
    """åº”ç”¨æ¨¡å‹"""
    __tablename__ = "applications"
    
    id = Column(Integer, primary_key=True, index=True)
    name = Column(String(100), unique=True, nullable=False, index=True)
    description = Column(Text, nullable=True)
    app_type = Column(SQLEnum(AppType), default=AppType.DESKTOP, nullable=False)
    status = Column(SQLEnum(AppStatus), default=AppStatus.ACTIVE, nullable=False)
    api_key = Column(String(64), unique=True, nullable=False, index=True)
    api_secret = Column(String(128), nullable=False)
    
    # å…³ç³»
    licenses = relationship("LicenseCode", back_populates="application")
    device_binds = relationship("DeviceBind", back_populates="application")
```

#### å¡å¯†æ¨¡å‹ (LicenseCode)

```python
class LicenseCode(Base, TimestampMixin, SoftDeleteMixin):
    """å¡å¯†æ¨¡å‹"""
    __tablename__ = "license_codes"
    
    id = Column(Integer, primary_key=True, index=True)
    code_encrypt = Column(String(255), unique=True, nullable=False, index=True)
    code_hash = Column(String(64), unique=True, nullable=False, index=True)
    application_id = Column(Integer, ForeignKey("applications.id"), nullable=False)
    status = Column(SQLEnum(LicenseStatus), default=LicenseStatus.INACTIVE)
    expire_at = Column(DateTime(timezone=True), nullable=False, index=True)
    activated_at = Column(DateTime(timezone=True), nullable=True)
    max_bind_devices = Column(Integer, default=1, nullable=False)
    current_bind_devices = Column(Integer, default=0, nullable=False)
    batch_id = Column(String(36), nullable=True, index=True)
    
    # å…³ç³»
    application = relationship("Application", back_populates="licenses")
    user_binds = relationship("UserLicenseBind", back_populates="license")
    device_binds = relationship("DeviceBind", back_populates="license")
```

### 4.2 æ•°æ®æµç¤ºæ„å›¾

```mermaid
flowchart LR
    A[å®¢æˆ·ç«¯è¯·æ±‚] --> B[APIç½‘å…³]
    B --> C[è®¤è¯ä¸­é—´ä»¶]
    C --> D[ä¸šåŠ¡é€»è¾‘å±‚]
    D --> E[æ•°æ®è®¿é—®å±‚]
    E --> F[PostgreSQL]
    E --> G[Redisç¼“å­˜]
    
    H[å®šæ—¶ä»»åŠ¡] --> I[æ•°æ®æ¸…ç†]
    I --> F
    
    J[ç›‘æ§ç³»ç»Ÿ] --> K[æ—¥å¿—æ”¶é›†]
    K --> L[æ—¥å¿—å­˜å‚¨]
    
    M[å¤‡ä»½ç³»ç»Ÿ] --> N[æ•°æ®å¤‡ä»½]
    N --> O[å¤‡ä»½å­˜å‚¨]
    
    subgraph "æ•°æ®å±‚"
        F[PostgreSQL<br/>ä¸»æ•°æ®å­˜å‚¨]
        G[Redis<br/>ç¼“å­˜å±‚]
        L[æ—¥å¿—å­˜å‚¨]
        O[å¤‡ä»½å­˜å‚¨]
    end
```

### 4.3 ç¼“å­˜ç­–ç•¥

#### ç¼“å­˜å±‚çº§

1. **L1ç¼“å­˜ï¼ˆåº”ç”¨å†…å­˜ï¼‰**
   - é…ç½®ä¿¡æ¯ç¼“å­˜
   - ç”¨æˆ·ä¼šè¯ç¼“å­˜
   - çƒ­ç‚¹æ•°æ®ç¼“å­˜

2. **L2ç¼“å­˜ï¼ˆRedisï¼‰**
   - ç”¨æˆ·è®¤è¯ä¿¡æ¯
   - APIé™æµè®¡æ•°
   - ä¸´æ—¶æ•°æ®å­˜å‚¨

#### ç¼“å­˜ç­–ç•¥é…ç½®

```python
CACHE_STRATEGIES = {
    # ç”¨æˆ·ä¿¡æ¯ç¼“å­˜
    "user_info": {
        "ttl": 3600,  # 1å°æ—¶
        "strategy": "write_through"
    },
    
    # åº”ç”¨é…ç½®ç¼“å­˜
    "app_config": {
        "ttl": 7200,  # 2å°æ—¶
        "strategy": "cache_aside"
    },
    
    # å¡å¯†éªŒè¯ç»“æœç¼“å­˜
    "license_verify": {
        "ttl": 300,   # 5åˆ†é’Ÿ
        "strategy": "write_behind"
    },
    
    # APIé™æµç¼“å­˜
    "rate_limit": {
        "ttl": 60,    # 1åˆ†é’Ÿ
        "strategy": "time_based"
    }
}
```

#### ç¼“å­˜æ›´æ–°ç­–ç•¥

```python
class CacheManager:
    """ç¼“å­˜ç®¡ç†å™¨"""
    
    async def get_or_set(self, key: str, fetch_func, ttl: int = 3600):
        """è·å–æˆ–è®¾ç½®ç¼“å­˜"""
        # å°è¯•ä»ç¼“å­˜è·å–
        cached_data = await self.redis.get(key)
        if cached_data:
            return json.loads(cached_data)
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œä»æ•°æ®æºè·å–
        data = await fetch_func()
        if data:
            await self.redis.setex(key, ttl, json.dumps(data))
        
        return data
    
    async def invalidate(self, pattern: str):
        """æ‰¹é‡å¤±æ•ˆç¼“å­˜"""
        keys = await self.redis.keys(pattern)
        if keys:
            await self.redis.delete(*keys)
```

### 4.4 æ•°æ®éªŒè¯è§„åˆ™

#### è¾“å…¥éªŒè¯è§„åˆ™

```python
from pydantic import BaseModel, validator, Field
from typing import Optional
import re

class UserCreateSchema(BaseModel):
    """ç”¨æˆ·åˆ›å»ºéªŒè¯æ¨¡å¼"""
    username: str = Field(..., min_length=3, max_length=50)
    password: str = Field(..., min_length=8, max_length=128)
    email: Optional[str] = Field(None, max_length=100)
    role: str = Field(default="user")
    
    @validator('username')
    def validate_username(cls, v):
        if not re.match(r'^[a-zA-Z0-9_]+$', v):
            raise ValueError('ç”¨æˆ·ååªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—å’Œä¸‹åˆ’çº¿')
        return v
    
    @validator('password')
    def validate_password(cls, v):
        if not re.search(r'[A-Z]', v):
            raise ValueError('å¯†ç å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªå¤§å†™å­—æ¯')
        if not re.search(r'[a-z]', v):
            raise ValueError('å¯†ç å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªå°å†™å­—æ¯')
        if not re.search(r'\d', v):
            raise ValueError('å¯†ç å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªæ•°å­—')
        return v
    
    @validator('email')
    def validate_email(cls, v):
        if v and not re.match(r'^[\w\.-]+@[\w\.-]+\.\w+$', v):
            raise ValueError('é‚®ç®±æ ¼å¼ä¸æ­£ç¡®')
        return v

class LicenseActivateSchema(BaseModel):
    """å¡å¯†æ¿€æ´»éªŒè¯æ¨¡å¼"""
    license_code: str = Field(..., min_length=16, max_length=64)
    device_id: str = Field(..., min_length=8, max_length=100)
    device_info: Optional[dict] = None
    
    @validator('license_code')
    def validate_license_code(cls, v):
        # ç§»é™¤ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
        v = re.sub(r'[\s-]', '', v)
        if not re.match(r'^[A-Z0-9]+$', v):
            raise ValueError('å¡å¯†æ ¼å¼ä¸æ­£ç¡®')
        return v
    
    @validator('device_id')
    def validate_device_id(cls, v):
        if not re.match(r'^[a-zA-Z0-9_-]+$', v):
            raise ValueError('è®¾å¤‡IDæ ¼å¼ä¸æ­£ç¡®')
        return v
```

#### ä¸šåŠ¡è§„åˆ™éªŒè¯

```python
class BusinessRuleValidator:
    """ä¸šåŠ¡è§„åˆ™éªŒè¯å™¨"""
    
    @staticmethod
    def validate_license_activation(license: LicenseCode, device_id: str) -> bool:
        """éªŒè¯å¡å¯†æ¿€æ´»è§„åˆ™"""
        # æ£€æŸ¥å¡å¯†çŠ¶æ€
        if license.status != LicenseStatus.INACTIVE:
            raise ValueError("å¡å¯†å·²è¢«æ¿€æ´»æˆ–å·²ç¦ç”¨")
        
        # æ£€æŸ¥è¿‡æœŸæ—¶é—´
        if license.expire_at < datetime.now(timezone.utc):
            raise ValueError("å¡å¯†å·²è¿‡æœŸ")
        
        # æ£€æŸ¥è®¾å¤‡ç»‘å®šæ•°é‡
        if license.current_bind_devices >= license.max_bind_devices:
            raise ValueError("è®¾å¤‡ç»‘å®šæ•°é‡å·²è¾¾ä¸Šé™")
        
        return True
    
    @staticmethod
    def validate_device_binding(user_id: int, application_id: int, device_id: str) -> bool:
        """éªŒè¯è®¾å¤‡ç»‘å®šè§„åˆ™"""
        # æ£€æŸ¥è®¾å¤‡æ˜¯å¦å·²ç»‘å®š
        existing_bind = DeviceBind.query.filter_by(
            user_id=user_id,
            application_id=application_id,
            device_id=device_id,
            is_active=True
        ).first()
        
        if existing_bind:
            raise ValueError("è®¾å¤‡å·²ç»‘å®š")
        
        return True
```

---

## 5. UI/UXè®¾è®¡éƒ¨åˆ†

### 5.1 è®¾è®¡è§„èŒƒ

#### è‰²å½©ç³»ç»Ÿ

```css
/* ä¸»è‰²è°ƒ */
:root {
  /* Primary Colors */
  --color-primary-50: #eff6ff;
  --color-primary-100: #dbeafe;
  --color-primary-200: #bfdbfe;
  --color-primary-300: #93c5fd;
  --color-primary-400: #60a5fa;
  --color-primary-500: #3b82f6;  /* ä¸»è‰² */
  --color-primary-600: #2563eb;
  --color-primary-700: #1d4ed8;
  --color-primary-800: #1e40af;
  --color-primary-900: #1e3a8a;
  
  /* Secondary Colors */
  --color-secondary-50: #f8fafc;
  --color-secondary-100: #f1f5f9;
  --color-secondary-200: #e2e8f0;
  --color-secondary-300: #cbd5e1;
  --color-secondary-400: #94a3b8;
  --color-secondary-500: #64748b;  /* è¾…åŠ©è‰² */
  --color-secondary-600: #475569;
  --color-secondary-700: #334155;
  --color-secondary-800: #1e293b;
  --color-secondary-900: #0f172a;
  
  /* Status Colors */
  --color-success: #10b981;
  --color-warning: #f59e0b;
  --color-error: #ef4444;
  --color-info: #3b82f6;
  
  /* Neutral Colors */
  --color-gray-50: #f9fafb;
  --color-gray-100: #f3f4f6;
  --color-gray-200: #e5e7eb;
  --color-gray-300: #d1d5db;
  --color-gray-400: #9ca3af;
  --color-gray-500: #6b7280;
  --color-gray-600: #4b5563;
  --color-gray-700: #374151;
  --color-gray-800: #1f2937;
  --color-gray-900: #111827;
}

/* æ·±è‰²æ¨¡å¼ */
[data-theme="dark"] {
  --color-primary-dark: #1e40af;
  --color-background: #0f172a;
  --color-surface: #1e293b;
  --color-text-primary: #f8fafc;
  --color-text-secondary: #cbd5e1;
}
```

#### å­—ä½“ç³»ç»Ÿ

```css
/* å­—ä½“æ— */
:root {
  --font-family-sans: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
  --font-family-mono: 'JetBrains Mono', 'Fira Code', Consolas, monospace;
  
  /* å­—ä½“å¤§å° */
  --text-xs: 0.75rem;    /* 12px */
  --text-sm: 0.875rem;   /* 14px */
  --text-base: 1rem;     /* 16px */
  --text-lg: 1.125rem;   /* 18px */
  --text-xl: 1.25rem;    /* 20px */
  --text-2xl: 1.5rem;    /* 24px */
  --text-3xl: 1.875rem;  /* 30px */
  --text-4xl: 2.25rem;   /* 36px */
  
  /* å­—é‡ */
  --font-weight-light: 300;
  --font-weight-normal: 400;
  --font-weight-medium: 500;
  --font-weight-semibold: 600;
  --font-weight-bold: 700;
  
  /* è¡Œé«˜ */
  --line-height-tight: 1.25;
  --line-height-normal: 1.5;
  --line-height-relaxed: 1.75;
}
```

#### é—´è·ç³»ç»Ÿ

```css
/* é—´è·è§„èŒƒ */
:root {
  --spacing-0: 0;
  --spacing-1: 0.25rem;  /* 4px */
  --spacing-2: 0.5rem;   /* 8px */
  --spacing-3: 0.75rem;  /* 12px */
  --spacing-4: 1rem;     /* 16px */
  --spacing-5: 1.25rem;  /* 20px */
  --spacing-6: 1.5rem;   /* 24px */
  --spacing-8: 2rem;     /* 32px */
  --spacing-10: 2.5rem;  /* 40px */
  --spacing-12: 3rem;    /* 48px */
  --spacing-16: 4rem;    /* 64px */
  --spacing-20: 5rem;    /* 80px */
  --spacing-24: 6rem;    /* 96px */
}
```

#### åœ†è§’ä¸é˜´å½±

```css
/* åœ†è§’ */
:root {
  --radius-none: 0;
  --radius-sm: 0.125rem;   /* 2px */
  --radius-base: 0.25rem;  /* 4px */
  --radius-md: 0.375rem;   /* 6px */
  --radius-lg: 0.5rem;     /* 8px */
  --radius-xl: 0.75rem;    /* 12px */
  --radius-2xl: 1rem;      /* 16px */
  --radius-full: 9999px;
}

/* é˜´å½± */
:root {
  --shadow-sm: 0 1px 2px 0 rgb(0 0 0 / 0.05);
  --shadow-base: 0 1px 3px 0 rgb(0 0 0 / 0.1), 0 1px 2px -1px rgb(0 0 0 / 0.1);
  --shadow-md: 0 4px 6px -1px rgb(0 0 0 / 0.1), 0 2px 4px -2px rgb(0 0 0 / 0.1);
  --shadow-lg: 0 10px 15px -3px rgb(0 0 0 / 0.1), 0 4px 6px -4px rgb(0 0 0 / 0.1);
  --shadow-xl: 0 20px 25px -5px rgb(0 0 0 / 0.1), 0 8px 10px -6px rgb(0 0 0 / 0.1);
  --shadow-2xl: 0 25px 50px -12px rgb(0 0 0 / 0.25);
}
```

### 5.2 é«˜ä¿çœŸåŸå‹å›¾é“¾æ¥

ç”±äºè¿™æ˜¯ä¸€ä¸ªå®é™…çš„å¼€å‘é¡¹ç›®ï¼ŒåŸå‹å›¾å·²é€šè¿‡ä»£ç å®ç°ã€‚ä¸»è¦ç•Œé¢åŒ…æ‹¬ï¼š

1. **ç™»å½•é¡µé¢** (`/login`)
   - ç®€æ´çš„ç™»å½•è¡¨å•
   - æ”¯æŒæ·±è‰²/æµ…è‰²æ¨¡å¼åˆ‡æ¢
   - å“åº”å¼è®¾è®¡

2. **ä»ªè¡¨ç›˜** (`/dashboard`)
   - æ•°æ®ç»Ÿè®¡å¡ç‰‡
   - å›¾è¡¨å±•ç¤º
   - æœ€è¿‘æ´»åŠ¨åˆ—è¡¨

3. **åº”ç”¨ç®¡ç†** (`/applications`)
   - åº”ç”¨åˆ—è¡¨è¡¨æ ¼
   - æœç´¢å’Œç­›é€‰åŠŸèƒ½
   - åº”ç”¨è¯¦æƒ…æ¨¡æ€æ¡†

4. **å¡å¯†ç®¡ç†** (`/licenses`)
   - å¡å¯†åˆ—è¡¨å’ŒçŠ¶æ€
   - æ‰¹é‡æ“ä½œåŠŸèƒ½
   - ç”Ÿæˆå¡å¯†å‘å¯¼

### 5.3 äº¤äº’åŠ¨æ•ˆè¯´æ˜

#### é¡µé¢è½¬åœºåŠ¨æ•ˆ

```css
/* é¡µé¢æ·¡å…¥æ·¡å‡º */
.page-transition-enter {
  opacity: 0;
  transform: translateY(20px);
}

.page-transition-enter-active {
  opacity: 1;
  transform: translateY(0);
  transition: opacity 300ms ease-out, transform 300ms ease-out;
}

.page-transition-exit {
  opacity: 1;
  transform: translateY(0);
}

.page-transition-exit-active {
  opacity: 0;
  transform: translateY(-20px);
  transition: opacity 200ms ease-in, transform 200ms ease-in;
}
```

#### æŒ‰é’®äº¤äº’åŠ¨æ•ˆ

```css
/* æŒ‰é’®æ‚¬åœå’Œç‚¹å‡»æ•ˆæœ */
.button {
  transition: all 200ms ease;
  transform: scale(1);
}

.button:hover {
  transform: scale(1.05);
  box-shadow: var(--shadow-lg);
}

.button:active {
  transform: scale(0.95);
  transition: all 100ms ease;
}

/* åŠ è½½çŠ¶æ€åŠ¨ç”» */
.button-loading {
  position: relative;
  color: transparent;
}

.button-loading::after {
  content: '';
  position: absolute;
  width: 16px;
  height: 16px;
  top: 50%;
  left: 50%;
  margin-left: -8px;
  margin-top: -8px;
  border: 2px solid transparent;
  border-top-color: currentColor;
  border-radius: 50%;
  animation: spin 1s linear infinite;
}

@keyframes spin {
  to {
    transform: rotate(360deg);
  }
}
```

#### æ¨¡æ€æ¡†åŠ¨æ•ˆ

```css
/* æ¨¡æ€æ¡†å¼¹å‡ºåŠ¨ç”» */
.modal-overlay {
  background: rgba(0, 0, 0, 0.5);
  backdrop-filter: blur(4px);
  transition: all 200ms ease;
}

.modal-content {
  transform: scale(0.95) translateY(-20px);
  opacity: 0;
  transition: all 200ms ease;
}

.modal-content.open {
  transform: scale(1) translateY(0);
  opacity: 1;
}
```

### 5.4 å“åº”å¼è®¾è®¡è§„èŒƒ

#### æ–­ç‚¹ç³»ç»Ÿ

```css
/* å“åº”å¼æ–­ç‚¹ */
:root {
  --breakpoint-sm: 640px;   /* å°å±è®¾å¤‡ */
  --breakpoint-md: 768px;   /* å¹³æ¿è®¾å¤‡ */
  --breakpoint-lg: 1024px;  /* æ¡Œé¢è®¾å¤‡ */
  --breakpoint-xl: 1280px;  /* å¤§å±è®¾å¤‡ */
  --breakpoint-2xl: 1536px; /* è¶…å¤§å±è®¾å¤‡ */
}

/* åª’ä½“æŸ¥è¯¢ */
@media (max-width: 640px) {
  /* ç§»åŠ¨ç«¯æ ·å¼ */
  .container {
    padding: var(--spacing-4);
  }
  
  .sidebar {
    transform: translateX(-100%);
    transition: transform 300ms ease;
  }
  
  .sidebar.open {
    transform: translateX(0);
  }
}

@media (min-width: 641px) and (max-width: 1024px) {
  /* å¹³æ¿æ ·å¼ */
  .grid {
    grid-template-columns: repeat(2, 1fr);
  }
}

@media (min-width: 1025px) {
  /* æ¡Œé¢æ ·å¼ */
  .grid {
    grid-template-columns: repeat(3, 1fr);
  }
}
```

#### ç§»åŠ¨ç«¯ä¼˜åŒ–

```css
/* è§¦æ‘¸å‹å¥½çš„æŒ‰é’®å°ºå¯¸ */
@media (max-width: 768px) {
  .button {
    min-height: 44px;
    min-width: 44px;
    padding: var(--spacing-3) var(--spacing-4);
  }
  
  .table {
    font-size: var(--text-sm);
  }
  
  .modal {
    margin: var(--spacing-4);
    max-height: calc(100vh - 2rem);
  }
}

/* æ¨ªå±é€‚é… */
@media (orientation: landscape) and (max-height: 500px) {
  .header {
    height: 48px;
  }
  
  .sidebar {
    width: 200px;
  }
}
```

### 5.5 å¯è®¿é—®æ€§æ ‡å‡†

#### WCAG 2.1 AA çº§åˆ«åˆè§„

```css
/* é¢œè‰²å¯¹æ¯”åº¦ */
:root {
  /* ç¡®ä¿æ–‡æœ¬å¯¹æ¯”åº¦è‡³å°‘ä¸º 4.5:1 */
  --text-on-light: #1f2937;  /* å¯¹æ¯”åº¦ > 4.5:1 */
  --text-on-dark: #f9fafb;   /* å¯¹æ¯”åº¦ > 4.5:1 */
}

/* ç„¦ç‚¹æŒ‡ç¤ºå™¨ */
.focusable:focus {
  outline: 2px solid var(--color-primary-500);
  outline-offset: 2px;
}

/* è·³è¿‡é“¾æ¥ */
.skip-link {
  position: absolute;
  top: -40px;
  left: 6px;
  background: var(--color-primary-600);
  color: white;
  padding: 8px;
  text-decoration: none;
  border-radius: 4px;
  z-index: 1000;
}

.skip-link:focus {
  top: 6px;
}
```

#### è¯­ä¹‰åŒ–HTML

```html
<!-- æ­£ç¡®çš„è¯­ä¹‰åŒ–ç»“æ„ -->
<main role="main" aria-label="ä¸»è¦å†…å®¹">
  <header>
    <h1>é¡µé¢æ ‡é¢˜</h1>
    <nav aria-label="ä¸»å¯¼èˆª">
      <ul role="menubar">
        <li role="none">
          <a href="/dashboard" role="menuitem" aria-current="page">
            ä»ªè¡¨ç›˜
          </a>
        </li>
      </ul>
    </nav>
  </header>
  
  <section aria-labelledby="content-heading">
    <h2 id="content-heading">å†…å®¹åŒºåŸŸ</h2>
    <!-- å†…å®¹ -->
  </section>
</main>

<!-- è¡¨å•å¯è®¿é—®æ€§ -->
<form>
  <div class="form-group">
    <label for="username">ç”¨æˆ·å</label>
    <input 
      id="username" 
      type="text" 
      required 
      aria-describedby="username-help"
      aria-invalid="false"
    >
    <div id="username-help" class="help-text">
      è¯·è¾“å…¥3-50ä¸ªå­—ç¬¦çš„ç”¨æˆ·å
    </div>
  </div>
</form>
```

#### é”®ç›˜å¯¼èˆªæ”¯æŒ

```typescript
// é”®ç›˜å¯¼èˆªå¤„ç†
const handleKeyDown = (event: KeyboardEvent) => {
  switch (event.key) {
    case 'Escape':
      closeModal();
      break;
    case 'Tab':
      // ç„¦ç‚¹é™·é˜±å¤„ç†
      trapFocus(event);
      break;
    case 'Enter':
    case ' ':
      if (event.target === buttonRef.current) {
        event.preventDefault();
        handleClick();
      }
      break;
  }
};

// ç„¦ç‚¹é™·é˜±å®ç°
const trapFocus = (event: KeyboardEvent) => {
  const focusableElements = modal.querySelectorAll(
    'button, [href], input, select, textarea, [tabindex]:not([tabindex="-1"])'
  );
  
  const firstElement = focusableElements[0] as HTMLElement;
  const lastElement = focusableElements[focusableElements.length - 1] as HTMLElement;
  
  if (event.shiftKey) {
    if (document.activeElement === firstElement) {
      lastElement.focus();
      event.preventDefault();
    }
  } else {
    if (document.activeElement === lastElement) {
      firstElement.focus();
      event.preventDefault();
    }
  }
};
```

---

## 6. å…¶ä»–ä¿¡æ¯

### 6.1 å¼€å‘ç¯å¢ƒé…ç½®

#### ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**ï¼šmacOS 10.15+, Windows 10+, Ubuntu 18.04+
- **Node.js**ï¼š16.0.0+
- **Python**ï¼š3.9+
- **PostgreSQL**ï¼š13.0+
- **Redis**ï¼š6.0+

#### å‰ç«¯ç¯å¢ƒé…ç½®

```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd frontend

# 2. å®‰è£…ä¾èµ–
npm install

# 3. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env.local

# 4. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
npm run dev
```

**ç¯å¢ƒå˜é‡é…ç½® (.env.local)ï¼š**
```env
NEXT_PUBLIC_API_URL=http://localhost:8000
NEXT_PUBLIC_WS_URL=ws://localhost:8000
NEXT_PUBLIC_APP_NAME=é‡‘é±¼æ™ºç›’å¡å¯†æˆæƒç³»ç»Ÿ
NEXT_PUBLIC_APP_VERSION=1.0.0
```

#### åç«¯ç¯å¢ƒé…ç½®

```bash
# 1. è¿›å…¥åç«¯ç›®å½•
cd backend

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv .venv
source .venv/bin/activate  # Linux/macOS
# æˆ–
.venv\Scripts\activate     # Windows

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env

# 5. åˆå§‹åŒ–æ•°æ®åº“
python -c "from app.db.init_db import init_db; init_db()"

# 6. å¯åŠ¨æœåŠ¡å™¨
python main.py
```

**ç¯å¢ƒå˜é‡é…ç½® (.env)ï¼š**
```env
# æ•°æ®åº“é…ç½®
DATABASE_URL=postgresql://postgres:password@localhost:5432/license_system

# Redisé…ç½®
REDIS_URL=redis://localhost:6379/0

# JWTé…ç½®
JWT_SECRET_KEY=your-super-secret-jwt-key
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=60
JWT_REFRESH_TOKEN_EXPIRE_DAYS=30

# æœåŠ¡å™¨é…ç½®
SERVER_HOST=0.0.0.0
SERVER_PORT=8000
DEBUG=true

# åŠ å¯†é…ç½®
ENCRYPTION_KEY=your-32-byte-encryption-key

# ç®¡ç†å‘˜è´¦å·
FIRST_SUPERUSER=admin
FIRST_SUPERUSER_PASSWORD=admin1314159
```

#### æ•°æ®åº“é…ç½®

```bash
# PostgreSQL å®‰è£…å’Œé…ç½®
# macOS
brew install postgresql
brew services start postgresql

# Ubuntu
sudo apt update
sudo apt install postgresql postgresql-contrib
sudo systemctl start postgresql

# åˆ›å»ºæ•°æ®åº“
sudo -u postgres psql
CREATE DATABASE license_system;
CREATE USER license_user WITH PASSWORD 'your_password';
GRANT ALL PRIVILEGES ON DATABASE license_system TO license_user;
\q

# Redis å®‰è£…å’Œé…ç½®
# macOS
brew install redis
brew services start redis

# Ubuntu
sudo apt update
sudo apt install redis-server
sudo systemctl start redis-server
```

#### å¼€å‘å·¥å…·æ¨è

**å‰ç«¯å¼€å‘ï¼š**
- **IDE**ï¼šVS Code + ç›¸å…³æ’ä»¶
- **æµè§ˆå™¨**ï¼šChrome DevTools
- **è°ƒè¯•**ï¼šReact Developer Tools
- **APIæµ‹è¯•**ï¼šPostman æˆ– Insomnia

**åç«¯å¼€å‘ï¼š**
- **IDE**ï¼šPyCharm æˆ– VS Code
- **æ•°æ®åº“ç®¡ç†**ï¼špgAdmin æˆ– DBeaver
- **APIæ–‡æ¡£**ï¼šè‡ªåŠ¨ç”Ÿæˆçš„ FastAPI Swagger UI
- **æ—¥å¿—æŸ¥çœ‹**ï¼šå†…ç½®æ—¥å¿—ç³»ç»Ÿ

### 6.2 éƒ¨ç½²æµç¨‹

#### ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

**1. æœåŠ¡å™¨å‡†å¤‡**
```bash
# æ›´æ–°ç³»ç»Ÿ
sudo apt update && sudo apt upgrade -y

# å®‰è£…å¿…è¦è½¯ä»¶
sudo apt install -y nginx postgresql redis-server python3.9 python3.9-venv nodejs npm

# é…ç½®é˜²ç«å¢™
sudo ufw allow 22
sudo ufw allow 80
sudo ufw allow 443
sudo ufw enable
```

**2. æ•°æ®åº“é…ç½®**
```bash
# PostgreSQL é…ç½®
sudo -u postgres createdb license_system_prod
sudo -u postgres createuser --interactive license_prod

# Redis é…ç½®
sudo systemctl enable redis-server
sudo systemctl start redis-server
```

**3. åç«¯éƒ¨ç½²**
```bash
# åˆ›å»ºåº”ç”¨ç›®å½•
sudo mkdir -p /opt/license-system
sudo chown $USER:$USER /opt/license-system
cd /opt/license-system

# å…‹éš†ä»£ç 
git clone <repository-url> .

# é…ç½®Pythonç¯å¢ƒ
python3.9 -m venv venv
source venv/bin/activate
pip install -r backend/requirements.txt

# é…ç½®ç¯å¢ƒå˜é‡
cp backend/.env.example backend/.env.prod
# ç¼–è¾‘ç”Ÿäº§ç¯å¢ƒé…ç½®

# åˆå§‹åŒ–æ•°æ®åº“
cd backend
python -c "from app.db.init_db import init_db; init_db()"
```

**4. å‰ç«¯éƒ¨ç½²**
```bash
# æ„å»ºå‰ç«¯
cd frontend
npm install
npm run build

# é…ç½®Nginx
sudo cp deployment/nginx.conf /etc/nginx/sites-available/license-system
sudo ln -s /etc/nginx/sites-available/license-system /etc/nginx/sites-enabled/
sudo nginx -t
sudo systemctl reload nginx
```

**5. è¿›ç¨‹ç®¡ç†**
```bash
# ä½¿ç”¨systemdç®¡ç†åç«¯æœåŠ¡
sudo cp deployment/license-backend.service /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl enable license-backend
sudo systemctl start license-backend
```

#### Docker éƒ¨ç½²

**docker-compose.ymlï¼š**
```yaml
version: '3.8'

services:
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://backend:8000
    depends_on:
      - backend

  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://postgres:password@db:5432/license_system
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - db
      - redis
    volumes:
      - ./backend/logs:/app/logs

  db:
    image: postgres:15
    environment:
      - POSTGRES_DB=license_system
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./backend/sql/init.sql:/docker-entrypoint-initdb.d/init.sql

  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis_data:/data

volumes:
  postgres_data:
  redis_data:
```

### 6.3 æµ‹è¯•æ–¹æ¡ˆ

#### å•å…ƒæµ‹è¯•

**åç«¯æµ‹è¯• (pytest)ï¼š**
```python
# tests/test_auth.py
import pytest
from fastapi.testclient import TestClient
from app.main import app
from app.core.config import settings

client = TestClient(app)

class TestAuth:
    def test_login_success(self):
        """æµ‹è¯•ç™»å½•æˆåŠŸ"""
        response = client.post(
            "/api/v1/auth/login",
            json={
                "username": "admin",
                "password": "admin1314159"
            }
        )
        assert response.status_code == 200
        data = response.json()
        assert "access_token" in data
        assert data["token_type"] == "bearer"
    
    def test_login_invalid_credentials(self):
        """æµ‹è¯•ç™»å½•å¤±è´¥"""
        response = client.post(
            "/api/v1/auth/login",
            json={
                "username": "admin",
                "password": "wrong_password"
            }
        )
        assert response.status_code == 401
    
    def test_license_activation(self):
        """æµ‹è¯•å¡å¯†æ¿€æ´»"""
        # å…ˆåˆ›å»ºæµ‹è¯•å¡å¯†
        license_code = "TEST-1234-5678-ABCD"
        
        response = client.post(
            "/api/v1/auth/activate",
            json={
                "license_code": license_code,
                "device_id": "test-device-001",
                "device_info": {
                    "os": "Windows 10",
                    "cpu": "Intel i7"
                }
            }
        )
        assert response.status_code == 200
        data = response.json()
        assert data["success"] is True
```

**å‰ç«¯æµ‹è¯• (Jest + React Testing Library)ï¼š**
```typescript
// __tests__/components/LoginForm.test.tsx
import { render, screen, fireEvent, waitFor } from '@testing-library/react';
import { LoginForm } from '@/components/LoginForm';
import { AuthProvider } from '@/contexts/AuthContext';

describe('LoginForm', () => {
  it('renders login form correctly', () => {
    render(
      <AuthProvider>
        <LoginForm />
      </AuthProvider>
    );
    
    expect(screen.getByLabelText(/ç”¨æˆ·å/i)).toBeInTheDocument();
    expect(screen.getByLabelText(/å¯†ç /i)).toBeInTheDocument();
    expect(screen.getByRole('button', { name: /ç™»å½•/i })).toBeInTheDocument();
  });
  
  it('shows validation errors for empty fields', async () => {
    render(
      <AuthProvider>
        <LoginForm />
      </AuthProvider>
    );
    
    const submitButton = screen.getByRole('button', { name: /ç™»å½•/i });
    fireEvent.click(submitButton);
    
    await waitFor(() => {
      expect(screen.getByText(/è¯·è¾“å…¥ç”¨æˆ·å/i)).toBeInTheDocument();
      expect(screen.getByText(/è¯·è¾“å…¥å¯†ç /i)).toBeInTheDocument();
    });
  });
  
  it('submits form with valid credentials', async () => {
    const mockLogin = jest.fn();
    
    render(
      <AuthProvider value={{ login: mockLogin }}>
        <LoginForm />
      </AuthProvider>
    );
    
    fireEvent.change(screen.getByLabelText(/ç”¨æˆ·å/i), {
      target: { value: 'admin' }
    });
    fireEvent.change(screen.getByLabelText(/å¯†ç /i), {
      target: { value: 'admin1314159' }
    });
    
    fireEvent.click(screen.getByRole('button', { name: /ç™»å½•/i }));
    
    await waitFor(() => {
      expect(mockLogin).toHaveBeenCalledWith({
        username: 'admin',
        password: 'admin1314159'
      });
    });
  });
});
```

#### é›†æˆæµ‹è¯•

```python
# tests/test_integration.py
import pytest
from fastapi.testclient import TestClient
from app.main import app
from app.db.session import get_db
from app.models.user import User
from app.models.license import LicenseCode

client = TestClient(app)

class TestLicenseWorkflow:
    """æµ‹è¯•å®Œæ•´çš„å¡å¯†å·¥ä½œæµç¨‹"""
    
    def test_complete_license_workflow(self, db_session):
        """æµ‹è¯•ä»åˆ›å»ºåˆ°æ¿€æ´»çš„å®Œæ•´æµç¨‹"""
        # 1. ç®¡ç†å‘˜ç™»å½•
        login_response = client.post(
            "/api/v1/auth/login",
            json={"username": "admin", "password": "admin1314159"}
        )
        token = login_response.json()["access_token"]
        headers = {"Authorization": f"Bearer {token}"}
        
        # 2. åˆ›å»ºåº”ç”¨
        app_response = client.post(
            "/api/v1/applications",
            json={
                "name": "æµ‹è¯•åº”ç”¨",
                "description": "ç”¨äºæµ‹è¯•çš„åº”ç”¨",
                "app_type": "desktop"
            },
            headers=headers
        )
        app_id = app_response.json()["id"]
        
        # 3. ç”Ÿæˆå¡å¯†
        license_response = client.post(
            "/api/v1/licenses/generate",
            json={
                "application_id": app_id,
                "count": 1,
                "expire_days": 365,
                "max_bind_devices": 1
            },
            headers=headers
        )
        license_codes = license_response.json()["codes"]
        license_code = license_codes[0]
        
        # 4. æ¿€æ´»å¡å¯†
        activate_response = client.post(
            "/api/v1/auth/activate",
            json={
                "license_code": license_code,
                "device_id": "test-device-001"
            }
        )
        assert activate_response.status_code == 200
        
        # 5. éªŒè¯å¡å¯†
        verify_response = client.post(
            "/api/v1/auth/verify",
            json={
                "license_code": license_code,
                "device_id": "test-device-001"
            }
        )
        assert verify_response.status_code == 200
        assert verify_response.json()["valid"] is True
```

#### æ€§èƒ½æµ‹è¯•

```python
# tests/test_performance.py
import time
import asyncio
from concurrent.futures import ThreadPoolExecutor
from fastapi.testclient import TestClient
from app.main import app

client = TestClient(app)

class TestPerformance:
    def test_api_response_time(self):
        """æµ‹è¯•APIå“åº”æ—¶é—´"""
        start_time = time.time()
        
        response = client.get("/api/v1/applications")
        
        end_time = time.time()
        response_time = end_time - start_time
        
        assert response.status_code == 200
        assert response_time < 0.3  # å“åº”æ—¶é—´åº”å°äº300ms
    
    def test_concurrent_requests(self):
        """æµ‹è¯•å¹¶å‘è¯·æ±‚å¤„ç†èƒ½åŠ›"""
        def make_request():
            return client.get("/api/v1/health")
        
        # æ¨¡æ‹Ÿ100ä¸ªå¹¶å‘è¯·æ±‚
        with ThreadPoolExecutor(max_workers=100) as executor:
            futures = [executor.submit(make_request) for _ in range(100)]
            results = [future.result() for future in futures]
        
        # æ‰€æœ‰è¯·æ±‚éƒ½åº”è¯¥æˆåŠŸ
        assert all(result.status_code == 200 for result in results)
```

### 6.4 æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### å‰ç«¯æ€§èƒ½ä¼˜åŒ–

**1. ä»£ç åˆ†å‰²å’Œæ‡’åŠ è½½**
```typescript
// è·¯ç”±çº§åˆ«çš„ä»£ç åˆ†å‰²
const Dashboard = lazy(() => import('@/pages/dashboard'));
const Applications = lazy(() => import('@/pages/applications'));
const Licenses = lazy(() => import('@/pages/licenses'));

// ç»„ä»¶çº§åˆ«çš„æ‡’åŠ è½½
const HeavyChart = lazy(() => import('@/components/HeavyChart'));

// ä½¿ç”¨SuspenseåŒ…è£…
<Suspense fallback={<LoadingSpinner />}>
  <HeavyChart data={chartData} />
</Suspense>
```

**2. å›¾ç‰‡å’Œèµ„æºä¼˜åŒ–**
```typescript
// next.config.js
module.exports = {
  images: {
    domains: ['example.com'],
    formats: ['image/webp', 'image/avif'],
  },
  
  // å¯ç”¨å‹ç¼©
  compress: true,
  
  // ä¼˜åŒ–å­—ä½“åŠ è½½
  optimizeFonts: true,
  
  // å¯ç”¨å®éªŒæ€§åŠŸèƒ½
  experimental: {
    optimizeCss: true,
    optimizeImages: true,
  }
};
```

**3. çŠ¶æ€ç®¡ç†ä¼˜åŒ–**
```typescript
// ä½¿ç”¨useMemoä¼˜åŒ–è®¡ç®—
const expensiveValue = useMemo(() => {
  return heavyCalculation(data);
}, [data]);

// ä½¿ç”¨useCallbackä¼˜åŒ–å‡½æ•°
const handleClick = useCallback((id: string) => {
  onItemClick(id);
}, [onItemClick]);

// è™šæ‹ŸåŒ–é•¿åˆ—è¡¨
import { FixedSizeList as List } from 'react-window';

const VirtualizedList = ({ items }) => (
  <List
    height={600}
    itemCount={items.length}
    itemSize={50}
    itemData={items}
  >
    {Row}
  </List>
);
```

#### åç«¯æ€§èƒ½ä¼˜åŒ–

**1. æ•°æ®åº“æŸ¥è¯¢ä¼˜åŒ–**
```python
# ä½¿ç”¨ç´¢å¼•ä¼˜åŒ–æŸ¥è¯¢
class LicenseCode(Base):
    # å¤åˆç´¢å¼•
    __table_args__ = (
        Index('idx_app_status_expire', 'application_id', 'status', 'expire_at'),
        Index('idx_batch_status', 'batch_id', 'status'),
    )

# æŸ¥è¯¢ä¼˜åŒ–
def get_licenses_optimized(db: Session, app_id: int, status: str):
    return db.query(LicenseCode)\
        .options(selectinload(LicenseCode.application))\
        .filter(
            LicenseCode.application_id == app_id,
            LicenseCode.status == status
        )\
        .order_by(LicenseCode.created_at.desc())\
        .limit(100)\
        .all()

# ä½¿ç”¨åŸç”ŸSQLå¤„ç†å¤æ‚æŸ¥è¯¢
def get_license_statistics(db: Session):
    result = db.execute(
        text("""
        SELECT 
            application_id,
            COUNT(*) as total_licenses,
            COUNT(CASE WHEN status = 1 THEN 1 END) as active_licenses,
            COUNT(CASE WHEN expire_at < NOW() THEN 1 END) as expired_licenses
        FROM license_codes 
        GROUP BY application_id
        """)
    )
    return result.fetchall()
```

**2. ç¼“å­˜ç­–ç•¥ä¼˜åŒ–**
```python
# å¤šçº§ç¼“å­˜
class CacheService:
    def __init__(self):
        self.local_cache = {}  # æœ¬åœ°ç¼“å­˜
        self.redis_client = redis.Redis()  # Redisç¼“å­˜
    
    async def get_with_cache(self, key: str, fetch_func, ttl: int = 3600):
        # L1: æœ¬åœ°ç¼“å­˜
        if key in self.local_cache:
            return self.local_cache[key]
        
        # L2: Redisç¼“å­˜
        cached_data = await self.redis_client.get(key)
        if cached_data:
            data = json.loads(cached_data)
            self.local_cache[key] = data
            return data
        
        # ç¼“å­˜æœªå‘½ä¸­ï¼Œä»æ•°æ®æºè·å–
        data = await fetch_func()
        if data:
            # å†™å…¥Redis
            await self.redis_client.setex(key, ttl, json.dumps(data))
            # å†™å…¥æœ¬åœ°ç¼“å­˜
            self.local_cache[key] = data
        
        return data

# ç¼“å­˜é¢„çƒ­
async def warm_up_cache():
    """ç³»ç»Ÿå¯åŠ¨æ—¶é¢„çƒ­ç¼“å­˜"""
    cache_service = CacheService()
    
    # é¢„çƒ­çƒ­ç‚¹æ•°æ®
    await cache_service.get_with_cache(
        "app_configs",
        lambda: get_all_app_configs()
    )
    
    await cache_service.get_with_cache(
        "user_roles",
        lambda: get_all_user_roles()
    )
```

**3. å¼‚æ­¥å¤„ç†ä¼˜åŒ–**
```python
# ä½¿ç”¨åå°ä»»åŠ¡å¤„ç†è€—æ—¶æ“ä½œ
from fastapi import BackgroundTasks

@router.post("/licenses/generate")
async def generate_licenses(
    request: LicenseGenerateRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db)
):
    # ç«‹å³è¿”å›ä»»åŠ¡ID
    task_id = str(uuid.uuid4())
    
    # åå°æ‰§è¡Œç”Ÿæˆä»»åŠ¡
    background_tasks.add_task(
        generate_licenses_task,
        task_id,
        request.dict(),
        db
    )
    
    return {"task_id": task_id, "status": "processing"}

async def generate_licenses_task(task_id: str, params: dict, db: Session):
    """åå°ç”Ÿæˆå¡å¯†ä»»åŠ¡"""
    try:
        # æ›´æ–°ä»»åŠ¡çŠ¶æ€
        await update_task_status(task_id, "running")
        
        # æ‰¹é‡ç”Ÿæˆå¡å¯†
        licenses = []
        for i in range(params["count"]):
            license = create_license_code(params, db)
            licenses.append(license)
            
            # æ¯100ä¸ªæäº¤ä¸€æ¬¡
            if len(licenses) % 100 == 0:
                db.commit()
        
        # æœ€ç»ˆæäº¤
        db.commit()
        
        # æ›´æ–°ä»»åŠ¡å®ŒæˆçŠ¶æ€
        await update_task_status(task_id, "completed", {
            "generated_count": len(licenses)
        })
        
    except Exception as e:
        await update_task_status(task_id, "failed", {
            "error": str(e)
        })
```

### 6.5 å·²çŸ¥é—®é¢˜åˆ—è¡¨

#### å½“å‰å·²çŸ¥é—®é¢˜

**é«˜ä¼˜å…ˆçº§é—®é¢˜ï¼š**

1. **é…ç½®ç¡¬ç¼–ç é—®é¢˜**
   - **æè¿°**ï¼šéƒ¨åˆ†é…ç½®ä¿¡æ¯ç¡¬ç¼–ç åœ¨ä»£ç ä¸­
   - **å½±å“**ï¼šéš¾ä»¥åœ¨ä¸åŒç¯å¢ƒé—´åˆ‡æ¢
   - **è§£å†³æ–¹æ¡ˆ**ï¼šå°†æ‰€æœ‰é…ç½®ç§»è‡³ç¯å¢ƒå˜é‡
   - **çŠ¶æ€**ï¼šè®¡åˆ’ä¿®å¤

2. **é”™è¯¯å¤„ç†ä¸å®Œå–„**
   - **æè¿°**ï¼šæŸäº›å¼‚å¸¸æƒ…å†µç¼ºå°‘é€‚å½“çš„é”™è¯¯å¤„ç†
   - **å½±å“**ï¼šå¯èƒ½å¯¼è‡´ç³»ç»Ÿå´©æºƒæˆ–ç”¨æˆ·ä½“éªŒå·®
   - **è§£å†³æ–¹æ¡ˆ**ï¼šå®Œå–„å…¨å±€å¼‚å¸¸å¤„ç†æœºåˆ¶
   - **çŠ¶æ€**ï¼šå¼€å‘ä¸­

3. **æ•°æ®åº“è¿æ¥æ± é…ç½®**
   - **æè¿°**ï¼šæ•°æ®åº“è¿æ¥æ± å‚æ•°éœ€è¦æ ¹æ®è´Ÿè½½è°ƒä¼˜
   - **å½±å“**ï¼šé«˜å¹¶å‘æ—¶å¯èƒ½å‡ºç°è¿æ¥ä¸è¶³
   - **è§£å†³æ–¹æ¡ˆ**ï¼šä¼˜åŒ–è¿æ¥æ± é…ç½®
   - **çŠ¶æ€**ï¼šå¾…ä¼˜åŒ–

**ä¸­ä¼˜å…ˆçº§é—®é¢˜ï¼š**

4. **å‰ç«¯ç±»å‹å®šä¹‰ä¸å®Œæ•´**
   - **æè¿°**ï¼šéƒ¨åˆ†APIå“åº”ç¼ºå°‘TypeScriptç±»å‹å®šä¹‰
   - **å½±å“**ï¼šå¼€å‘æ—¶ç¼ºå°‘ç±»å‹æ£€æŸ¥
   - **è§£å†³æ–¹æ¡ˆ**ï¼šè¡¥å……å®Œæ•´çš„ç±»å‹å®šä¹‰
   - **çŠ¶æ€**ï¼šé€æ­¥å®Œå–„

5. **æ—¥å¿—ç³»ç»Ÿå¾…å®Œå–„**
   - **æè¿°**ï¼šç¼ºå°‘ç»“æ„åŒ–æ—¥å¿—å’Œæ—¥å¿—è½®è½¬
   - **å½±å“**ï¼šéš¾ä»¥è¿›è¡Œé—®é¢˜æ’æŸ¥å’Œç›‘æ§
   - **è§£å†³æ–¹æ¡ˆ**ï¼šå¼•å…¥ç»“æ„åŒ–æ—¥å¿—æ¡†æ¶
   - **çŠ¶æ€**ï¼šè®¡åˆ’ä¸­

6. **ç¼“å­˜å¤±æ•ˆç­–ç•¥**
   - **æè¿°**ï¼šç¼“å­˜å¤±æ•ˆç­–ç•¥éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–
   - **å½±å“**ï¼šå¯èƒ½å‡ºç°æ•°æ®ä¸ä¸€è‡´
   - **è§£å†³æ–¹æ¡ˆ**ï¼šå®ç°æ›´ç²¾ç¡®çš„ç¼“å­˜å¤±æ•ˆæœºåˆ¶
   - **çŠ¶æ€**ï¼šç ”ç©¶ä¸­

**ä½ä¼˜å…ˆçº§é—®é¢˜ï¼š**

7. **å›½é™…åŒ–æ”¯æŒ**
   - **æè¿°**ï¼šç›®å‰åªæ”¯æŒä¸­æ–‡ç•Œé¢
   - **å½±å“**ï¼šé™åˆ¶äº†å›½é™…åŒ–ä½¿ç”¨
   - **è§£å†³æ–¹æ¡ˆ**ï¼šæ·»åŠ i18næ”¯æŒ
   - **çŠ¶æ€**ï¼šæœªæ¥ç‰ˆæœ¬

8. **ç§»åŠ¨ç«¯é€‚é…**
   - **æè¿°**ï¼šç§»åŠ¨ç«¯ä½“éªŒæœ‰å¾…ä¼˜åŒ–
   - **å½±å“**ï¼šç§»åŠ¨è®¾å¤‡ä½¿ç”¨ä½“éªŒä¸ä½³
   - **è§£å†³æ–¹æ¡ˆ**ï¼šä¼˜åŒ–ç§»åŠ¨ç«¯ç•Œé¢
   - **çŠ¶æ€**ï¼šæœªæ¥ç‰ˆæœ¬

#### æ€§èƒ½ç“¶é¢ˆ

1. **å¤§é‡å¡å¯†æŸ¥è¯¢æ€§èƒ½**
   - **åœºæ™¯**ï¼šå½“å¡å¯†æ•°é‡è¶…è¿‡10ä¸‡æ—¶æŸ¥è¯¢å˜æ…¢
   - **ä¸´æ—¶æ–¹æ¡ˆ**ï¼šæ·»åŠ åˆ†é¡µå’Œç´¢å¼•
   - **é•¿æœŸæ–¹æ¡ˆ**ï¼šè€ƒè™‘åˆ†åº“åˆ†è¡¨

2. **å®æ—¶é€šçŸ¥æ€§èƒ½**
   - **åœºæ™¯**ï¼šå¤§é‡ç”¨æˆ·åŒæ—¶åœ¨çº¿æ—¶WebSocketè¿æ¥å‹åŠ›å¤§
   - **ä¸´æ—¶æ–¹æ¡ˆ**ï¼šé™åˆ¶è¿æ¥æ•°
   - **é•¿æœŸæ–¹æ¡ˆ**ï¼šä½¿ç”¨æ¶ˆæ¯é˜Ÿåˆ—ä¼˜åŒ–

#### 3.3.8 å®æ—¶é€šçŸ¥æ€§èƒ½ä¼˜åŒ–

**æ–‡ä»¶è·¯å¾„ï¼š`services/notification_service.py`**

```python
from typing import Dict, List, Optional, Any, Callable
from enum import Enum
from dataclasses import dataclass, field
from datetime import datetime, timedelta
import asyncio
import json
import redis.asyncio as redis
from fastapi import WebSocket
from sqlalchemy.ext.asyncio import AsyncSession
from app.core.database import get_db
from app.core.logger import get_logger
from app.services.event_bus import event_bus
from app.models.user import User
from app.models.application import Application

logger = get_logger(__name__)

class NotificationType(str, Enum):
    """é€šçŸ¥ç±»å‹æšä¸¾"""
    LICENSE_EXPIRY = "license_expiry"
    LICENSE_ACTIVATED = "license_activated"
    LICENSE_DEACTIVATED = "license_deactivated"
    APPLICATION_UPDATE = "application_update"
    SYSTEM_ANNOUNCEMENT = "system_announcement"
    SECURITY_ALERT = "security_alert"
    MAINTENANCE_NOTICE = "maintenance_notice"
    USER_LOGIN = "user_login"
    DEVICE_BINDING = "device_binding"
    QUOTA_WARNING = "quota_warning"

class NotificationPriority(str, Enum):
    """é€šçŸ¥ä¼˜å…ˆçº§"""
    LOW = "low"
    NORMAL = "normal"
    HIGH = "high"
    URGENT = "urgent"

class DeliveryChannel(str, Enum):
    """æŠ•é€’æ¸ é“"""
    WEBSOCKET = "websocket"
    EMAIL = "email"
    SMS = "sms"
    PUSH = "push"
    IN_APP = "in_app"

@dataclass
class NotificationMessage:
    """é€šçŸ¥æ¶ˆæ¯æ•°æ®ç»“æ„"""
    id: str
    type: NotificationType
    priority: NotificationPriority
    title: str
    content: str
    recipient_id: Optional[str] = None
    recipient_type: str = "user"  # user, application, broadcast
    channels: List[DeliveryChannel] = field(default_factory=lambda: [DeliveryChannel.WEBSOCKET])
    metadata: Dict[str, Any] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.utcnow)
    expires_at: Optional[datetime] = None
    retry_count: int = 0
    max_retries: int = 3
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            "id": self.id,
            "type": self.type.value,
            "priority": self.priority.value,
            "title": self.title,
            "content": self.content,
            "recipient_id": self.recipient_id,
            "recipient_type": self.recipient_type,
            "channels": [ch.value for ch in self.channels],
            "metadata": self.metadata,
            "created_at": self.created_at.isoformat(),
            "expires_at": self.expires_at.isoformat() if self.expires_at else None,
            "retry_count": self.retry_count,
            "max_retries": self.max_retries
        }

class MessageQueue:
    """åŸºäºRedisçš„æ¶ˆæ¯é˜Ÿåˆ—"""
    
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client
        self.queues = {
            NotificationPriority.URGENT: "notifications:urgent",
            NotificationPriority.HIGH: "notifications:high",
            NotificationPriority.NORMAL: "notifications:normal",
            NotificationPriority.LOW: "notifications:low"
        }
        self.processing_queue = "notifications:processing"
        self.failed_queue = "notifications:failed"
        self.dead_letter_queue = "notifications:dead_letter"
    
    async def enqueue(self, message: NotificationMessage) -> bool:
        """å°†æ¶ˆæ¯åŠ å…¥é˜Ÿåˆ—"""
        try:
            queue_name = self.queues[message.priority]
            message_data = json.dumps(message.to_dict())
            
            # ä½¿ç”¨Redisçš„LPUSHæ·»åŠ åˆ°é˜Ÿåˆ—å¤´éƒ¨ï¼ˆé«˜ä¼˜å…ˆçº§å…ˆå¤„ç†ï¼‰
            await self.redis.lpush(queue_name, message_data)
            
            # è®¾ç½®æ¶ˆæ¯è¿‡æœŸæ—¶é—´
            if message.expires_at:
                ttl = int((message.expires_at - datetime.utcnow()).total_seconds())
                await self.redis.expire(f"msg:{message.id}", ttl)
            
            logger.info(f"Message {message.id} enqueued to {queue_name}")
            return True
            
        except Exception as e:
            logger.error(f"Failed to enqueue message {message.id}: {e}")
            return False
    
    async def dequeue(self, timeout: int = 10) -> Optional[NotificationMessage]:
        """ä»é˜Ÿåˆ—ä¸­å–å‡ºæ¶ˆæ¯ï¼ˆæŒ‰ä¼˜å…ˆçº§é¡ºåºï¼‰"""
        try:
            # æŒ‰ä¼˜å…ˆçº§é¡ºåºæ£€æŸ¥é˜Ÿåˆ—
            queue_names = [
                self.queues[NotificationPriority.URGENT],
                self.queues[NotificationPriority.HIGH],
                self.queues[NotificationPriority.NORMAL],
                self.queues[NotificationPriority.LOW]
            ]
            
            # ä½¿ç”¨BRPOPé˜»å¡å¼å¼¹å‡ºï¼ˆä»é˜Ÿåˆ—å°¾éƒ¨å–å‡ºï¼‰
            result = await self.redis.brpop(queue_names, timeout=timeout)
            
            if result:
                queue_name, message_data = result
                message_dict = json.loads(message_data)
                
                # é‡æ„NotificationMessageå¯¹è±¡
                message = NotificationMessage(
                    id=message_dict["id"],
                    type=NotificationType(message_dict["type"]),
                    priority=NotificationPriority(message_dict["priority"]),
                    title=message_dict["title"],
                    content=message_dict["content"],
                    recipient_id=message_dict.get("recipient_id"),
                    recipient_type=message_dict.get("recipient_type", "user"),
                    channels=[DeliveryChannel(ch) for ch in message_dict.get("channels", [])],
                    metadata=message_dict.get("metadata", {}),
                    created_at=datetime.fromisoformat(message_dict["created_at"]),
                    expires_at=datetime.fromisoformat(message_dict["expires_at"]) if message_dict.get("expires_at") else None,
                    retry_count=message_dict.get("retry_count", 0),
                    max_retries=message_dict.get("max_retries", 3)
                )
                
                # ç§»åŠ¨åˆ°å¤„ç†é˜Ÿåˆ—
                await self.redis.lpush(self.processing_queue, message_data)
                
                return message
            
            return None
            
        except Exception as e:
            logger.error(f"Failed to dequeue message: {e}")
            return None
    
    async def mark_completed(self, message_id: str) -> bool:
        """æ ‡è®°æ¶ˆæ¯å¤„ç†å®Œæˆ"""
        try:
            # ä»å¤„ç†é˜Ÿåˆ—ä¸­ç§»é™¤
            processing_messages = await self.redis.lrange(self.processing_queue, 0, -1)
            for msg_data in processing_messages:
                msg_dict = json.loads(msg_data)
                if msg_dict["id"] == message_id:
                    await self.redis.lrem(self.processing_queue, 1, msg_data)
                    logger.info(f"Message {message_id} marked as completed")
                    return True
            
            return False
            
        except Exception as e:
            logger.error(f"Failed to mark message {message_id} as completed: {e}")
            return False
    
    async def mark_failed(self, message: NotificationMessage) -> bool:
        """æ ‡è®°æ¶ˆæ¯å¤„ç†å¤±è´¥"""
        try:
            message.retry_count += 1
            
            if message.retry_count <= message.max_retries:
                # é‡æ–°åŠ å…¥é˜Ÿåˆ—é‡è¯•
                await self.enqueue(message)
                logger.warning(f"Message {message.id} failed, retry {message.retry_count}/{message.max_retries}")
            else:
                # ç§»åŠ¨åˆ°æ­»ä¿¡é˜Ÿåˆ—
                await self.redis.lpush(self.dead_letter_queue, json.dumps(message.to_dict()))
                logger.error(f"Message {message.id} moved to dead letter queue after {message.max_retries} retries")
            
            # ä»å¤„ç†é˜Ÿåˆ—ä¸­ç§»é™¤
            await self.mark_completed(message.id)
            return True
            
        except Exception as e:
            logger.error(f"Failed to mark message {message.id} as failed: {e}")
            return False
    
    async def get_queue_stats(self) -> Dict[str, int]:
        """è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯"""
        stats = {}
        
        for priority, queue_name in self.queues.items():
            stats[f"{priority.value}_queue"] = await self.redis.llen(queue_name)
        
        stats["processing_queue"] = await self.redis.llen(self.processing_queue)
        stats["failed_queue"] = await self.redis.llen(self.failed_queue)
        stats["dead_letter_queue"] = await self.redis.llen(self.dead_letter_queue)
        
        return stats

class WebSocketManager:
    """WebSocketè¿æ¥ç®¡ç†å™¨"""
    
    def __init__(self):
        # ç”¨æˆ·è¿æ¥æ˜ å°„ï¼šuser_id -> List[WebSocket]
        self.user_connections: Dict[str, List[WebSocket]] = {}
        # åº”ç”¨è¿æ¥æ˜ å°„ï¼šapp_id -> List[WebSocket]
        self.app_connections: Dict[str, List[WebSocket]] = {}
        # å¹¿æ’­è¿æ¥åˆ—è¡¨
        self.broadcast_connections: List[WebSocket] = []
        # è¿æ¥å…ƒæ•°æ®ï¼šWebSocket -> Dict
        self.connection_metadata: Dict[WebSocket, Dict[str, Any]] = {}
    
    async def connect(self, websocket: WebSocket, user_id: Optional[str] = None, 
                     app_id: Optional[str] = None, metadata: Optional[Dict] = None):
        """å»ºç«‹WebSocketè¿æ¥"""
        await websocket.accept()
        
        # å­˜å‚¨è¿æ¥å…ƒæ•°æ®
        self.connection_metadata[websocket] = {
            "user_id": user_id,
            "app_id": app_id,
            "connected_at": datetime.utcnow(),
            "metadata": metadata or {}
        }
        
        # æ ¹æ®ç±»å‹æ·»åŠ åˆ°ç›¸åº”çš„è¿æ¥æ± 
        if user_id:
            if user_id not in self.user_connections:
                self.user_connections[user_id] = []
            self.user_connections[user_id].append(websocket)
        
        if app_id:
            if app_id not in self.app_connections:
                self.app_connections[app_id] = []
            self.app_connections[app_id].append(websocket)
        
        # æ·»åŠ åˆ°å¹¿æ’­è¿æ¥æ± 
        self.broadcast_connections.append(websocket)
        
        logger.info(f"WebSocket connected: user_id={user_id}, app_id={app_id}")
    
    async def disconnect(self, websocket: WebSocket):
        """æ–­å¼€WebSocketè¿æ¥"""
        metadata = self.connection_metadata.get(websocket, {})
        user_id = metadata.get("user_id")
        app_id = metadata.get("app_id")
        
        # ä»å„ä¸ªè¿æ¥æ± ä¸­ç§»é™¤
        if user_id and user_id in self.user_connections:
            self.user_connections[user_id] = [
                ws for ws in self.user_connections[user_id] if ws != websocket
            ]
            if not self.user_connections[user_id]:
                del self.user_connections[user_id]
        
        if app_id and app_id in self.app_connections:
            self.app_connections[app_id] = [
                ws for ws in self.app_connections[app_id] if ws != websocket
            ]
            if not self.app_connections[app_id]:
                del self.app_connections[app_id]
        
        if websocket in self.broadcast_connections:
            self.broadcast_connections.remove(websocket)
        
        if websocket in self.connection_metadata:
            del self.connection_metadata[websocket]
        
        logger.info(f"WebSocket disconnected: user_id={user_id}, app_id={app_id}")
    
    async def send_to_user(self, user_id: str, message: Dict[str, Any]) -> int:
        """å‘é€æ¶ˆæ¯ç»™ç‰¹å®šç”¨æˆ·"""
        sent_count = 0
        
        if user_id in self.user_connections:
            connections = self.user_connections[user_id].copy()
            
            for websocket in connections:
                try:
                    await websocket.send_json(message)
                    sent_count += 1
                except Exception as e:
                    logger.warning(f"Failed to send message to user {user_id}: {e}")
                    await self.disconnect(websocket)
        
        return sent_count
    
    async def send_to_app(self, app_id: str, message: Dict[str, Any]) -> int:
        """å‘é€æ¶ˆæ¯ç»™ç‰¹å®šåº”ç”¨çš„æ‰€æœ‰è¿æ¥"""
        sent_count = 0
        
        if app_id in self.app_connections:
            connections = self.app_connections[app_id].copy()
            
            for websocket in connections:
                try:
                    await websocket.send_json(message)
                    sent_count += 1
                except Exception as e:
                    logger.warning(f"Failed to send message to app {app_id}: {e}")
                    await self.disconnect(websocket)
        
        return sent_count
    
    async def broadcast(self, message: Dict[str, Any]) -> int:
        """å¹¿æ’­æ¶ˆæ¯ç»™æ‰€æœ‰è¿æ¥"""
        sent_count = 0
        connections = self.broadcast_connections.copy()
        
        for websocket in connections:
            try:
                await websocket.send_json(message)
                sent_count += 1
            except Exception as e:
                logger.warning(f"Failed to broadcast message: {e}")
                await self.disconnect(websocket)
        
        return sent_count
    
    def get_connection_stats(self) -> Dict[str, Any]:
        """è·å–è¿æ¥ç»Ÿè®¡ä¿¡æ¯"""
        return {
            "total_connections": len(self.broadcast_connections),
            "user_connections": len(self.user_connections),
            "app_connections": len(self.app_connections),
            "users_online": list(self.user_connections.keys()),
            "apps_connected": list(self.app_connections.keys())
        }

class NotificationService:
    """é€šçŸ¥æœåŠ¡ä¸»ç±»"""
    
    def __init__(self, redis_client: redis.Redis):
        self.message_queue = MessageQueue(redis_client)
        self.websocket_manager = WebSocketManager()
        self.delivery_handlers: Dict[DeliveryChannel, Callable] = {}
        self.is_running = False
        self.worker_tasks: List[asyncio.Task] = []
        
        # æ³¨å†Œé»˜è®¤æŠ•é€’å¤„ç†å™¨
        self.register_delivery_handler(DeliveryChannel.WEBSOCKET, self._handle_websocket_delivery)
    
    def register_delivery_handler(self, channel: DeliveryChannel, handler: Callable):
        """æ³¨å†ŒæŠ•é€’æ¸ é“å¤„ç†å™¨"""
        self.delivery_handlers[channel] = handler
        logger.info(f"Registered delivery handler for {channel.value}")
    
    async def send_notification(self, message: NotificationMessage) -> bool:
        """å‘é€é€šçŸ¥ï¼ˆåŠ å…¥é˜Ÿåˆ—ï¼‰"""
        return await self.message_queue.enqueue(message)
    
    async def _handle_websocket_delivery(self, message: NotificationMessage) -> bool:
        """å¤„ç†WebSocketæŠ•é€’"""
        try:
            notification_data = {
                "id": message.id,
                "type": message.type.value,
                "priority": message.priority.value,
                "title": message.title,
                "content": message.content,
                "metadata": message.metadata,
                "timestamp": message.created_at.isoformat()
            }
            
            sent_count = 0
            
            if message.recipient_type == "user" and message.recipient_id:
                sent_count = await self.websocket_manager.send_to_user(
                    message.recipient_id, notification_data
                )
            elif message.recipient_type == "application" and message.recipient_id:
                sent_count = await self.websocket_manager.send_to_app(
                    message.recipient_id, notification_data
                )
            elif message.recipient_type == "broadcast":
                sent_count = await self.websocket_manager.broadcast(notification_data)
            
            logger.info(f"WebSocket notification {message.id} sent to {sent_count} connections")
            return sent_count > 0
            
        except Exception as e:
            logger.error(f"Failed to handle WebSocket delivery for {message.id}: {e}")
            return False
    
    async def _process_message(self, message: NotificationMessage) -> bool:
        """å¤„ç†å•ä¸ªæ¶ˆæ¯"""
        try:
            # æ£€æŸ¥æ¶ˆæ¯æ˜¯å¦è¿‡æœŸ
            if message.expires_at and datetime.utcnow() > message.expires_at:
                logger.warning(f"Message {message.id} expired, skipping")
                return True
            
            success = True
            
            # æŒ‰æ¸ é“æŠ•é€’æ¶ˆæ¯
            for channel in message.channels:
                if channel in self.delivery_handlers:
                    try:
                        result = await self.delivery_handlers[channel](message)
                        if not result:
                            success = False
                            logger.warning(f"Failed to deliver message {message.id} via {channel.value}")
                    except Exception as e:
                        success = False
                        logger.error(f"Error delivering message {message.id} via {channel.value}: {e}")
                else:
                    logger.warning(f"No handler registered for delivery channel {channel.value}")
            
            return success
            
        except Exception as e:
            logger.error(f"Error processing message {message.id}: {e}")
            return False
    
    async def _worker(self, worker_id: int):
        """æ¶ˆæ¯å¤„ç†å·¥ä½œçº¿ç¨‹"""
        logger.info(f"Notification worker {worker_id} started")
        
        while self.is_running:
            try:
                # ä»é˜Ÿåˆ—ä¸­è·å–æ¶ˆæ¯
                message = await self.message_queue.dequeue(timeout=5)
                
                if message:
                    logger.debug(f"Worker {worker_id} processing message {message.id}")
                    
                    # å¤„ç†æ¶ˆæ¯
                    success = await self._process_message(message)
                    
                    if success:
                        await self.message_queue.mark_completed(message.id)
                        logger.debug(f"Message {message.id} processed successfully")
                    else:
                        await self.message_queue.mark_failed(message)
                        logger.warning(f"Message {message.id} processing failed")
                
            except asyncio.CancelledError:
                logger.info(f"Worker {worker_id} cancelled")
                break
            except Exception as e:
                logger.error(f"Worker {worker_id} error: {e}")
                await asyncio.sleep(1)  # é¿å…é”™è¯¯å¾ªç¯
        
        logger.info(f"Notification worker {worker_id} stopped")
    
    async def start(self, worker_count: int = 3):
        """å¯åŠ¨é€šçŸ¥æœåŠ¡"""
        if self.is_running:
            logger.warning("Notification service is already running")
            return
        
        self.is_running = True
        
        # å¯åŠ¨å·¥ä½œçº¿ç¨‹
        for i in range(worker_count):
            task = asyncio.create_task(self._worker(i))
            self.worker_tasks.append(task)
        
        logger.info(f"Notification service started with {worker_count} workers")
    
    async def stop(self):
        """åœæ­¢é€šçŸ¥æœåŠ¡"""
        if not self.is_running:
            return
        
        self.is_running = False
        
        # å–æ¶ˆæ‰€æœ‰å·¥ä½œä»»åŠ¡
        for task in self.worker_tasks:
            task.cancel()
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        if self.worker_tasks:
            await asyncio.gather(*self.worker_tasks, return_exceptions=True)
        
        self.worker_tasks.clear()
        logger.info("Notification service stopped")
    
    async def get_service_stats(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡ç»Ÿè®¡ä¿¡æ¯"""
        queue_stats = await self.message_queue.get_queue_stats()
        connection_stats = self.websocket_manager.get_connection_stats()
        
        return {
            "service_status": "running" if self.is_running else "stopped",
            "worker_count": len(self.worker_tasks),
            "queue_stats": queue_stats,
            "connection_stats": connection_stats,
            "delivery_channels": list(self.delivery_handlers.keys())
        }

# å…¨å±€é€šçŸ¥æœåŠ¡å®ä¾‹
notification_service: Optional[NotificationService] = None

def get_notification_service() -> NotificationService:
    """è·å–é€šçŸ¥æœåŠ¡å®ä¾‹"""
    global notification_service
    if notification_service is None:
        raise RuntimeError("Notification service not initialized")
    return notification_service

def init_notification_service(redis_client: redis.Redis) -> NotificationService:
    """åˆå§‹åŒ–é€šçŸ¥æœåŠ¡"""
    global notification_service
    notification_service = NotificationService(redis_client)
    return notification_service
```

**æ–‡ä»¶è·¯å¾„ï¼š`api/websocket.py`**

```python
from fastapi import APIRouter, WebSocket, WebSocketDisconnect, Depends, HTTPException
from typing import Optional
import json
from app.core.auth import get_current_user_websocket
from app.services.notification_service import get_notification_service
from app.core.logger import get_logger

logger = get_logger(__name__)
router = APIRouter()

@router.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    """é€šç”¨WebSocketç«¯ç‚¹"""
    notification_service = get_notification_service()
    
    try:
        # å»ºç«‹è¿æ¥
        await notification_service.websocket_manager.connect(websocket)
        
        while True:
            # æ¥æ”¶å®¢æˆ·ç«¯æ¶ˆæ¯
            data = await websocket.receive_text()
            message = json.loads(data)
            
            # å¤„ç†è®¤è¯æ¶ˆæ¯
            if message.get("type") == "auth":
                token = message.get("token")
                if token:
                    try:
                        # éªŒè¯tokenå¹¶è·å–ç”¨æˆ·ä¿¡æ¯
                        user = await get_current_user_websocket(token)
                        if user:
                            # é‡æ–°è¿æ¥å¹¶å…³è”ç”¨æˆ·
                            await notification_service.websocket_manager.disconnect(websocket)
                            await notification_service.websocket_manager.connect(
                                websocket, 
                                user_id=str(user.id),
                                metadata={"username": user.username, "role": user.role}
                            )
                            
                            await websocket.send_json({
                                "type": "auth_success",
                                "user_id": str(user.id),
                                "username": user.username
                            })
                        else:
                            await websocket.send_json({
                                "type": "auth_error",
                                "message": "Invalid token"
                            })
                    except Exception as e:
                        await websocket.send_json({
                            "type": "auth_error",
                            "message": str(e)
                        })
            
            # å¤„ç†å¿ƒè·³æ¶ˆæ¯
            elif message.get("type") == "ping":
                await websocket.send_json({"type": "pong"})
            
            # å¤„ç†å…¶ä»–æ¶ˆæ¯ç±»å‹
            else:
                logger.debug(f"Received WebSocket message: {message}")
    
    except WebSocketDisconnect:
        logger.info("WebSocket disconnected")
    except Exception as e:
        logger.error(f"WebSocket error: {e}")
    finally:
        await notification_service.websocket_manager.disconnect(websocket)

@router.websocket("/ws/app/{app_id}")
async def app_websocket_endpoint(websocket: WebSocket, app_id: str):
    """åº”ç”¨ä¸“ç”¨WebSocketç«¯ç‚¹"""
    notification_service = get_notification_service()
    
    try:
        # å»ºç«‹åº”ç”¨è¿æ¥
        await notification_service.websocket_manager.connect(
            websocket, 
            app_id=app_id,
            metadata={"app_id": app_id}
        )
        
        while True:
            data = await websocket.receive_text()
            message = json.loads(data)
            
            # å¤„ç†åº”ç”¨æ¶ˆæ¯
            if message.get("type") == "app_status":
                await websocket.send_json({
                    "type": "status_ack",
                    "app_id": app_id,
                    "timestamp": message.get("timestamp")
                })
            
            elif message.get("type") == "ping":
                await websocket.send_json({"type": "pong"})
    
    except WebSocketDisconnect:
        logger.info(f"App WebSocket disconnected: {app_id}")
    except Exception as e:
        logger.error(f"App WebSocket error for {app_id}: {e}")
    finally:
        await notification_service.websocket_manager.disconnect(websocket)
```

#### å®‰å…¨è€ƒè™‘

1. **å¯†é’¥è½®æ¢æœºåˆ¶**
   - **ç°çŠ¶**ï¼šJWTå¯†é’¥å’ŒåŠ å¯†å¯†é’¥ä¸ºé™æ€é…ç½®
   - **é£é™©**ï¼šé•¿æœŸä½¿ç”¨åŒä¸€å¯†é’¥å­˜åœ¨å®‰å…¨é£é™©
   - **å»ºè®®**ï¼šå®ç°å®šæœŸå¯†é’¥è½®æ¢æœºåˆ¶

2. **APIé™æµç­–ç•¥**
   - **ç°çŠ¶**ï¼šåŸºç¡€çš„IPé™æµ
   - **æ”¹è¿›**ï¼šå®ç°æ›´ç²¾ç»†çš„ç”¨æˆ·çº§åˆ«é™æµ

3. **å®¡è®¡æ—¥å¿—å®Œæ•´æ€§**
   - **ç°çŠ¶**ï¼šåŸºæœ¬çš„æ“ä½œæ—¥å¿—è®°å½•
   - **æ”¹è¿›**ï¼šå¢åŠ æ—¥å¿—å®Œæ•´æ€§æ ¡éªŒå’Œé˜²ç¯¡æ”¹æœºåˆ¶

---

## éƒ¨ç½²æŒ‡å—

### 4.1 ç¯å¢ƒå‡†å¤‡

**ç³»ç»Ÿè¦æ±‚ï¼š**
- æ“ä½œç³»ç»Ÿï¼šUbuntu 20.04+ / CentOS 8+ / macOS 10.15+
- Pythonï¼š3.9+
- Node.jsï¼š18+
- PostgreSQLï¼š13+
- Redisï¼š6+
- Nginxï¼š1.18+

**ä¾èµ–å®‰è£…ï¼š**

```bash
# Ubuntu/Debian
sudo apt update
sudo apt install python3.9 python3.9-venv python3.9-dev
sudo apt install nodejs npm
sudo apt install postgresql postgresql-contrib
sudo apt install redis-server
sudo apt install nginx

# CentOS/RHEL
sudo yum update
sudo yum install python39 python39-devel
sudo yum install nodejs npm
sudo yum install postgresql postgresql-server postgresql-contrib
sudo yum install redis
sudo yum install nginx

# macOS
brew install python@3.9
brew install node
brew install postgresql
brew install redis
brew install nginx
```

### 4.2 æ•°æ®åº“é…ç½®

**PostgreSQLé…ç½®ï¼š**

```sql
-- åˆ›å»ºæ•°æ®åº“å’Œç”¨æˆ·
CREATE DATABASE goldfish_license_system;
CREATE USER goldfish_user WITH PASSWORD 'your_secure_password';
GRANT ALL PRIVILEGES ON DATABASE goldfish_license_system TO goldfish_user;

-- é…ç½®è¿æ¥å‚æ•°
ALTER SYSTEM SET max_connections = 200;
ALTER SYSTEM SET shared_buffers = '256MB';
ALTER SYSTEM SET effective_cache_size = '1GB';
ALTER SYSTEM SET work_mem = '4MB';
ALTER SYSTEM SET maintenance_work_mem = '64MB';
SELECT pg_reload_conf();
```

**Redisé…ç½®ï¼š**

```bash
# ç¼–è¾‘ /etc/redis/redis.conf
maxmemory 512mb
maxmemory-policy allkeys-lru
save 900 1
save 300 10
save 60 10000
appendonly yes
appendfsync everysec

# é‡å¯RedisæœåŠ¡
sudo systemctl restart redis
```

### 4.3 åç«¯éƒ¨ç½²

**1. å…‹éš†ä»£ç å¹¶å®‰è£…ä¾èµ–ï¼š**

```bash
git clone <repository_url>
cd goldfish-license-system/backend

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3.9 -m venv venv
source venv/bin/activate

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

**2. ç¯å¢ƒé…ç½®ï¼š**

```bash
# å¤åˆ¶ç¯å¢ƒé…ç½®æ–‡ä»¶
cp .env.example .env

# ç¼–è¾‘é…ç½®æ–‡ä»¶
vim .env
```

**3. æ•°æ®åº“è¿ç§»ï¼š**

```bash
# è¿è¡Œæ•°æ®åº“è¿ç§»
alembic upgrade head

# åˆ›å»ºåˆå§‹ç®¡ç†å‘˜ç”¨æˆ·
python scripts/create_admin.py
```

**4. å¯åŠ¨æœåŠ¡ï¼š**

```bash
# å¼€å‘ç¯å¢ƒ
uvicorn main:app --host 0.0.0.0 --port 8000 --reload

# ç”Ÿäº§ç¯å¢ƒ
gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

### 4.4 å‰ç«¯éƒ¨ç½²

**1. å®‰è£…ä¾èµ–å¹¶æ„å»ºï¼š**

```bash
cd ../frontend
npm install

# é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env.local
vim .env.local

# æ„å»ºç”Ÿäº§ç‰ˆæœ¬
npm run build
```

**2. å¯åŠ¨æœåŠ¡ï¼š**

```bash
# å¼€å‘ç¯å¢ƒ
npm run dev

# ç”Ÿäº§ç¯å¢ƒ
npm run start
```

### 4.5 Nginxé…ç½®

**é…ç½®æ–‡ä»¶ï¼š`/etc/nginx/sites-available/goldfish-license`**

```nginx
server {
    listen 80;
    server_name your-domain.com;
    
    # é‡å®šå‘åˆ°HTTPS
    return 301 https://$server_name$request_uri;
}

server {
    listen 443 ssl http2;
    server_name your-domain.com;
    
    # SSLé…ç½®
    ssl_certificate /path/to/ssl/cert.pem;
    ssl_certificate_key /path/to/ssl/private.key;
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
    ssl_prefer_server_ciphers off;
    ssl_session_cache shared:SSL:10m;
    ssl_session_timeout 10m;
    
    # å‰ç«¯é™æ€æ–‡ä»¶
    location / {
        proxy_pass http://127.0.0.1:3000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
    }
    
    # åç«¯API
    location /api/ {
        proxy_pass http://127.0.0.1:8000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        proxy_cache_bypass $http_upgrade;
        
        # APIé™æµ
        limit_req zone=api burst=20 nodelay;
    }
    
    # WebSocket
    location /ws {
        proxy_pass http://127.0.0.1:8000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
    
    # é™æ€èµ„æºç¼“å­˜
    location ~* \.(js|css|png|jpg|jpeg|gif|ico|svg)$ {
        expires 1y;
        add_header Cache-Control "public, immutable";
        add_header X-Content-Type-Options nosniff;
    }
    
    # å®‰å…¨å¤´
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
    add_header X-XSS-Protection "1; mode=block";
    add_header Strict-Transport-Security "max-age=31536000; includeSubDomains" always;
}

# é™æµé…ç½®
http {
    limit_req_zone $binary_remote_addr zone=api:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=login:10m rate=5r/m;
}
```

### 4.6 ç³»ç»ŸæœåŠ¡é…ç½®

**åç«¯æœåŠ¡ï¼š`/etc/systemd/system/goldfish-backend.service`**

```ini
[Unit]
Description=Goldfish License System Backend
After=network.target postgresql.service redis.service

[Service]
Type=exec
User=www-data
Group=www-data
WorkingDirectory=/opt/goldfish-license-system/backend
Environment=PATH=/opt/goldfish-license-system/backend/venv/bin
ExecStart=/opt/goldfish-license-system/backend/venv/bin/gunicorn main:app -w 4 -k uvicorn.workers.UvicornWorker --bind 127.0.0.1:8000
Restart=always
RestartSec=3

[Install]
WantedBy=multi-user.target
```

**å‰ç«¯æœåŠ¡ï¼š`/etc/systemd/system/goldfish-frontend.service`**

```ini
[Unit]
Description=Goldfish License System Frontend
After=network.target

[Service]
Type=exec
User=www-data
Group=www-data
WorkingDirectory=/opt/goldfish-license-system/frontend
Environment=NODE_ENV=production
ExecStart=/usr/bin/npm start
Restart=always
RestartSec=3

[Install]
WantedBy=multi-user.target
```

**å¯ç”¨æœåŠ¡ï¼š**

```bash
sudo systemctl enable goldfish-backend
sudo systemctl enable goldfish-frontend
sudo systemctl enable nginx
sudo systemctl enable postgresql
sudo systemctl enable redis

sudo systemctl start goldfish-backend
sudo systemctl start goldfish-frontend
sudo systemctl start nginx
```

## æµ‹è¯•æ–¹æ¡ˆ

### 5.1 å•å…ƒæµ‹è¯•

**åç«¯æµ‹è¯•æ¡†æ¶ï¼špytest**

```python
# tests/test_license_service.py
import pytest
from datetime import datetime, timedelta
from app.services.license_service import LicenseService
from app.models.license import License, LicenseStatus

@pytest.fixture
def license_service():
    return LicenseService()

@pytest.fixture
def sample_license():
    return License(
        key="TEST-1234-5678-9ABC",
        type="standard",
        status=LicenseStatus.INACTIVE,
        expires_at=datetime.utcnow() + timedelta(days=30),
        max_devices=1,
        application_id=1
    )

class TestLicenseService:
    
    async def test_generate_license_key(self, license_service):
        """æµ‹è¯•å¡å¯†ç”Ÿæˆ"""
        key = await license_service.generate_license_key()
        assert len(key) == 19  # æ ¼å¼ï¼šXXXX-XXXX-XXXX-XXXX
        assert key.count('-') == 3
    
    async def test_activate_license(self, license_service, sample_license):
        """æµ‹è¯•å¡å¯†æ¿€æ´»"""
        device_id = "test-device-001"
        user_id = 1
        
        result = await license_service.activate_license(
            sample_license.key, device_id, user_id
        )
        
        assert result.success is True
        assert result.license.status == LicenseStatus.ACTIVE
        assert len(result.license.devices) == 1
    
    async def test_activate_expired_license(self, license_service):
        """æµ‹è¯•æ¿€æ´»è¿‡æœŸå¡å¯†"""
        expired_license = License(
            key="EXPIRED-TEST-KEY",
            type="standard",
            status=LicenseStatus.INACTIVE,
            expires_at=datetime.utcnow() - timedelta(days=1),
            max_devices=1,
            application_id=1
        )
        
        result = await license_service.activate_license(
            expired_license.key, "device-001", 1
        )
        
        assert result.success is False
        assert "expired" in result.error_message.lower()
    
    async def test_device_limit_exceeded(self, license_service):
        """æµ‹è¯•è®¾å¤‡æ•°é‡é™åˆ¶"""
        # åˆ›å»ºå·²è¾¾åˆ°è®¾å¤‡é™åˆ¶çš„å¡å¯†
        license_with_max_devices = License(
            key="MAX-DEVICE-TEST",
            type="standard",
            status=LicenseStatus.ACTIVE,
            expires_at=datetime.utcnow() + timedelta(days=30),
            max_devices=1,
            application_id=1
        )
        # å‡è®¾å·²æœ‰ä¸€ä¸ªè®¾å¤‡ç»‘å®š
        
        result = await license_service.activate_license(
            license_with_max_devices.key, "new-device", 1
        )
        
        assert result.success is False
        assert "device limit" in result.error_message.lower()
```

**å‰ç«¯æµ‹è¯•æ¡†æ¶ï¼šJest + React Testing Library**

```typescript
// __tests__/components/LicenseForm.test.tsx
import React from 'react';
import { render, screen, fireEvent, waitFor } from '@testing-library/react';
import { LicenseForm } from '@/components/LicenseForm';
import { LicenseService } from '@/services/license-service';

// MockæœåŠ¡
jest.mock('@/services/license-service');
const mockLicenseService = LicenseService as jest.Mocked<typeof LicenseService>;

describe('LicenseForm', () => {
  beforeEach(() => {
    jest.clearAllMocks();
  });

  test('renders license form correctly', () => {
    render(<LicenseForm />);
    
    expect(screen.getByLabelText(/license key/i)).toBeInTheDocument();
    expect(screen.getByLabelText(/device id/i)).toBeInTheDocument();
    expect(screen.getByRole('button', { name: /activate/i })).toBeInTheDocument();
  });

  test('validates required fields', async () => {
    render(<LicenseForm />);
    
    const activateButton = screen.getByRole('button', { name: /activate/i });
    fireEvent.click(activateButton);
    
    await waitFor(() => {
      expect(screen.getByText(/license key is required/i)).toBeInTheDocument();
      expect(screen.getByText(/device id is required/i)).toBeInTheDocument();
    });
  });

  test('submits form with valid data', async () => {
    const mockActivate = jest.fn().mockResolvedValue({
      success: true,
      license: { id: 1, key: 'TEST-KEY', status: 'active' }
    });
    mockLicenseService.activate = mockActivate;
    
    render(<LicenseForm />);
    
    fireEvent.change(screen.getByLabelText(/license key/i), {
      target: { value: 'TEST-1234-5678-9ABC' }
    });
    fireEvent.change(screen.getByLabelText(/device id/i), {
      target: { value: 'device-001' }
    });
    
    fireEvent.click(screen.getByRole('button', { name: /activate/i }));
    
    await waitFor(() => {
      expect(mockActivate).toHaveBeenCalledWith('TEST-1234-5678-9ABC', 'device-001');
    });
  });

  test('displays error message on activation failure', async () => {
    const mockActivate = jest.fn().mockResolvedValue({
      success: false,
      error_message: 'License key not found'
    });
    mockLicenseService.activate = mockActivate;
    
    render(<LicenseForm />);
    
    fireEvent.change(screen.getByLabelText(/license key/i), {
      target: { value: 'INVALID-KEY' }
    });
    fireEvent.change(screen.getByLabelText(/device id/i), {
      target: { value: 'device-001' }
    });
    
    fireEvent.click(screen.getByRole('button', { name: /activate/i }));
    
    await waitFor(() => {
      expect(screen.getByText(/license key not found/i)).toBeInTheDocument();
    });
  });
});
```

### 5.2 é›†æˆæµ‹è¯•

**APIé›†æˆæµ‹è¯•ï¼š**

```python
# tests/test_api_integration.py
import pytest
from httpx import AsyncClient
from app.main import app

@pytest.mark.asyncio
class TestLicenseAPI:
    
    async def test_license_lifecycle(self):
        """æµ‹è¯•å¡å¯†å®Œæ•´ç”Ÿå‘½å‘¨æœŸ"""
        async with AsyncClient(app=app, base_url="http://test") as client:
            # 1. ç®¡ç†å‘˜ç™»å½•
            login_response = await client.post("/api/auth/login", json={
                "username": "admin",
                "password": "admin1314159"
            })
            assert login_response.status_code == 200
            token = login_response.json()["access_token"]
            headers = {"Authorization": f"Bearer {token}"}
            
            # 2. åˆ›å»ºåº”ç”¨
            app_response = await client.post("/api/applications", json={
                "name": "Test Application",
                "version": "1.0.0",
                "description": "Test app for integration testing"
            }, headers=headers)
            assert app_response.status_code == 201
            app_id = app_response.json()["id"]
            
            # 3. ç”Ÿæˆå¡å¯†
            license_response = await client.post("/api/licenses", json={
                "type": "standard",
                "duration_days": 30,
                "max_devices": 1,
                "application_id": app_id
            }, headers=headers)
            assert license_response.status_code == 201
            license_key = license_response.json()["key"]
            
            # 4. ç”¨æˆ·æ³¨å†Œ
            register_response = await client.post("/api/auth/register", json={
                "username": "testuser",
                "email": "test@example.com",
                "password": "testpass123"
            })
            assert register_response.status_code == 201
            
            # 5. ç”¨æˆ·ç™»å½•
            user_login_response = await client.post("/api/auth/login", json={
                "username": "testuser",
                "password": "testpass123"
            })
            assert user_login_response.status_code == 200
            user_token = user_login_response.json()["access_token"]
            user_headers = {"Authorization": f"Bearer {user_token}"}
            
            # 6. æ¿€æ´»å¡å¯†
            activate_response = await client.post("/api/licenses/activate", json={
                "license_key": license_key,
                "device_id": "test-device-001"
            }, headers=user_headers)
            assert activate_response.status_code == 200
            assert activate_response.json()["success"] is True
            
            # 7. éªŒè¯å¡å¯†çŠ¶æ€
            verify_response = await client.post("/api/licenses/verify", json={
                "license_key": license_key,
                "device_id": "test-device-001"
            }, headers=user_headers)
            assert verify_response.status_code == 200
            assert verify_response.json()["valid"] is True
            
            # 8. åœç”¨å¡å¯†
            deactivate_response = await client.post(
                f"/api/licenses/{license_key}/deactivate",
                headers=headers
            )
            assert deactivate_response.status_code == 200
            
            # 9. éªŒè¯å¡å¯†å·²åœç”¨
            verify_deactivated_response = await client.post("/api/licenses/verify", json={
                "license_key": license_key,
                "device_id": "test-device-001"
            }, headers=user_headers)
            assert verify_deactivated_response.status_code == 200
            assert verify_deactivated_response.json()["valid"] is False
```

### 5.3 æ€§èƒ½æµ‹è¯•

**è´Ÿè½½æµ‹è¯•è„šæœ¬ï¼š**

```python
# tests/performance/load_test.py
import asyncio
import aiohttp
import time
from typing import List, Dict
import statistics

class LoadTester:
    def __init__(self, base_url: str, concurrent_users: int = 100):
        self.base_url = base_url
        self.concurrent_users = concurrent_users
        self.results: List[Dict] = []
    
    async def make_request(self, session: aiohttp.ClientSession, endpoint: str, 
                          method: str = 'GET', data: dict = None) -> Dict:
        """å‘é€å•ä¸ªè¯·æ±‚å¹¶è®°å½•æ€§èƒ½æŒ‡æ ‡"""
        start_time = time.time()
        try:
            async with session.request(method, f"{self.base_url}{endpoint}", 
                                     json=data) as response:
                await response.text()
                end_time = time.time()
                return {
                    'endpoint': endpoint,
                    'method': method,
                    'status_code': response.status,
                    'response_time': end_time - start_time,
                    'success': 200 <= response.status < 400
                }
        except Exception as e:
            end_time = time.time()
            return {
                'endpoint': endpoint,
                'method': method,
                'status_code': 0,
                'response_time': end_time - start_time,
                'success': False,
                'error': str(e)
            }
    
    async def simulate_user_session(self, session: aiohttp.ClientSession, user_id: int):
        """æ¨¡æ‹Ÿç”¨æˆ·ä¼šè¯"""
        # 1. ç™»å½•
        login_result = await self.make_request(
            session, '/api/auth/login', 'POST',
            {'username': f'user{user_id}', 'password': 'testpass123'}
        )
        self.results.append(login_result)
        
        if not login_result['success']:
            return
        
        # 2. è·å–ç”¨æˆ·ä¿¡æ¯
        profile_result = await self.make_request(session, '/api/users/profile')
        self.results.append(profile_result)
        
        # 3. æŸ¥è¯¢å¡å¯†åˆ—è¡¨
        licenses_result = await self.make_request(session, '/api/licenses')
        self.results.append(licenses_result)
        
        # 4. éªŒè¯å¡å¯†
        verify_result = await self.make_request(
            session, '/api/licenses/verify', 'POST',
            {'license_key': 'TEST-KEY', 'device_id': f'device-{user_id}'}
        )
        self.results.append(verify_result)
    
    async def run_load_test(self, duration_seconds: int = 60):
        """è¿è¡Œè´Ÿè½½æµ‹è¯•"""
        print(f"Starting load test with {self.concurrent_users} concurrent users for {duration_seconds} seconds")
        
        connector = aiohttp.TCPConnector(limit=self.concurrent_users * 2)
        async with aiohttp.ClientSession(connector=connector) as session:
            start_time = time.time()
            tasks = []
            
            while time.time() - start_time < duration_seconds:
                # åˆ›å»ºå¹¶å‘ç”¨æˆ·ä»»åŠ¡
                for user_id in range(self.concurrent_users):
                    task = asyncio.create_task(
                        self.simulate_user_session(session, user_id)
                    )
                    tasks.append(task)
                
                # ç­‰å¾…å½“å‰æ‰¹æ¬¡å®Œæˆ
                await asyncio.gather(*tasks, return_exceptions=True)
                tasks.clear()
                
                # çŸ­æš‚ä¼‘æ¯
                await asyncio.sleep(1)
    
    def generate_report(self) -> Dict:
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æŠ¥å‘Š"""
        if not self.results:
            return {'error': 'No test results available'}
        
        # æŒ‰ç«¯ç‚¹åˆ†ç»„ç»Ÿè®¡
        endpoint_stats = {}
        for result in self.results:
            endpoint = result['endpoint']
            if endpoint not in endpoint_stats:
                endpoint_stats[endpoint] = {
                    'total_requests': 0,
                    'successful_requests': 0,
                    'failed_requests': 0,
                    'response_times': [],
                    'error_rate': 0
                }
            
            stats = endpoint_stats[endpoint]
            stats['total_requests'] += 1
            stats['response_times'].append(result['response_time'])
            
            if result['success']:
                stats['successful_requests'] += 1
            else:
                stats['failed_requests'] += 1
        
        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        for endpoint, stats in endpoint_stats.items():
            response_times = stats['response_times']
            stats['avg_response_time'] = statistics.mean(response_times)
            stats['min_response_time'] = min(response_times)
            stats['max_response_time'] = max(response_times)
            stats['p95_response_time'] = statistics.quantiles(response_times, n=20)[18]  # 95th percentile
            stats['error_rate'] = (stats['failed_requests'] / stats['total_requests']) * 100
            stats['throughput'] = stats['total_requests'] / 60  # requests per second
        
        return {
            'total_requests': len(self.results),
            'concurrent_users': self.concurrent_users,
            'endpoint_statistics': endpoint_stats,
            'overall_error_rate': (sum(1 for r in self.results if not r['success']) / len(self.results)) * 100
        }

# è¿è¡Œè´Ÿè½½æµ‹è¯•
if __name__ == '__main__':
    async def main():
        tester = LoadTester('http://localhost:8000', concurrent_users=50)
        await tester.run_load_test(duration_seconds=120)
        report = tester.generate_report()
        
        print("\n=== Load Test Report ===")
        print(f"Total Requests: {report['total_requests']}")
        print(f"Concurrent Users: {report['concurrent_users']}")
        print(f"Overall Error Rate: {report['overall_error_rate']:.2f}%")
        
        print("\n=== Endpoint Statistics ===")
        for endpoint, stats in report['endpoint_statistics'].items():
            print(f"\n{endpoint}:")
            print(f"  Total Requests: {stats['total_requests']}")
            print(f"  Success Rate: {((stats['successful_requests']/stats['total_requests'])*100):.2f}%")
            print(f"  Avg Response Time: {stats['avg_response_time']*1000:.2f}ms")
            print(f"  P95 Response Time: {stats['p95_response_time']*1000:.2f}ms")
            print(f"  Throughput: {stats['throughput']:.2f} req/s")
    
    asyncio.run(main())
```

### 5.4 å®‰å…¨æµ‹è¯•

**å®‰å…¨æµ‹è¯•æ£€æŸ¥æ¸…å•ï¼š**

```python
# tests/security/security_test.py
import pytest
import requests
from sqlalchemy import text
from app.core.database import get_db

class SecurityTester:
    def __init__(self, base_url: str):
        self.base_url = base_url
    
    def test_sql_injection(self):
        """æµ‹è¯•SQLæ³¨å…¥é˜²æŠ¤"""
        malicious_payloads = [
            "'; DROP TABLE users; --",
            "' OR '1'='1",
            "' UNION SELECT * FROM users --",
            "'; INSERT INTO users (username) VALUES ('hacker'); --"
        ]
        
        for payload in malicious_payloads:
            response = requests.post(f"{self.base_url}/api/auth/login", json={
                "username": payload,
                "password": "test"
            })
            
            # åº”è¯¥è¿”å›è®¤è¯å¤±è´¥ï¼Œè€Œä¸æ˜¯æœåŠ¡å™¨é”™è¯¯
            assert response.status_code in [400, 401, 422]
            assert "error" not in response.text.lower() or "sql" not in response.text.lower()
    
    def test_xss_protection(self):
        """æµ‹è¯•XSSé˜²æŠ¤"""
        xss_payloads = [
            "<script>alert('XSS')</script>",
            "javascript:alert('XSS')",
            "<img src=x onerror=alert('XSS')>",
            "<svg onload=alert('XSS')>"
        ]
        
        # è·å–ç®¡ç†å‘˜token
        login_response = requests.post(f"{self.base_url}/api/auth/login", json={
            "username": "admin",
            "password": "admin1314159"
        })
        token = login_response.json()["access_token"]
        headers = {"Authorization": f"Bearer {token}"}
        
        for payload in xss_payloads:
            response = requests.post(f"{self.base_url}/api/applications", json={
                "name": payload,
                "version": "1.0.0",
                "description": "Test app"
            }, headers=headers)
            
            if response.status_code == 201:
                # æ£€æŸ¥è¿”å›çš„æ•°æ®æ˜¯å¦è¢«æ­£ç¡®è½¬ä¹‰
                app_data = response.json()
                assert "<script>" not in app_data["name"]
                assert "javascript:" not in app_data["name"]
    
    def test_authentication_bypass(self):
        """æµ‹è¯•è®¤è¯ç»•è¿‡"""
        protected_endpoints = [
            "/api/users",
            "/api/licenses",
            "/api/applications",
            "/api/admin/dashboard"
        ]
        
        for endpoint in protected_endpoints:
            # æ— tokenè®¿é—®
            response = requests.get(f"{self.base_url}{endpoint}")
            assert response.status_code == 401
            
            # æ— æ•ˆtokenè®¿é—®
            headers = {"Authorization": "Bearer invalid_token"}
            response = requests.get(f"{self.base_url}{endpoint}", headers=headers)
            assert response.status_code == 401
    
    def test_rate_limiting(self):
        """æµ‹è¯•APIé™æµ"""
        # å¿«é€Ÿå‘é€å¤šä¸ªç™»å½•è¯·æ±‚
        for i in range(20):
            response = requests.post(f"{self.base_url}/api/auth/login", json={
                "username": "admin",
                "password": "wrong_password"
            })
            
            if i > 10:  # è¶…è¿‡é™åˆ¶ååº”è¯¥è¢«é™æµ
                assert response.status_code == 429
    
    def test_sensitive_data_exposure(self):
        """æµ‹è¯•æ•æ„Ÿæ•°æ®æ³„éœ²"""
        # æ­£å¸¸ç™»å½•
        response = requests.post(f"{self.base_url}/api/auth/login", json={
            "username": "admin",
            "password": "admin1314159"
        })
        
        user_data = response.json()
        
        # ç¡®ä¿å¯†ç ç­‰æ•æ„Ÿä¿¡æ¯ä¸åœ¨å“åº”ä¸­
        assert "password" not in user_data
        assert "password_hash" not in user_data
        assert "secret_key" not in user_data
    
    def test_csrf_protection(self):
        """æµ‹è¯•CSRFé˜²æŠ¤"""
        # è·å–token
        login_response = requests.post(f"{self.base_url}/api/auth/login", json={
            "username": "admin",
            "password": "admin1314159"
        })
        token = login_response.json()["access_token"]
        
        # å°è¯•ä»ä¸åŒæ¥æºå‘é€è¯·æ±‚
        headers = {
            "Authorization": f"Bearer {token}",
            "Origin": "http://malicious-site.com",
            "Referer": "http://malicious-site.com"
        }
        
        response = requests.post(f"{self.base_url}/api/applications", json={
            "name": "Test App",
            "version": "1.0.0"
        }, headers=headers)
        
        # åº”è¯¥è¢«CORSç­–ç•¥é˜»æ­¢
        assert response.status_code in [403, 400]
```

### 5.5 æµ‹è¯•æ‰§è¡Œ

**æµ‹è¯•å‘½ä»¤ï¼š**

```bash
# åç«¯æµ‹è¯•
cd backend

# è¿è¡Œå•å…ƒæµ‹è¯•
pytest tests/unit/ -v --cov=app --cov-report=html

# è¿è¡Œé›†æˆæµ‹è¯•
pytest tests/integration/ -v

# è¿è¡Œæ€§èƒ½æµ‹è¯•
python tests/performance/load_test.py

# è¿è¡Œå®‰å…¨æµ‹è¯•
pytest tests/security/ -v

# å‰ç«¯æµ‹è¯•
cd ../frontend

# è¿è¡Œå•å…ƒæµ‹è¯•
npm test

# è¿è¡ŒE2Eæµ‹è¯•
npm run test:e2e

# ç”Ÿæˆæµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š
npm run test:coverage
```

**æŒç»­é›†æˆé…ç½®ï¼š`.github/workflows/ci.yml`**

```yaml
name: CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  backend-tests:
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:13
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
      
      redis:
        image: redis:6
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install dependencies
      run: |
        cd backend
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-asyncio
    
    - name: Run tests
      env:
        DATABASE_URL: postgresql://postgres:postgres@localhost/test_db
        REDIS_URL: redis://localhost:6379
      run: |
        cd backend
        pytest tests/ -v --cov=app --cov-report=xml
    
    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./backend/coverage.xml
  
  frontend-tests:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Node.js
      uses: actions/setup-node@v3
      with:
        node-version: '18'
        cache: 'npm'
        cache-dependency-path: frontend/package-lock.json
    
    - name: Install dependencies
      run: |
        cd frontend
        npm ci
    
    - name: Run tests
      run: |
        cd frontend
        npm test -- --coverage --watchAll=false
    
    - name: Build
      run: |
        cd frontend
        npm run build
  
  security-scan:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Run security scan
      uses: securecodewarrior/github-action-add-sarif@v1
      with:
        sarif-file: 'security-scan-results.sarif'
```

---

## æ€»ç»“

æœ¬æ–‡æ¡£è¯¦ç»†æè¿°äº†é‡‘é±¼æ™ºç›’å¡å¯†æˆæƒç³»ç»Ÿçš„å®Œæ•´å¼€å‘ä¿¡æ¯ï¼Œæ¶µç›–äº†å‰ç«¯ã€åç«¯ã€æ•°æ®ã€UI/UXè®¾è®¡ç­‰å„ä¸ªæ–¹é¢ã€‚ç³»ç»Ÿé‡‡ç”¨ç°ä»£åŒ–çš„æŠ€æœ¯æ ˆï¼Œå…·å¤‡è‰¯å¥½çš„å¯æ‰©å±•æ€§å’Œç»´æŠ¤æ€§ã€‚

**ä¸»è¦ç‰¹ç‚¹ï¼š**
- å‰åç«¯åˆ†ç¦»æ¶æ„ï¼ŒæŠ€æœ¯æ ˆå…ˆè¿›
- å®Œå–„çš„æƒé™æ§åˆ¶å’Œå®‰å…¨æœºåˆ¶
- å“åº”å¼è®¾è®¡ï¼Œæ”¯æŒå¤šè®¾å¤‡è®¿é—®
- è¯¦ç»†çš„APIæ–‡æ¡£å’Œæµ‹è¯•è¦†ç›–
- å®Œæ•´çš„éƒ¨ç½²å’Œè¿ç»´æ–¹æ¡ˆ

**åç»­å‘å±•æ–¹å‘ï¼š**
- æŒç»­ä¼˜åŒ–æ€§èƒ½å’Œç”¨æˆ·ä½“éªŒ
- å®Œå–„ç›‘æ§å’Œå‘Šè­¦ç³»ç»Ÿ
- å¢åŠ æ›´å¤šä¼ä¸šçº§åŠŸèƒ½
- æå‡ç³»ç»Ÿå®‰å…¨æ€§å’Œç¨³å®šæ€§

æœ¬æ–‡æ¡£å°†éšç€ç³»ç»Ÿçš„å‘å±•æŒç»­æ›´æ–°ï¼Œä¸ºå¼€å‘å›¢é˜Ÿæä¾›æœ€æ–°çš„æŠ€æœ¯æŒ‡å¯¼ã€‚



